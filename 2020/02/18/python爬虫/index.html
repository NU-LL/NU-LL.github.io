<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>python爬虫 | spaceman</title><meta name="keywords" content="python,爬虫"><meta name="author" content="spaceman"><meta name="copyright" content="spaceman"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="定向网络数据爬取和网页解析 request库：http:&#x2F;&#x2F;www.python-request.org requests库官方文档中文版：http:&#x2F;&#x2F;cn.python-requests.org&#x2F;zh_CN&#x2F;latest&#x2F;index.html BeautifulSoup库官方文档中文版：http:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F; PEP8">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫">
<meta property="og:url" content="http://nu-ll.github.io/2020/02/18/python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="spaceman">
<meta property="og:description" content="定向网络数据爬取和网页解析 request库：http:&#x2F;&#x2F;www.python-request.org requests库官方文档中文版：http:&#x2F;&#x2F;cn.python-requests.org&#x2F;zh_CN&#x2F;latest&#x2F;index.html BeautifulSoup库官方文档中文版：http:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F; PEP8">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/NU-LL/image-host/raw/master/12.jpg">
<meta property="article:published_time" content="2020-02-18T15:40:18.000Z">
<meta property="article:modified_time" content="2020-03-04T06:42:28.419Z">
<meta property="article:author" content="spaceman">
<meta property="article:tag" content="python">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/NU-LL/image-host/raw/master/12.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://nu-ll.github.io/2020/02/18/python%E7%88%AC%E8%99%AB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'python爬虫',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-03-04 14:42:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/spaceman.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">92</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fas fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://gitee.com/NU-LL/image-host/raw/master/12.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">spaceman</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fas fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">python爬虫</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-02-18T15:40:18.000Z" title="发表于 2020-02-18 23:40:18">2020-02-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-03-04T06:42:28.419Z" title="更新于 2020-03-04 14:42:28">2020-03-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>60分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="python爬虫"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="定向网络数据爬取和网页解析">定向网络数据爬取和网页解析</h2>
<p>request库：<a target="_blank" rel="noopener" href="http://www.python-request.org">http://www.python-request.org</a></p>
<p>requests库官方文档中文版：<a target="_blank" rel="noopener" href="http://cn.python-requests.org/zh_CN/latest/index.html">http://cn.python-requests.org/zh_CN/latest/index.html</a><br>
BeautifulSoup库官方文档中文版：<a target="_blank" rel="noopener" href="http://beautifulsoup.readthedocs.io/zh_CN/latest/">http://beautifulsoup.readthedocs.io/zh_CN/latest/</a><br>
PEP8——Python代码规范：<a target="_blank" rel="noopener" href="https://www.python.org/dev/peps/pep-0008/">https://www.python.org/dev/peps/pep-0008/</a></p>
<p>简单入门：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> request</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>)<span class="comment">#访问百度</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.status_code<span class="comment">#获取状态码</span></span><br><span class="line"><span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.encoding=<span class="string">&#x27;utf-8&#x27;</span><span class="comment">#更改编码</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text<span class="comment">#打印网页内容</span></span><br><span class="line"><span class="string">&#x27;&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(\&#x27;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=\&#x27;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ \&#x27;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;\&#x27;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n&#x27;</span></span><br></pre></td></tr></table></figure>
<p>常用的7个方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">requests.request()<span class="comment">#构造一个请求,支撑以下各方法的基础方法</span></span><br><span class="line">requests.get()<span class="comment">#获取HTML网页的主要方法,对应于HTTP的GET </span></span><br><span class="line">requests.head()<span class="comment">#获取HTML网页头信息的方法,对应于HTTP的HEAD </span></span><br><span class="line">requests.post()<span class="comment">#向HTML网页提交POST请求的方法,对应于HTTP的POST </span></span><br><span class="line">requests.put()<span class="comment">#向HTML网页提交PUT请求的方法,对应于HTTP的PUT </span></span><br><span class="line">requests.patch()<span class="comment">#向HTML网页提交局部修改请求,对应于HTTP的PATCH </span></span><br><span class="line">requests.delete()<span class="comment">#向HTML页面提交删除请求,对应于HTTP的DELETE</span></span><br></pre></td></tr></table></figure>
<ul>
<li>实际上底层都是使用了<code>request</code>方法来封装</li>
</ul>
<p>爬虫的尺寸：</p>
<ul>
<li>Requests库：小规模，数据量小，爬取速度不敏感（爬取网页 玩转网页）</li>
<li>Scrapy库：中规模，数据规模较大，爬取速度敏感（爬取网站 爬取系列网站）</li>
<li>定制开发：大规模，搜索引擎，爬取速度关键（爬取全网）</li>
</ul>
<h3 id="get">get</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r = request.get(url)</span><br><span class="line"><span class="comment">#完整版</span></span><br><span class="line">r = request.get(url, params=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>get方法构造一个向服务器请求资源的Request对象（由request库内部生成）</li>
<li>r：返回一个包含服务器资源的Response对象（包括从服务器返回的所有资源）</li>
<li>url：拟获取页面的url链接</li>
<li>params:url中的额外参数,字典或字节流格式,可选</li>
<li>**kwargs:12个控制访问的参数</li>
</ul>
<p>Response对象常用属性：</p>
<ul>
<li><code>r.status_code</code>：HTTP请求的返回状态,200表示<strong>连接成功</strong>,404表示失败（其余各种数均为失败）</li>
<li><code>r.text</code>：HTTP响应内容的字符串形式,即,url应的页面内容</li>
<li><code>r.encoding</code>：从 HTTP header中猜测的响应内容编码方式（如果HTTP header中不存在，则默认为<strong>ISO-8859-1</strong>）</li>
<li><code>r.apparent_encoding</code>：从内容中分析出的响应内容编码方式(备选编码方式)</li>
<li><code>r.content</code>：HTTP响应内容的二进制形式（保存图片可能会用到）</li>
</ul>
<h3 id="通用代码框架">通用代码框架</h3>
<p>request库的相关异常：</p>
<ul>
<li><code>requests.ConnectionError</code>：网络连接错误异常,如DNS查询失败、拒绝连接等</li>
<li><code>requests.HTTPError</code>：HTTP错误异常</li>
<li><code>requests.URLRequired</code>：URL缺失异常</li>
<li><code>requests.TooManyRedirects</code>：超过最大重定向次数,产生重定向异常</li>
<li><code>requests.ConnectTimeout</code>：连接远程服务器超时异常（仅仅指与远程服务器连接的时间）</li>
<li><code>requests.Timeout</code>：请求URL超时,产生超时异常（发出请求到获得内容的整个过程的时间）</li>
</ul>
<p>产生异常函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r.raise_for_status()<span class="comment">#如果不是200,产生异常requests.HTTPError</span></span><br></pre></td></tr></table></figure>
<p>通用代码框架：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()<span class="comment">#如果状态不是200,引发理 PError异常</span></span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r. text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;产生异常&quot;</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    url = <span class="string">&quot;http://www.baidu.com&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(getHTMLText(url))</span><br></pre></td></tr></table></figure>
<h3 id="HTTP协议及request库方法">HTTP协议及request库方法</h3>
<h4 id="HTTP协议">HTTP协议</h4>
<p>HTTP, Hypertext Transfer Protocol,超文本传输协议，基于&quot;请求与响应&quot;模式的、无状态的应用层协议，采用URL作为定位网络资源的标识。URL是通过HTTP协议存取资源的Internet路径,一个URL对应一个数据资源。</p>
<p>URL格式：<code>http://host[:port][path]</code></p>
<ul>
<li>host:合法的 Internet主机域名或IP地址</li>
<li>port:端口号,缺省端囗为80</li>
<li>path:请求资源的路径</li>
</ul>
<p>HTTP协议对资源的操作：</p>
<ul>
<li><code>GET</code>：请求获取URL位置的资源</li>
<li><code>HEAD</code>：请求获取URL位置资源的响应消息报告,即获得该资源的头部信息</li>
<li><code>POST</code>：请求向URL位置的资源后附加新的数据</li>
<li><code>PUT</code>：请求向URL位置存储一个资源,覆盖原URL位置的资源</li>
<li><code>PATCH</code>：请求局部更新URL位置的资原,即改变该处资原的部分内容（节省网络带宽）</li>
<li><code>DELETE</code>：请求删除URL位置存储的资源</li>
</ul>
<p>注：上述方法和request库中的方法是一一对应的</p>
<h4 id="request库方法">request库方法</h4>
<p>由于网络安全的限制，一般只会使用到get，对于某些特别大的url链接只用head即可</p>
<p><strong>request方法</strong>：所有方法的基础方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.request(method, url, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>method:请求方式,对应其他get/put/post等7种方法</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">requests.request(<span class="string">&#x27;GET&#x27;</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">&#x27;HEAD&#x27;</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">&#x27;POST&#x27;</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">&#x27;PUT&#x27;</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">&#x27;PATCH&#x27;</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">&#x27;delete&#x27;</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">&#x27;OPTIONS&#x27;</span>, url, **kwargs)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>url:拟获取页面的url链接</p>
</li>
<li>
<p>**kwargs:控制访问的参数,共13个</p>
<ul>
<li>
<p>params:字典或字节序列,作为参数增加到url中</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">&#x27;key1&#x27;</span>:<span class="string">&#x27;value1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>:<span class="string">&#x27;value2&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;GET&#x27;</span>,<span class="string">&#x27;http://python123.io/ws&#x27;</span>,params = kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(r.url)</span><br><span class="line">https://python123.io/ws?key1=value1&amp;key2=value2</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(r.request.url)<span class="comment">#发过去的链接</span></span><br><span class="line">https://python123.io/ws?key1=value1&amp;key2=value2</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>data:字典、字节序列或文件对象,作为 Request的内容</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">&#x27;key1&#x27;</span>:<span class="string">&#x27;value1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>:<span class="string">&#x27;value2&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;POST&#x27;</span>,<span class="string">&#x27;http://python123.io/ws&#x27;</span>,data = kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>body = <span class="string">&#x27;主体内容&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;POST&#x27;</span>,<span class="string">&#x27;http://python123.io/ws&#x27;</span>,data = body)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>json:JSON格式的数据,作为 Request的内容</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">&#x27;key1&#x27;</span>:<span class="string">&#x27;value1&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;POST&#x27;</span>,<span class="string">&#x27;http://python123.io/ws&#x27;</span>,json = kv)<span class="comment">#赋值到服务器的json域上</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>headers:字典,HTTP定制头</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hd = &#123;<span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Chrome/10&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;POST&#x27;</span>,<span class="string">&#x27;http://python123.io/ws&#x27;</span>,headers = hd)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>cookies:字典或 Cookiejar, Request中的 cookie</p>
</li>
<li>
<p>auth:元组,支持HTTP认证功能</p>
</li>
<li>
<p>files:字典类型,传输文件</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fs = &#123;<span class="string">&#x27;file&#x27;</span>:<span class="built_in">open</span>(<span class="string">&#x27;data.xls&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;POST&#x27;</span>,<span class="string">&#x27;http://python123.io/ws&#x27;</span>,files = fs)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>timeout:设定超时时间,秒为单位（如果请求内容没有返回回来，会产生一个超时的异常）</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;GET&#x27;</span>,<span class="string">&#x27;http://www.baidu.com&#x27;</span>,timeout = <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>proxies:字典类型,设定访问代理服务器,可以增加登录认证</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pxs = &#123;<span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;http://user:pass@10.10.10.1:1234&#x27;</span>,<span class="string">&#x27;https&#x27;</span>:<span class="string">&#x27;https://10.10.10.1:4321&#x27;</span>&#125;<span class="comment">#增加http和https的代理，防止对爬虫的逆追踪</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">&#x27;GET&#x27;</span>,<span class="string">&#x27;http://www.baidu.com&#x27;</span>,proxies = pxs)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>allow_redirects:True/ False,默认为True,重定向开关</p>
</li>
<li>
<p>stream:True/ False,默认为True,获取内容立即下载开关</p>
</li>
<li>
<p>verify:True/ False,默认为True,认证SSL证书开关</p>
</li>
<li>
<p>cert:本地SSL证书路径</p>
</li>
</ul>
</li>
</ul>
<p><strong>get方法</strong>：获取网页</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get(url, params=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>params:url中的额外参数,字典或字节流格式,可选</li>
<li>**kwargs:12个控制访问的参数(request方法中除了params的12个访问参数)</li>
</ul>
<p><strong>head方法</strong>：用很少的流量获得资源的概要信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.head(url, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>**kwargs:13个控制访问的参数(与request方法中一样)</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.head(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.headers<span class="comment">#展示头部信息</span></span><br><span class="line">&#123;<span class="string">&#x27;Date&#x27;</span>: <span class="string">&#x27;Wed, 19 Feb 2020 04:58:13 GMT&#x27;</span>, <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>, <span class="string">&#x27;Content-Length&#x27;</span>: <span class="string">&#x27;305&#x27;</span>, <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>, <span class="string">&#x27;Server&#x27;</span>: <span class="string">&#x27;gunicorn/19.9.0&#x27;</span>, <span class="string">&#x27;Access-Control-Allow-Origin&#x27;</span>: <span class="string">&#x27;*&#x27;</span>, <span class="string">&#x27;Access-Control-Allow-Credentials&#x27;</span>: <span class="string">&#x27;true&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text<span class="comment">#展示全部内容</span></span><br><span class="line"><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>post方法</strong>：向服务器提交新增数据。向 URL POST一个<strong>字典</strong>会自动编码为<strong>form</strong>(表单)，向 URL POST一个<strong>字符串</strong>会自动编码为<strong>data</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.post(url, data=<span class="literal">None</span>, json=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>data:字典、字节序列或文件, Request的内容</li>
<li>json:JSON格式的数据, Request的内容</li>
<li>**kwargs:剩下11个控制访问的参数(与request方法中一样)</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>payload = &#123;<span class="string">&#x27;key1&#x27;</span>:<span class="string">&#x27;value1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>:<span class="string">&#x27;value2&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>,data = payload)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;key1&quot;</span>: <span class="string">&quot;value1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;key2&quot;</span>: <span class="string">&quot;value2&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>,data = <span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">&quot;data&quot;</span>: <span class="string">&quot;ABC&quot;</span>,</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;&#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>put方法</strong>：与post方法类似，只不过会覆盖原有数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.put(url, data=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>data:字典、字节序列或文件, Request的内容</li>
<li>**kwargs:剩下12个控制访问的参数(与request方法中一样)</li>
</ul>
<p><strong>patch方法</strong>：向HTML网页提交局部修改请求,对应于HTTP的PATCH，能够节省网络带宽</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.patch(url, data=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>data:字典、字节序列或文件, Request的内容</li>
<li>**kwargs:剩下12个控制访问的参数(与request方法中一样)</li>
</ul>
<p><strong>delete方法</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.patch(url, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>**kwargs:13个控制访问的参数(与request方法中一样)</li>
</ul>
<h3 id="Robots协议">Robots协议</h3>
<p>一些网站对网络爬虫的限制：</p>
<ul>
<li>来源审查:判断 User-Agent进行限制
<ul>
<li>检查来访HTTP协议头的User-Agent域或,只响应浏览器或友好爬虫的访问</li>
</ul>
</li>
<li>发布公告: Robots协议，Robots exclusion standard 网络爬虫排除标准
<ul>
<li>告知所有爬虫，网站的爬取策略，要求爬虫遵守.</li>
</ul>
</li>
</ul>
<p>Robots协议：</p>
<ul>
<li>作用:网站告知网络爬虫哪些页面可以抓取,哪些不行</li>
<li>形式:在网站根目录下的 robots.txt文件中写明了那些目录能够爬取，那些不能</li>
</ul>
<p>例子（京东Robots协议<a target="_blank" rel="noopener" href="https://www.jd.com/robots.txt">https://www.jd.com/robots.txt</a>）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">User-agent: * </span><br><span class="line">Disallow: /?* </span><br><span class="line">Disallow: /pop/*.html </span><br><span class="line">Disallow: /pinpai/*.html?* </span><br><span class="line">User-agent: EtaoSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: HuihuiSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: GwdangSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: WochachaSpider </span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure>
<ul>
<li><code>User-agent: *</code> ：对于任何的爬虫来源，都应该遵守如下规则</li>
<li><code>Disallow</code>：不允许访问的目录和文件</li>
<li><code>EtaoSpider</code>、<code>HuihuiSpider</code>、<code>GwdangSpider</code>、<code>WochachaSpider</code>：对这四类爬虫禁止爬取</li>
</ul>
<p>其他例子：</p>
<ul>
<li>百度：<a target="_blank" rel="noopener" href="http://www.baudu.com/robots.txt">http://www.baudu.com/robots.txt</a></li>
<li>新浪：<a target="_blank" rel="noopener" href="http://www.sina.com.cn/robots.txt">http://www.sina.com.cn/robots.txt</a></li>
<li>QQ：<a target="_blank" rel="noopener" href="http://www.qq.com/robots.txt">http://www.qq.com/robots.txt</a></li>
<li>QQ新闻：<a target="_blank" rel="noopener" href="http://news.qq.com/robots.txt">http://news.qq.com/robots.txt</a></li>
</ul>
<h4 id="遵守方式">遵守方式</h4>
<p>要求网络爬虫能够自动或人工识别 robots.txt,再进行内容爬取</p>
<p>Robots协议是建议但非约束性,网络爬虫可以不遵守,但存在法律风险.</p>
<h3 id="实例-3">实例</h3>
<p>亚马逊商品获取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">&quot;https://www.amazon.cn/gp/product/B01M8L5Z3Y&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0&#x27;</span>&#125;</span><br><span class="line">    r = requests.get(url, headers=kv)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    <span class="built_in">print</span>(r.text[<span class="number">1000</span>:<span class="number">2000</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取失败&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>360、百度的搜索：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">&quot;http://www.baidu.com/s&quot;</span><span class="comment">#百度</span></span><br><span class="line"><span class="comment">#url = &quot;http://www.so.com/s&quot;#360</span></span><br><span class="line">keyword = <span class="string">&quot;python&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">&#x27;wd&#x27;</span>:keyword&#125;<span class="comment">#百度</span></span><br><span class="line">    <span class="comment">#kv = &#123;&#x27;q&#x27;:keyword&#125;#360</span></span><br><span class="line">    r = requests.get(url, params=kv)</span><br><span class="line">    <span class="built_in">print</span>(r.request.url)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(r.text))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取失败&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>网络图片的爬取和存储：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">url = <span class="string">&quot;http://image.nationalgeographic.com.cn/2017/0211/20170211061910157.jpg&quot;</span></span><br><span class="line">root = <span class="string">&quot;D://pics//&quot;</span></span><br><span class="line">path = root+url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;文件保存成功&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;文件已存在&quot;</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取失败&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="网络爬虫与信息提取">网络爬虫与信息提取</h2>
<p>BeautifulSoup库：能够解析HTML和XML</p>
<p>BeautifulSoup库官方文档中文版：<a target="_blank" rel="noopener" href="http://beautifulsoup.readthedocs.io/zh_CN/latest/">http://beautifulsoup.readthedocs.io/zh_CN/latest/</a></p>
<h3 id="BeautifulSoup库的基本元素">BeautifulSoup库的基本元素</h3>
<p>HTML/XML文档 &lt;==&gt; 标签树 &lt;==&gt; BeautifulSoup类，即BeautifulSoup类对应一个 HTMLIXML文档的全部内容.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#常用形式：</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(<span class="string">&quot;&lt;html&gt;data&lt;/html&gt;&quot;</span>,<span class="string">&quot;html.parser&quot;</span>)<span class="comment">#方式一</span></span><br><span class="line">soup2 = BeautifulSoup(<span class="built_in">open</span>(<span class="string">&quot;D://demo.html&quot;</span>),<span class="string">&quot;html.parser&quot;</span>)<span class="comment">#方式二</span></span><br></pre></td></tr></table></figure>
<p>BeautifulSoup库的解析器：</p>
<ul>
<li>bs4的HTML解析器：<code>BeautifulSoup( mk, 'html.parser')</code>，需要安装bs4库</li>
<li>lxml的HTML解析器：<code>BeautifulSoup(mk,'lxml')</code>，需要安装lxml：<br>
<code>pip install Ixml</code></li>
<li>lxml的XML解析器：<code>BeautifulSoup(mk, ‘xml’)</code>，需要安装lxml：<code>pip install lxml</code></li>
<li>htmI5lib的解析器：<code>BeautifulSoup(mk, 'html5lib')</code>，需要安装html5lib：<code>pip install html5lib</code></li>
</ul>
<p>BeautifulSoup类的基本元素：</p>
<ul>
<li><code>Tag</code>：标签,最基本的信息组织单元,分别用&lt;&gt;和&lt;/&gt;标明开头和结尾</li>
<li><code>Name</code>：标签的名字,<p>…</p>的名字是’p’,格式:<tag>.name</tag></li>
<li><code>Attributes</code>：标签的属性,<strong>字典</strong>形式组织,格式:<tag>.attrs
<ul>
<li>无论标签有没有属性，总能获得一个attrs，无属性就是空</li>
</ul>
</tag></li>
<li><code>NavigableString</code>：标签内非属性字符串,&lt;&gt;…&lt;/&gt;中字符串,格式:<tag>.string</tag></li>
<li><code>Comment</code>：标签内字符串的注释部分,一种特殊的Comment类型</li>
</ul>
<p><img src="/2020/02/18/python%E7%88%AC%E8%99%AB/image-20200220123236026.png" alt="图解"></p>
<p>例子：</p>
<p>对于如下demo网页<a target="_blank" rel="noopener" href="https://python123.io/ws/demo.html">https://python123.io/ws/demo.html</a>，其内容为：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>This is a python demo page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;title&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>The demo python introduces several python courses.<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;course&quot;</span>&gt;</span>Python is a wonderful general-purpose programming language. You can learn Python from novice to</span><br><span class="line">        professional by tracking the following courses:</span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="attr">class</span>=<span class="string">&quot;py1&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Basic Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span> and <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">            <span class="attr">href</span>=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="attr">class</span>=<span class="string">&quot;py2&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Advanced Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>使用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup<span class="comment">#从bs4库中导入BeautifulSoup类</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)<span class="comment">#demo即为上述页面的一个变量</span></span><br><span class="line"><span class="comment">#也可以通过soup = BeautifulSoup(open(&quot;demo.html&quot;),&quot;html.parser&quot;)，从本地文件获取</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.title<span class="comment">#查看title</span></span><br><span class="line">&lt;title&gt;This <span class="keyword">is</span> a python demo page&lt;/title&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag = soup.a<span class="comment">#获得a标签（只能获取第一个）</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag<span class="comment">#标签</span></span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(tag)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;bs4.element.Tag&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag.attrs<span class="comment">#标签属性 字典类型</span></span><br><span class="line">&#123;<span class="string">&#x27;href&#x27;</span>: <span class="string">&#x27;http://www.icourse163.org/course/BIT-268001&#x27;</span>, <span class="string">&#x27;class&#x27;</span>: [<span class="string">&#x27;py1&#x27;</span>], <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;link1&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag.attrs[<span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;py1&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(tag.attrs)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;dict&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag.string<span class="comment">#字符串属性 </span></span><br><span class="line"><span class="string">&#x27;Basic Python&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(tag.string)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;bs4.element.NavigableString&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.name<span class="comment">#获得a标签的名字</span></span><br><span class="line"><span class="string">&#x27;a&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.parent.name<span class="comment">#获得a标签的父亲的名字</span></span><br><span class="line"><span class="string">&#x27;p&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.parent.parent.name<span class="comment">#获得a标签的父亲的父亲的名字</span></span><br><span class="line"><span class="string">&#x27;body&#x27;</span></span><br></pre></td></tr></table></figure>
<p>关于注释的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>newsoup = BeautifulSoup(<span class="string">&quot;&lt;b&gt;&lt;!--This is a comment--&gt;&lt;/b&gt;&lt;p&gt;This is not a comment&lt;/p&gt;&quot;</span>,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="comment">#注释</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>newsoup.b.string</span><br><span class="line"><span class="string">&#x27;This is a comment&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(newsoup.b.string)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;bs4.element.Comment&#x27;</span>&gt;</span><br><span class="line"><span class="comment">#字符串</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>newsoup.p.string</span><br><span class="line"><span class="string">&#x27;This is not a comment&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(newsoup.p.string)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;bs4.element.NavigableString&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>是字符串还是注释，需要根据<strong>类型</strong>去判断</li>
</ul>
<h3 id="HTML遍历">HTML遍历</h3>
<p>下行遍历：沿着根节点向叶子节点遍历的</p>
<p>上行遍历：沿着叶子结点向根节点遍历</p>
<p>平行遍历：在平行节点之间互相遍历</p>
<p>标签树的<strong>下行遍历</strong>：</p>
<ul>
<li><code>.contents</code>：子节点的列表,将<tag><strong>所有</strong>儿子节点存入列表</tag></li>
<li><code>.children</code>：子节点的迭代类型,与.contents类似,用于循环遍历儿子节点</li>
<li><code>.descendants</code>：子孙节点的迭代类型,包含所有子孙节点,用于循环遍历</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.head</span><br><span class="line">&lt;head&gt;&lt;title&gt;This <span class="keyword">is</span> a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.head.contents</span><br><span class="line">[&lt;title&gt;This <span class="keyword">is</span> a python demo page&lt;/title&gt;]</span><br><span class="line"><span class="comment">#.contents</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.body.contents</span><br><span class="line">[<span class="string">&#x27;\n&#x27;</span>, &lt;p <span class="keyword">class</span>=<span class="string">&quot;title&quot;</span>&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;, <span class="string">&#x27;\n&#x27;</span>, &lt;p <span class="keyword">class</span>=<span class="string">&quot;course&quot;</span>&gt;Python <span class="keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="keyword">from</span> novice to professional by tracking the following courses:</span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt; <span class="keyword">and</span> &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;, <span class="string">&#x27;\n&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(soup.body.contents)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.body.contents[<span class="number">1</span>]</span><br><span class="line">&lt;p <span class="keyword">class</span>=<span class="string">&quot;title&quot;</span>&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;</span><br><span class="line"><span class="comment">#.children 遍历儿子节点</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.body.children:</span><br><span class="line">    <span class="built_in">print</span>(child)</span><br><span class="line"><span class="comment">#.descendants 遍历子孙节点</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.body.descendants:</span><br><span class="line">    <span class="built_in">print</span>(child)</span><br></pre></td></tr></table></figure>
<ul>
<li>一个标签的子节点并不仅仅只有标签节点，也存在<strong>字符串节点</strong>，如：‘\n’</li>
</ul>
<p>标签树的<strong>上行遍历</strong>：</p>
<ul>
<li><code>.parent</code>：节点的父亲标签</li>
<li><code>.parents</code>：节点先辈标签的迭代类型,用于循环遍历先辈节点</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="comment">#.parent</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.title.parent</span><br><span class="line">&lt;head&gt;&lt;title&gt;This <span class="keyword">is</span> a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.html.parent</span><br><span class="line">&lt;html&gt;&lt;head&gt;&lt;title&gt;This <span class="keyword">is</span> a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;p <span class="keyword">class</span>=<span class="string">&quot;title&quot;</span>&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;</span><br><span class="line">&lt;p <span class="keyword">class</span>=<span class="string">&quot;course&quot;</span>&gt;Python <span class="keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="keyword">from</span> novice to professional by tracking the following courses:</span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt; <span class="keyword">and</span> &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.parent<span class="comment">#空</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#.parents 上行遍历</span></span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.a.parents:</span><br><span class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(parent)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(parent.name)</span><br></pre></td></tr></table></figure>
<p>标签树的<strong>平行遍历</strong>：</p>
<ul>
<li>.next_sibling：返回按照HTML文本顺序的下一个平行节点标签</li>
<li>.previous_sibling：返回按照HTML文本顺序的上一个平行节点标签</li>
<li>.next_siblings：迭代类型,返回按照HTML文本顺序的后续所有平行节点标签</li>
<li>.previous_siblings：迭代类型,返回按照HTML文本顺序的前续所有平行节点标签</li>
</ul>
<p>条件：所有的平行遍历都发生在<strong>同一个父节点</strong>下的各节点间</p>
<p>注意：任何一个节点的平行、父亲、儿子节点是可能存在<strong>NavigableString</strong>类型的</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="comment">#.next_sibling</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.next_sibling</span><br><span class="line"><span class="string">&#x27; and &#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.next_sibling.next_sibling</span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;</span><br><span class="line"><span class="comment">#.previous_sibling</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.previous_sibling</span><br><span class="line"><span class="string">&#x27;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.previous_sibling.previous_sibling<span class="comment">#空标签</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.parent</span><br><span class="line">&lt;p <span class="keyword">class</span>=<span class="string">&quot;course&quot;</span>&gt;Python <span class="keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="keyword">from</span> novice to professional by tracking the following courses:</span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt; <span class="keyword">and</span> &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"><span class="comment">#遍历后续节点：</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">    <span class="built_in">print</span>(sibling)</span><br><span class="line"><span class="comment">#遍历前续节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.previous_siblings:</span><br><span class="line">    <span class="built_in">print</span>(sibling)</span><br></pre></td></tr></table></figure>
<h3 id="HTML格式化和编码">HTML格式化和编码</h3>
<p>基于bs4库的<code>prettify()</code>方法</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.prettify()</span><br><span class="line"><span class="string">&#x27;&lt;html&gt;\n &lt;head&gt;\n  &lt;title&gt;\n   This is a python demo page\n  &lt;/title&gt;\n &lt;/head&gt;\n &lt;body&gt;\n  &lt;p class=&quot;title&quot;&gt;\n   &lt;b&gt;\n    The demo python introduces several python courses.\n   &lt;/b&gt;\n  &lt;/p&gt;\n  &lt;p class=&quot;course&quot;&gt;\n   Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\n   &lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt;\n    Basic Python\n   &lt;/a&gt;\n   and\n   &lt;a class=&quot;py2&quot; href=&quot;http://www.icourse163.org/course/BIT-1001870001&quot; id=&quot;link2&quot;&gt;\n    Advanced Python\n   &lt;/a&gt;\n   .\n  &lt;/p&gt;\n &lt;/body&gt;\n&lt;/html&gt;&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(soup.prettify())</span><br><span class="line">&lt;html&gt;</span><br><span class="line"> &lt;head&gt;</span><br><span class="line">  &lt;title&gt;</span><br><span class="line">   This <span class="keyword">is</span> a python demo page</span><br><span class="line">  &lt;/title&gt;</span><br><span class="line"> &lt;/head&gt;</span><br><span class="line"> &lt;body&gt;</span><br><span class="line">  &lt;p <span class="keyword">class</span>=<span class="string">&quot;title&quot;</span>&gt;</span><br><span class="line">   &lt;b&gt;</span><br><span class="line">    The demo python introduces several python courses.</span><br><span class="line">   &lt;/b&gt;</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line">  &lt;p <span class="keyword">class</span>=<span class="string">&quot;course&quot;</span>&gt;</span><br><span class="line">   Python <span class="keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="keyword">from</span> novice to professional by tracking the following courses:</span><br><span class="line">   &lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span><br><span class="line">    Basic Python</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   <span class="keyword">and</span></span><br><span class="line">   &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span><br><span class="line">    Advanced Python</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   .</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line"> &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(soup.a.prettify())</span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span><br><span class="line"> Basic Python</span><br><span class="line">&lt;/a&gt;</span><br></pre></td></tr></table></figure>
<p>bs4将任何html文件或字符串都转化为了<strong>utf-8编码</strong></p>
<h3 id="信息标记">信息标记</h3>
<p>信息标记的三种形式：</p>
<ul>
<li>
<p>XML（eXtensible Markup Language）：采取了以标签为主，来构建信息表达信息的方式（XML是HTML发展以来的一种通用信息表达形式）</p>
<ul>
<li>在标签中具有名字、属性，与HTML类似：<code>&lt;img src=&quot;china,jpg&quot; size=&quot;10&quot;&gt;...&lt;/img&gt;</code></li>
<li>如果标签中没有内容，可以采用缩写形式：<code>&lt;img src=&quot;china,jpg&quot; size=&quot;10&quot; /&gt;</code></li>
<li>可以嵌入注释：<code>&lt;!--This is acomment, very useful --&gt;</code></li>
</ul>
</li>
<li>
<p>JSON（JavsScript Object Notation）：有类型的键值对构建的信息表达方式</p>
<ul>
<li>规定：
<ul>
<li>键：对信息类型进行定义</li>
<li>值：对信息值的描述</li>
<li>键值对具有数据类型：无论是键还是值，均需要通过<code>&quot;</code>来表示字符串</li>
<li>当值中有多个信息的时候，采用<code>[,]</code>形式来组织：<code>&quot;name&quot;:[&quot;北京&quot;,&quot;延安&quot;]</code></li>
<li>键值对之间可以嵌套使用，嵌套时采用<code>&#123;,&#125;</code>书写：<code>&quot;name&quot;:&#123;&quot;oldname&quot;:&quot;北京&quot;,&quot;newname&quot;:&quot;延安&quot;&#125;</code></li>
</ul>
</li>
<li>好处：
<ul>
<li>对于JavaScript等编程语言来说，可以直接将JSON作为程序的一部分</li>
</ul>
</li>
</ul>
</li>
<li>
<p>YAML（YAML Aint Markup Language）：采用无类型键值对，在键值之间不采用任何双引号或相关的类型标记</p>
<ul>
<li>
<p>没有数据类型：<code>name:北京</code></p>
</li>
<li>
<p>可以通过缩进的关系表达所属关系</p>
</li>
<li>
<p>用<code>-</code>表达并联关系</p>
</li>
<li>
<p>用<code>|</code>表示整块数据</p>
</li>
<li>
<p>用<code>#</code>表示注释</p>
  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">key :</span> <span class="string">value</span></span><br><span class="line"><span class="attr">key :</span> <span class="comment">#Comment</span></span><br><span class="line"><span class="string">-value1</span></span><br><span class="line"><span class="string">-value2</span></span><br><span class="line"><span class="attr">key :</span></span><br><span class="line">    <span class="attr">dubkey :</span> <span class="string">subvalue</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>对比：</p>
<ul>
<li>XML最早的通用信息标记语言,可扩展性好,但繁琐.
<ul>
<li>Internet上的信息交互和传递</li>
</ul>
</li>
<li>JSON信息有类型,适合程序处理(js),较XML简洁.
<ul>
<li>移动应用云端和节点的信息通信,无注释.</li>
</ul>
</li>
<li>YAML信息无类型,文本信息比例最高,可读性好.
<ul>
<li>各类系统的配置文件,有注释易读.</li>
</ul>
</li>
</ul>
<p>信息提取的一般方法：</p>
<ul>
<li>完成解析信息的标记形式，再提取关键信息
<ul>
<li>优点：信息解析准确</li>
<li>缺点：提取过程繁琐，速度慢</li>
</ul>
</li>
<li>无视标记形式,直接搜索关键信息
<ul>
<li>优点:提取过程简洁,速度较快.</li>
<li>缺点:提取结果准确性与信息內容相关</li>
</ul>
</li>
<li>融合方法:结合形式解析与搜索方法,提取关键信息</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#融合方法:先查找a的标签 再解析</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;a&#x27;</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(link.get(<span class="string">&#x27;href&#x27;</span>))</span><br><span class="line">...</span><br><span class="line">http://www.icourse163.org/course/BIT-<span class="number">268001</span></span><br><span class="line">http://www.icourse163.org/course/BIT-<span class="number">1001870001</span></span><br></pre></td></tr></table></figure>
<h3 id="内容查找">内容查找</h3>
<p>基本方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;&gt;.find_all(name,attrs,recursive,string,**kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>返回值：列表，储存查取结果</li>
<li>name：对标签名称的检索字符串，如果为True则输出所有标签信息，可以使用正则表达式</li>
<li>attrs：对标签属性值的检索字符串，可标注属性检索，只能够精确查找，否则需要正则表达式</li>
<li>recursive：是否对子孙所有节点进行检索，默认True</li>
<li>string：&lt;&gt;…&lt;/&gt;中字符串区域的检索字符串，只能够精确查找，否则需要正则表达式</li>
</ul>
<p>注意，由于find_all方法常用，可以简写为：</p>
<ul>
<li><code>&lt;tag&gt;.find_all(...)</code>等价于<code>&lt;tag&gt;(...)</code></li>
<li><code>soup.find_all(...)</code>等价于<code>soup(...)</code></li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://python123.io/ws/demo.html&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="comment">#name</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">[&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt;, &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>])</span><br><span class="line">[&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;, &lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt;, &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(<span class="literal">True</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(tag.name)</span><br><span class="line">...</span><br><span class="line">html</span><br><span class="line">head</span><br><span class="line">title</span><br><span class="line">body</span><br><span class="line">p</span><br><span class="line">b</span><br><span class="line">p</span><br><span class="line">a</span><br><span class="line">a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.<span class="built_in">compile</span>(<span class="string">&#x27;b&#x27;</span>)):<span class="comment">#使用正则</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(tag.name)</span><br><span class="line">...</span><br><span class="line">body</span><br><span class="line">b</span><br><span class="line"><span class="comment">#attrs</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">&#x27;p&#x27;</span>,<span class="string">&#x27;course&#x27;</span>)<span class="comment">#检索p标签中带有course属性值的标签</span></span><br><span class="line">[&lt;p <span class="keyword">class</span>=<span class="string">&quot;course&quot;</span>&gt;Python <span class="keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="keyword">from</span> novice to professional by tracking the following courses:</span><br><span class="line">&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt; <span class="keyword">and</span> &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="built_in">id</span>=<span class="string">&#x27;link1&#x27;</span>)<span class="comment">#属性域中id=&#x27;link1&#x27;的标签  精确查找</span></span><br><span class="line">[&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="built_in">id</span>=<span class="string">&#x27;link&#x27;</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="built_in">id</span>=re.<span class="built_in">compile</span>(<span class="string">&#x27;link&#x27;</span>))<span class="comment">#正则</span></span><br><span class="line">[&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt;, &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="comment">#recursive</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">[&lt;a <span class="keyword">class</span>=<span class="string">&quot;py1&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-268001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>&gt;Basic Python&lt;/a&gt;, &lt;a <span class="keyword">class</span>=<span class="string">&quot;py2&quot;</span> href=<span class="string">&quot;http://www.icourse163.org/course/BIT-1001870001&quot;</span> <span class="built_in">id</span>=<span class="string">&quot;link2&quot;</span>&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">&#x27;a&#x27;</span>,recursive=<span class="literal">False</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="comment">#string</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string = <span class="string">&quot;Basic Python&quot;</span>)<span class="comment">#精确</span></span><br><span class="line">[<span class="string">&#x27;Basic Python&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string = re.<span class="built_in">compile</span>(<span class="string">&quot;python&quot;</span>))<span class="comment">#正则</span></span><br><span class="line">[<span class="string">&#x27;This is a python demo page&#x27;</span>, <span class="string">&#x27;The demo python introduces several python courses.&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>扩展方法（与find_all的参数一样）：</p>
<ul>
<li><code>&lt;&gt;.find()</code>：搜索且只返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_parents()</code>：在先辈节点中搜索,返回列表类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_parent()</code>：在先辈节点中返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_next_siblings()</code>：在后续平行节点中搜索,返回列表类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_next_sibling()</code>：在后续平行节点中返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_previous_siblings()</code>：在前序平行节点中搜索,返回列表类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_previous_sibling()</code>：在前序平行节点中返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
</ul>
<h3 id="实例-4">实例</h3>
<p>中国大学排名定向爬虫</p>
<p>定向爬虫：仅对输入URL进行爬取,不扩展爬取.</p>
<p>爬取网页：<a target="_blank" rel="noopener" href="http://www.zuihaodaxue.com/BCSR/xinxiyutongxingongcheng2019.html">http://www.zuihaodaxue.com/BCSR/xinxiyutongxingongcheng2019.html</a>，且没有robots.txt文件</p>
<p>部分html代码：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tbody</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span> <span class="attr">class</span>=<span class="string">&quot;bgfd&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">&quot;ranking&quot;</span>&gt;</span>1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">&quot;ranking&quot;</span>&gt;</span>1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">&quot;align-center&quot;</span>&gt;</span>前1%<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">&quot;align-left&quot;</span>&gt;</span>清华大学<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;../houtai/templates/images/subject/bo1.png&quot;</span> <span class="attr">title</span>=<span class="string">&quot;一级学科博士学位授权点&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;../houtai/templates/images/subject/zhong1.png&quot;</span> <span class="attr">title</span>=<span class="string">&quot;一级学科国家重点学科&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>1219<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout = <span class="number">30</span>)<span class="comment">#30s</span></span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fillUnivList</span>(<span class="params">ulist, html</span>):</span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">&#x27;tbody&#x27;</span>).children:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(tr,bs4.element.Tag):</span><br><span class="line">            tds = tr(<span class="string">&#x27;td&#x27;</span>)<span class="comment">#tr.find_all(&#x27;td&#x27;)简写</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">3</span>].string, tds[<span class="number">6</span>].string])<span class="comment">#大学排名 大学名称 大学总分</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">printUnivList</span>(<span class="params">ulist, num</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;排名&quot;</span>,<span class="string">&quot;名称&quot;</span>,<span class="string">&quot;总分&quot;</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;&quot;</span>.<span class="built_in">format</span>(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">&#x27;http://www.zuihaodaxue.com/BCSR/xinxiyutongxingongcheng2019.html&#x27;</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>)<span class="comment">#只列出前20组</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>上述代码中，由于format输出过程中，采用英文空格填充，因为中英文间距宽度不同，所以会使得结果不会居中</p>
</li>
<li>
<p>为解决居中问题，可以将默认的填充字符由英文空格换成中文空格<code>ch(12288)</code>即可</p>
</li>
<li>
<p>修改后的<code>printUnivList</code>函数：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">printUnivList</span>(<span class="params">ulist, num</span>):</span><br><span class="line">    tplt = <span class="string">&quot;&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;&quot;</span><span class="comment">#&#123;3&#125;是采用第三个参数，即中文空格chr(12288)</span></span><br><span class="line">    <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(<span class="string">&quot;排名&quot;</span>,<span class="string">&quot;名称&quot;</span>,<span class="string">&quot;总分&quot;</span>,<span class="built_in">chr</span>(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>],<span class="built_in">chr</span>(<span class="number">12288</span>)))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="正则表达式库">正则表达式库</h2>
<ul>
<li>通用的字符串表达框架</li>
<li>用来<strong>简洁</strong>的表达一组字符串的表达式</li>
<li>是字符串表达”简洁“和”特征“思想的工具</li>
<li>判断某字符串的特征归属</li>
</ul>
<p>正则表达式是由<strong>字符</strong>和<strong>操作符</strong>构成的</p>
<h3 id="操作符">操作符</h3>
<table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.</td>
<td style="text-align:center">表示任何单个字符</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">[]</td>
<td style="text-align:center">字符集，对单个字符给出取值范围</td>
<td style="text-align:center">[abc]表示a、b、c，[a-z]表示a到z单个字符</td>
</tr>
<tr>
<td style="text-align:center">[^]</td>
<td style="text-align:center">非字符集，对单个字符给出排除范围</td>
<td style="text-align:center">[^abc]表示非a或b或c的单个字符</td>
</tr>
<tr>
<td style="text-align:center">*</td>
<td style="text-align:center">前一个字符0次或无限次扩展</td>
<td style="text-align:center">abc*表示ab、abc、abcc、abccc等</td>
</tr>
<tr>
<td style="text-align:center">+</td>
<td style="text-align:center">前一个字符1次或无限次扩展</td>
<td style="text-align:center">abc+表示abc、abcc、abccc等</td>
</tr>
<tr>
<td style="text-align:center">?</td>
<td style="text-align:center">前一个字符0次或1次扩展</td>
<td style="text-align:center">abc?表示abc、abcc、abccc等</td>
</tr>
<tr>
<td style="text-align:center">|</td>
<td style="text-align:center">左右表达式任意一个</td>
<td style="text-align:center">abc|def表示abc或者是def</td>
</tr>
<tr>
<td style="text-align:center">{m}</td>
<td style="text-align:center">扩展前一个字符m次</td>
<td style="text-align:center">ab{2}c表示abbc</td>
</tr>
<tr>
<td style="text-align:center">{m,n}</td>
<td style="text-align:center">扩展前一个字符m至n次（包含n）</td>
<td style="text-align:center">ab{1,2}c表示abc、abbc</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">匹配字符串开头</td>
<td style="text-align:center">^abc表示abc且在一个字符串的开头</td>
</tr>
<tr>
<td style="text-align:center">$</td>
<td style="text-align:center">匹配字符串结尾</td>
<td style="text-align:center">abc$表示abc且在一个字符串的结尾</td>
</tr>
<tr>
<td style="text-align:center">()</td>
<td style="text-align:center">分组标记，内部只能使用|操作符</td>
<td style="text-align:center">(abc)表示abc，(abc|def)表示abc或def</td>
</tr>
<tr>
<td style="text-align:center">\d</td>
<td style="text-align:center">数字，等价于[0-9]</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">\w</td>
<td style="text-align:center">单词字符，等价于[A-Za-z0-9_]</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h3 id="Match对象">Match对象</h3>
<p>一次匹配的结果，包含了很多匹配的相关信息，Match对象的具体类型为<code>re.Match</code></p>
<p>重要属性：</p>
<ul>
<li><code>.string</code>：待匹配的文本</li>
<li><code>.re</code>：匹配时使用的 pattern对象(即正则表达式)</li>
<li><code>.pos</code>：正则表达式搜索文本的开始位置</li>
<li><code>.endpos</code>：正则表达式搜索文本的结束位置</li>
</ul>
<p>常用方法：</p>
<ul>
<li><code>.group(0)</code>：获得匹配后的字符串</li>
<li><code>.start()</code>：匹配字符串在原始字符串的开始位置</li>
<li><code>.end()</code>：匹配字符串在原始字符串的结束位置</li>
<li><code>.span()</code>：返回(.start(), .end())</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = re.match(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;271035 TaiAn,WeiHai 264200&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.string</span><br><span class="line"><span class="string">&#x27;271035 TaiAn,WeiHai 264200&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.re</span><br><span class="line">re.<span class="built_in">compile</span>(<span class="string">&#x27;[1-9]\\d&#123;5&#125;&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.pos</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.endpos</span><br><span class="line"><span class="number">26</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;271035&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.start()</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.end()</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span()</span><br><span class="line">(<span class="number">0</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure>
<h3 id="相关函数-10">相关函数</h3>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.search()</td>
<td>在一个字符串中搜索匹配正则表达式的<strong>第一个位置</strong>,返回 match对象</td>
</tr>
<tr>
<td>re.match()</td>
<td>从一个字符串的<strong>开始位置起</strong>匹配正则表达式,返回 match对象</td>
</tr>
<tr>
<td>re.findall()</td>
<td>搜索字符串,以<strong>列表</strong>类型返回<strong>全部</strong>能匹配的子串</td>
</tr>
<tr>
<td>re.split()</td>
<td>将一个字符串按照正则表达式匹配结果进行<strong>分割</strong>,返回列表类型</td>
</tr>
<tr>
<td>re.finditer()</td>
<td>搜索字符串,返回一个匹配结果的<strong>迭代</strong>类型,每个迭代元素是 match对象</td>
</tr>
<tr>
<td>re.sub()</td>
<td>在一个字符串中<strong>替换</strong>所有匹配正则表达式的子串,返回替换后的字符串</td>
</tr>
</tbody>
</table>
<p>函数说明：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.search(pattern, string, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>在一个字符串中搜索匹配正则表达式的第一个位置，返回 match对象</p>
<ul>
<li>pattern：正则表达式的字符串或原生字符串表示
<ul>
<li>原生字符串（raw string）：即<code>r&quot;xxxx&quot;</code>类型字符串</li>
</ul>
</li>
<li>string：待匹配字符串</li>
<li>flags：正则表达式使用时的控制标记
<ul>
<li><code>re.I(re.IGNORECASE)</code>：<strong>忽略</strong>正则表达式的<strong>大小写</strong>，[A-Z]能够匹配小写字符</li>
<li><code>re.M(re.MULTILINE)</code>：正则表达式中的**^<strong>操作符能够将给定字符串的</strong>每行**当作匹配开始</li>
<li><code>re.S(re.DOTALL)</code>：正则表达式中的**.<strong>操作符能够匹配</strong>所有字符**（默认匹配<strong>除换行外</strong>的所有字符）</li>
</ul>
</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">match = re.search(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;TaiAn 271035,WeiHai 264200&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> match :</span><br><span class="line">    <span class="built_in">print</span>(match.group(<span class="number">0</span>))</span><br><span class="line"><span class="comment">#输出 271035</span></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.match(pattern, string, flags=<span class="number">0</span>) </span><br></pre></td></tr></table></figure>
<p>从一个字符串的开始位置起匹配正则表达式，返回match对象</p>
<ul>
<li>参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">re.match()从字符串的起始位置开始匹配，如果起始位置匹配不成功，则匹配失败</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">match = re.match(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;TaiAn 271035,WeiHai 264200&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> match :</span><br><span class="line">    <span class="built_in">print</span>(match.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(match))</span><br><span class="line"><span class="comment">#输出&lt;class &#x27;NoneType&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#匹配成功例子：</span></span><br><span class="line">match = re.match(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;271035 TaiAn,WeiHai 264200&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> match :</span><br><span class="line">    <span class="built_in">print</span>(match.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(match))</span><br><span class="line"><span class="comment">#输出 &#x27;271035&#x27;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(pattern, string, flags=<span class="number">0</span>) </span><br></pre></td></tr></table></figure>
<p>搜索字符串，以列表类型返回全部能匹配的子串</p>
<ul>
<li>参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">ls = re.findall(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;TaiAn 271035 WeiHai 264200 222222 115545&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> ls :</span><br><span class="line"> <span class="built_in">print</span>(ls)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"> <span class="built_in">print</span>(<span class="built_in">type</span>(ls))</span><br><span class="line"></span><br><span class="line"><span class="comment">#[&#x27;271035&#x27;, &#x27;264200&#x27;, &#x27;222222&#x27;, &#x27;115545&#x27;]</span></span><br></pre></td></tr></table></figure>
<p>注意：findall如果使用了<strong>分组</strong>，则输出的内容将是分组中的内容而非find到的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">xxx = <span class="string">&quot;a123ca456c&quot;</span></span><br><span class="line"></span><br><span class="line">ret = re.findall(<span class="string">r&quot;a(123|456)c&quot;</span>, xxx)</span><br><span class="line"><span class="built_in">print</span>(ret)</span><br><span class="line"><span class="comment">#[&#x27;123&#x27;, &#x27;456&#x27;]</span></span><br></pre></td></tr></table></figure>
<p>解决方法：</p>
<ul>
<li>加上问号来启用“不捕捉模式”</li>
<li>不用分组</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启用“不捕捉模式”</span></span><br><span class="line">ret = re.findall(<span class="string">r&quot;a(?:123|456)c&quot;</span>, xxx)</span><br><span class="line"><span class="comment">#不用分组</span></span><br><span class="line">ret = re.findall(<span class="string">r&quot;a123c|a456c&quot;</span>, xxx)</span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(pattern, string, maxsplit=<span class="number">0</span>, flags=<span class="number">0</span>) </span><br></pre></td></tr></table></figure>
<p>将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</p>
<ul>
<li>maxsplit：最大分割数，剩余部分作为最后一个元素输出</li>
<li>其余参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;TaiAn271035WeiHai264200wo222222nihao115545abc&#x27;</span>)</span><br><span class="line">[<span class="string">&#x27;TaiAn&#x27;</span>, <span class="string">&#x27;WeiHai&#x27;</span>, <span class="string">&#x27;wo&#x27;</span>, <span class="string">&#x27;nihao&#x27;</span>, <span class="string">&#x27;abc&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;TaiAn271035WeiHai264200wo222222nihao115545abc&#x27;</span>,maxsplit=<span class="number">2</span>)</span><br><span class="line">[<span class="string">&#x27;TaiAn&#x27;</span>, <span class="string">&#x27;WeiHai&#x27;</span>, <span class="string">&#x27;wo222222nihao115545abc&#x27;</span>]</span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.finditer(pattern, string, flags=<span class="number">0</span>) </span><br></pre></td></tr></table></figure>
<p>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是 match对象</p>
<ul>
<li>参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> m <span class="keyword">in</span> re.finditer(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;TaiAn271035WeiHai264200wo222222nihao115545abc&#x27;</span>) :</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> m:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(m.group(<span class="number">0</span>))</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="built_in">type</span>(m))</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="string">&quot;null&quot;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="number">271035</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;re.Match&#x27;</span>&gt;</span><br><span class="line"><span class="number">264200</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;re.Match&#x27;</span>&gt;</span><br><span class="line"><span class="number">222222</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;re.Match&#x27;</span>&gt;</span><br><span class="line"><span class="number">115545</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;re.Match&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(pattern, repl, string, count=<span class="number">0</span>, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>用一个新的字符串替换所有匹配正则表达式的子串，返回替换后的字符串</p>
<ul>
<li>repl：替换匹配字符串的字符串</li>
<li>count：匹配的最大替换次数</li>
<li>其余参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.sub(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;隐藏邮政编码&#x27;</span>,<span class="string">&#x27;TaiAn271035WeiHai264200wo222222nihao115545abc&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;TaiAn隐藏邮政编码WeiHai隐藏邮政编码wo隐藏邮政编码nihao隐藏邮政编码abc&#x27;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="等价用法">等价用法</h3>
<ul>
<li>
<p>函数式用法：一次性操作</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rst = re.search(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>,<span class="string">&#x27;BIT 100081&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>面向对象用法：编译后的多次操作（能够加快程序运行速度）</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pat = re.<span class="built_in">compile</span>(<span class="string">r&#x27;[1-9]\d&#123;5&#125;&#x27;</span>)</span><br><span class="line">rst = pat.search(<span class="string">&#x27;BIT 100081&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>compile函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regex = re.<span class="built_in">compile</span>(pattern, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>将正则表达式的字符串形式编译成正则表达式对象</p>
<ul>
<li>pattern：正则表达式的字符串或原生字符串表示</li>
<li>flags：正则表达式使用时的控制标记</li>
</ul>
<p>注意：这里regex才是正则表达式（对象），代表了一组字符串。同时regex对象也含有上述re库提供的的六个方法，但是需要将方法中的<code>pattern</code>参数去除</p>
<h3 id="贪婪匹配和最小匹配">贪婪匹配和最小匹配</h3>
<p>Re库<strong>默认</strong>釆用贪婪匹配，即输出匹配<strong>最长</strong>的子串</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r&#x27;PY.*N&#x27;</span>,<span class="string">&#x27;PYANBNCNDN&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;PYANBNCNDN&#x27;</span></span><br></pre></td></tr></table></figure>
<p>最小匹配：输出匹配<strong>最短</strong>的子串，具体方法为 在匹配不同长度的操作符后 加个<code>?</code>即可</p>
<p>具体扩展的操作符：</p>
<table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">*?</td>
<td style="text-align:center">前一个字符0次或无限次扩展,最小匹配</td>
</tr>
<tr>
<td style="text-align:center">+?</td>
<td style="text-align:center">前一个字符1次或无限次扩展,最小匹配</td>
</tr>
<tr>
<td style="text-align:center">??</td>
<td style="text-align:center">前一个字符0次或1次扩展,最小匹配</td>
</tr>
<tr>
<td style="text-align:center">{m,n}?</td>
<td style="text-align:center">扩展前一个字符m至n次(含n),最小匹配</td>
</tr>
</tbody>
</table>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r&#x27;PY.*?N&#x27;</span>,<span class="string">&#x27;PYANBNCNDN&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;PYAN&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="实例-5">实例</h3>
<p>淘宝商品价格爬取</p>
<p>搜索接口：<a target="_blank" rel="noopener" href="https://s.taobao.com/search?q=%E7%AF%AE%E7%90%83">https://s.taobao.com/search?q=篮球</a><br>
翻页接口：第二页 <a target="_blank" rel="noopener" href="https://s.taobao.com/search?q=%E7%AF%AE%E7%90%83&amp;s=44">https://s.taobao.com/search?q=篮球&amp;s=44</a><br>
第三页 <a target="_blank" rel="noopener" href="https://s.taobao.com/search?q=%E7%AF%AE%E7%90%83&amp;s=88">https://s.taobao.com/search?q=篮球&amp;s=88</a></p>
<p>用爬虫爬淘宝，得到的页面是登录页面，想要跳过这个页面，需要提前在浏览器中登录淘宝，并获取hearders信息（关键是<strong>cookie</strong>和User-Agent）用于模拟用户登录，并作为参数传给requests.get(url,headers = header)，获取方法如下：</p>
<p>首先登陆淘宝账号，然后按 F12 进入检查，在上面的 network 的第一行中拖到最后，找到最上方以search？开头的一栏，右键 Copy–&gt;Copy as URL(bash)，然后打开这个网站： <a target="_blank" rel="noopener" href="https://curl.trillworks.com/">https://curl.trillworks.com/</a> 在里面把复制的内容放进去，选择 Python 然后会发现右边有一个 headers:{省略…}，把这个 headers 放进代码，用一个变量储存，然后在代码中的r equest.get(url,headers=你刚才复制的内容，也就是那个变量）,这个时候你再请求 request.text 返回的就是你要的页面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHtmlText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        header =  &#123;</span><br><span class="line">    <span class="string">&#x27;authority&#x27;</span>: <span class="string">&#x27;s.taobao.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;pragma&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cache-control&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;upgrade-insecure-requests&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: ,</span><br><span class="line">    <span class="string">&#x27;accept-encoding&#x27;</span>: <span class="string">&#x27;gzip, deflate, br&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cookie&#x27;</span>: ,</span><br><span class="line">&#125;<span class="comment">#隐去了cookie信息和referer信息</span></span><br><span class="line">        r = requests.get(url,headers = header)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;爬取失败&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parsePage</span>(<span class="params">ilist,html</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        plt = re.findall(<span class="string">r&#x27;\&quot;view_price\&quot;:\&quot;\d+\.\d*\&quot;&#x27;</span>,html)</span><br><span class="line">        tlt = re.findall(<span class="string">r&#x27;\&quot;raw_title\&quot;:\&quot;.*?\&quot;&#x27;</span>,html)</span><br><span class="line">        <span class="comment">#print(tlt)</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(plt))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(plt)):</span><br><span class="line">            price = <span class="built_in">eval</span>(plt[i].split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">3</span>])  <span class="comment"># eval：去掉双引号或单引号</span></span><br><span class="line">            title = tlt[i].split(<span class="string">&#x27;\&quot;&#x27;</span>)[<span class="number">3</span>]  <span class="comment"># 防止名字中出现:</span></span><br><span class="line">            ilist.append([title,price])</span><br><span class="line">        <span class="comment">#print(ilist)</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;解析出错&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">printGoodsList</span>(<span class="params">ilist,num</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=====================================================================================================&quot;</span>)</span><br><span class="line">    tplt = <span class="string">&quot;&#123;0:&lt;3&#125;\t&#123;1:&lt;30&#125;\t&#123;2:&gt;6&#125;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(<span class="string">&quot;序号&quot;</span>,<span class="string">&quot;商品名称&quot;</span>,<span class="string">&quot;价格&quot;</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> ilist:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> count &lt;= num:   </span><br><span class="line">            <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(count,g[<span class="number">0</span>],g[<span class="number">1</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=====================================================================================================&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    goods = <span class="string">&quot;篮球&quot;</span></span><br><span class="line">    depth = <span class="number">1</span></span><br><span class="line">    start_url = <span class="string">&quot;https://s.taobao.com/search?q=&quot;</span>+goods</span><br><span class="line">    infoList = []</span><br><span class="line">    num = <span class="number">20</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = start_url + <span class="string">&#x27;$S=&#x27;</span> + <span class="built_in">str</span>(<span class="number">44</span>*i)</span><br><span class="line">            html = getHtmlText(url)</span><br><span class="line">            parsePage(infoList,html)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    printGoodsList(infoList,num)</span><br><span class="line">    </span><br><span class="line">main() </span><br></pre></td></tr></table></figure>
<p>股票数据定向爬取：</p>
<p>步骤1：从中财网http://quote.cfi.cn/stockList.aspx获取股票列表</p>
<p>步骤2：根据股票列表获取股票的url，通过每个url获取股票信息</p>
<p>步骤3：将结果保存到文件中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#股票数据定向爬虫</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"> </span><br><span class="line"><span class="comment">#函数功能：原始数据爬取</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHtmlText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="comment">#r.encoding = r.apparent_encoding</span></span><br><span class="line">        r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        <span class="comment">#print(r.text[-500:])</span></span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        traceback.print_exc()</span><br><span class="line"> </span><br><span class="line">        </span><br><span class="line"><span class="comment">#函数功能：获取股票列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getStockList</span>(<span class="params">lst,stockListURL</span>):</span><br><span class="line">    ra = [<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>]</span><br><span class="line">    <span class="comment">#ra = [11]</span></span><br><span class="line">    count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ra:</span><br><span class="line">        stock_list_html = getHtmlText(stockListURL+<span class="built_in">str</span>(i))</span><br><span class="line">        soup = BeautifulSoup(stock_list_html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">        a = soup.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">            <span class="keyword">try</span> :</span><br><span class="line">                href = i.attrs[<span class="string">&quot;href&quot;</span>]</span><br><span class="line">                stock_a = re.search(<span class="string">r&#x27;\d&#123;6&#125;.html$&#x27;</span>,href)</span><br><span class="line">                <span class="keyword">if</span> stock_a:</span><br><span class="line">                    count += <span class="number">1</span></span><br><span class="line">                    lst.append(stock_a.group(<span class="number">0</span>))</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                traceback.print_exc()</span><br><span class="line">    <span class="keyword">return</span> count    </span><br><span class="line"> </span><br><span class="line"><span class="comment">#函数功能：进入每个股票的链接，爬取对应股票的相关信息               </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getStockInfo</span>(<span class="params">lis,stockInfoURL,fpath,count</span>):</span><br><span class="line">    ready_count = <span class="number">0</span></span><br><span class="line">    f = <span class="built_in">open</span>(fpath,<span class="string">&#x27;a&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> lis[:<span class="number">100</span>]:</span><br><span class="line">        stock_info_html = getHtmlText(stockInfoURL+<span class="built_in">str</span>(j))</span><br><span class="line">        <span class="comment">#print(stock_info_html)</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> stock_info_html == <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment">#每个股票存为字典，数据处理较麻烦，有些数据有“杂音”，需单独给出if判断，或在正则中约束</span></span><br><span class="line">            infoDict = &#123; &#125;</span><br><span class="line">            soup = BeautifulSoup(stock_info_html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">            stockInfo = soup.find(<span class="string">&#x27;div&#x27;</span>,attrs=&#123;<span class="string">&#x27;id&#x27;</span>:<span class="string">&#x27;act_quote&#x27;</span>&#125;)</span><br><span class="line">            name = stockInfo.find(<span class="string">&#x27;div&#x27;</span>,attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;Lfont&#x27;</span>&#125;).string</span><br><span class="line">            <span class="comment">#print(name)</span></span><br><span class="line">            infoDict.update(&#123;<span class="string">&#x27;股票名称&#x27;</span>: name&#125;)</span><br><span class="line">            stockDetialInfo = stockInfo.find(<span class="string">&#x27;table&#x27;</span>,attrs=&#123;<span class="string">&#x27;id&#x27;</span>:<span class="string">&#x27;quotetab_stock&#x27;</span>&#125;)</span><br><span class="line">            td = stockDetialInfo.find_all(<span class="string">&quot;td&quot;</span>)</span><br><span class="line">            <span class="comment">#print(td)</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> td:</span><br><span class="line">                <span class="comment">#print(item.get_text())</span></span><br><span class="line">                text= item.get_text()</span><br><span class="line">                <span class="keyword">if</span>(text==<span class="string">&quot;业绩预告&quot;</span>):</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;hear&quot;</span>)</span><br><span class="line">                    key = <span class="string">&quot;业绩预告&quot;</span></span><br><span class="line">                    real_val = <span class="string">&quot;业绩预告&quot;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    text_split = re.split(<span class="string">&#x27;:|：&#x27;</span>,text)<span class="comment">#网站程序员分号用了中文和英文两种……</span></span><br><span class="line">                    key = text_split[<span class="number">0</span>]</span><br><span class="line">                    val = text_split[<span class="number">1</span>]</span><br><span class="line">                    real_val = re.search(<span class="string">r&#x27;(-?\d+.?\d*[%|手|万|元]?)|(--)|(正无穷大)&#x27;</span>,val).group(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                infoDict[key] = real_val</span><br><span class="line">            f.write(<span class="built_in">str</span>(infoDict)+<span class="string">&#x27;\n&#x27;</span>) <span class="comment">#每个股票字典数据转为字符串写入文件</span></span><br><span class="line">            ready_count += <span class="number">1</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;\r当前第&#123;0:&#125;个,共&#123;1:&#125;个&#x27;</span>.<span class="built_in">format</span>(ready_count,count)) <span class="comment">#打印进度</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;\r当前第&#123;0:&#125;个,共&#123;1:&#125;个&#x27;</span>.<span class="built_in">format</span>(ready_count,count))</span><br><span class="line">            traceback.print_exc()</span><br><span class="line">    f.close()</span><br><span class="line">   </span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    lst = []</span><br><span class="line">    stock_list_url = <span class="string">&quot;http://quote.cfi.cn/stockList.aspx?t=&quot;</span> <span class="comment">#股票列表，翻页接口</span></span><br><span class="line">    stock_info_url = <span class="string">&quot;http://quote.cfi.cn/&quot;</span>                  <span class="comment">#每个股票的链接都是http://quote.cfi.cn/000000.html的形式。000000代表六位的股票代码</span></span><br><span class="line">    output_path = <span class="string">&quot;D:\ArticleForProgram\PythonProgram\Spider\StockInfo.txt&quot;</span> <span class="comment">#改成自己的</span></span><br><span class="line">    stock_count = getStockList(lst,stock_list_url)</span><br><span class="line">    getStockInfo(lst,stock_info_url,output_path,stock_count)</span><br><span class="line"> </span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h2 id="Scrapy框架">Scrapy框架</h2>
<p>安装scrapy：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br><span class="line">scrapy -h</span><br></pre></td></tr></table></figure>
<p>框架：</p>
<p><img src="/2020/02/18/python%E7%88%AC%E8%99%AB/image-20200224175001094.png" alt="总体框架图"></p>
<p>Engine模块（无需修改）：</p>
<ul>
<li>控制所有模块之间的数据流</li>
<li>根据条件触发事件</li>
</ul>
<p>Download模块（无需修改）：</p>
<ul>
<li>根据用户请求下载网页</li>
</ul>
<p>Scheduler模块（无需修改）：</p>
<ul>
<li>对所有爬取请求进行调度管理</li>
</ul>
<p>Downloader Middleware中间件（一般无需修改）：</p>
<ul>
<li>实施 Engine、 Scheduler和 Downloader之间进行用户可配置的控制</li>
<li>用户可以通过该中间件的编写来修改、丢弃、新增请求或响应</li>
</ul>
<p><strong>Spider模块</strong>：</p>
<ul>
<li>解析 Downloader返回的响应( Response)</li>
<li>产生爬取项( scraped item)</li>
<li>产生额外的爬取请求( Request)</li>
</ul>
<p><strong>Item Pipelines模块</strong>：</p>
<ul>
<li>以流水线方式处理 Spider产生的爬取项.</li>
<li>由一组操作顺序组成,类似流水线,每个操作是一个Item Pipeline类型.</li>
<li>可能操作包括:清理、检验和查重爬取项中的HTML数据、将数据存储到数据库.</li>
</ul>
<p>Spider Middleware中间件：</p>
<ul>
<li>对请求和肥取项的再处理</li>
<li>功能包括修改、丢弃、新增请求或爬取项</li>
</ul>
<h3 id="和request库的比较">和request库的比较</h3>
<p>相同点：</p>
<ul>
<li>两者都可以进行页面请求和肥取, Python肥吧虫的两个重要技术路线.</li>
<li>两者可用性都好,文档丰富,入门简单.</li>
<li>两者都没有处理js、提交表单、应对验证码等功能(可扩展).</li>
</ul>
<p>不同点：</p>
<table>
<thead>
<tr>
<th style="text-align:center">request</th>
<th style="text-align:center">Scrapy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">页面级爬虫</td>
<td style="text-align:center">网站级爬虫</td>
</tr>
<tr>
<td style="text-align:center">功能库</td>
<td style="text-align:center">框架</td>
</tr>
<tr>
<td style="text-align:center">并发性考虑不足,性能较差</td>
<td style="text-align:center">并发性好,性能较高</td>
</tr>
<tr>
<td style="text-align:center">重点在于页面下载</td>
<td style="text-align:center">重点在于爬虫结构</td>
</tr>
<tr>
<td style="text-align:center">定制灵活</td>
<td style="text-align:center">一般定制灵活,深度定制困难</td>
</tr>
<tr>
<td style="text-align:center">上手十分简单</td>
<td style="text-align:center">入门稍难</td>
</tr>
</tbody>
</table>
<h3 id="常用命令-2">常用命令</h3>
<p>Scrapy是为持续运行设计的专业爬虫框架，提供操作的Scrap命令行，其格式为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy &lt;<span class="built_in">command</span>&gt; [options] [args]</span><br></pre></td></tr></table></figure>
<p>常用命令（command）</p>
<table>
<thead>
<tr>
<th style="text-align:center">命令</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">格式</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>startproject</strong></td>
<td style="text-align:center">创建一个新工程</td>
<td style="text-align:center">scrapy startproject <name> [dir]</name></td>
</tr>
<tr>
<td style="text-align:center"><strong>genspider</strong></td>
<td style="text-align:center">创建一个爬虫</td>
<td style="text-align:center">scrapy genspider [options] <name> [domain]</name></td>
</tr>
<tr>
<td style="text-align:center">settings</td>
<td style="text-align:center">获得爬虫配置信息</td>
<td style="text-align:center">scrapy settings [options]</td>
</tr>
<tr>
<td style="text-align:center"><strong>crawl</strong></td>
<td style="text-align:center">运行一个爬虫</td>
<td style="text-align:center">scrapy crawl <spider></spider></td>
</tr>
<tr>
<td style="text-align:center">list</td>
<td style="text-align:center">列出工程中所有爬虫</td>
<td style="text-align:center">scrapy list</td>
</tr>
<tr>
<td style="text-align:center">shell</td>
<td style="text-align:center">启动URL调试命令行</td>
<td style="text-align:center">scrapy shell <url></url></td>
</tr>
</tbody>
</table>
<h3 id="步骤">步骤</h3>
<h4 id="创建工程">创建工程</h4>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject demo</span><br></pre></td></tr></table></figure>
<p>会产生如下文件：</p>
<ul>
<li>demo/：外层目录
<ul>
<li>scrapy.cfg：部署 Scrap爬虫的配置文件（服务器上用，本地无需）</li>
<li>demo/：Scrap框架的用户自定义 Python代码
<ul>
<li>__init__.py：初始化脚本</li>
<li><a target="_blank" rel="noopener" href="http://items.py">items.py</a>：Items代码模板(继承类)</li>
<li><a target="_blank" rel="noopener" href="http://middlewares.py">middlewares.py</a>：Middlewares代码模板(继承类)</li>
<li><a target="_blank" rel="noopener" href="http://pipelines.py">pipelines.py</a>：Pipelines代码模板(继承类)</li>
<li>settings：Scrap爬虫的配置文件</li>
<li>spiders/：Spiders代码模板目录(继承类)
<ul>
<li>__pycache__/：缓存目录,无需修改</li>
<li>__init__.py：初始化脚本</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="产生爬虫">产生爬虫</h4>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> </span><br><span class="line">scrapy genspider demopython123 python123.io<span class="comment">#名字 网站</span></span><br></pre></td></tr></table></figure>
<p>注意：爬虫名字不能和工程同名</p>
<p>会在<code>demo\demo\spiders\</code>下增加<code>demopython123.py</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Demopython123Spider</span>(scrapy.Spider):<span class="comment">#必须继承自scrapy.Spider</span></span><br><span class="line">    name = <span class="string">&#x27;demopython123&#x27;</span><span class="comment">#爬虫名字</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;python123.io&#x27;</span>]<span class="comment">#要爬取的域名</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://python123.io/&#x27;</span>]<span class="comment">#框架要爬取的初始页面</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>parse()</code>用于处理响应,解析内容形成字典,发现新的URL爬取请求</li>
</ul>
<h4 id="配置爬虫">配置爬虫</h4>
<p>修改<code>demopython123.py</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Demopython123Spider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;demopython123&#x27;</span></span><br><span class="line">    <span class="comment">#allowed_domains = [&#x27;python123.io&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span>]<span class="comment">#需要爬取的页面</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#response：从网络中返回内容所存储的或对应的对象</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):<span class="comment">#爬取功能</span></span><br><span class="line">        fname = response.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fname,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        sele.log(<span class="string">&#x27;Save file %s.&#x27;</span> % fname)</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h4 id="运行爬虫">运行爬虫</h4>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl demopython123</span><br></pre></td></tr></table></figure>
<p>捕获页面最终会在<code>\demo\demo.html</code>处</p>
<p>但是实际上，生成的<code>demopython123.py</code>文件是简化版，完整版的如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Demopython123Spider</span>(scrapy.Spider):<span class="comment">#必须继承自scrapy.Spider</span></span><br><span class="line">    name = <span class="string">&#x27;demopython123&#x27;</span><span class="comment">#爬虫名字</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_request</span>(<span class="params">self</span>):</span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">&#x27;http://python123.io/ws/demo.html&#x27;</span></span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>完整版和简化版的区别就在于将简化版中的start_urls变量改为了利用<code>yield</code>生成器的函数start_request</p>
<h3 id="Scrap爬虫的使用步骤">Scrap爬虫的使用步骤</h3>
<ul>
<li>步骤1:创建一个工程和 Spider模板</li>
<li>步骤2:编写 Spider</li>
<li>步骤3:编写 Item Pipeline</li>
<li>步骤4:优化配置策略</li>
</ul>
<p>涉及到的类：</p>
<ul>
<li>Request类：向网络上提交请求的内容</li>
<li>Response类：从网络中爬取内容的封装类</li>
<li>Item类：由Spider产生的信息而封装的类</li>
</ul>
<h4 id="Request类">Request类</h4>
<p>class scrapy.http.Request()</p>
<ul>
<li>表示一个Request对象</li>
<li>由 Spider生成,由 Downloader执行.</li>
</ul>
<p>属性或方法：</p>
<table>
<thead>
<tr>
<th style="text-align:center">属性或方法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.url</td>
<td style="text-align:center">Request对应的请求URL地址</td>
</tr>
<tr>
<td style="text-align:center">.method</td>
<td style="text-align:center">对应的请求方法，‘GET’、'POST’等</td>
</tr>
<tr>
<td style="text-align:center">.headers</td>
<td style="text-align:center">字典类型风格的请求头</td>
</tr>
<tr>
<td style="text-align:center">.body</td>
<td style="text-align:center">请求内容主体，字符串类型</td>
</tr>
<tr>
<td style="text-align:center">.meta</td>
<td style="text-align:center">用户添加的扩展信息，在 Scrapy内部模块间传递信息使用</td>
</tr>
<tr>
<td style="text-align:center">.copy()</td>
<td style="text-align:center">复制该请求</td>
</tr>
</tbody>
</table>
<h4 id="Response类">Response类</h4>
<p>class scrapy.http.Response()</p>
<ul>
<li>Response对象表示一个HTTP响应</li>
<li>由 Downloader生成,由 Spider处理</li>
</ul>
<p>属性或方法：</p>
<table>
<thead>
<tr>
<th style="text-align:center">属性或方法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.url</td>
<td style="text-align:center">Response对应的请求URL地址</td>
</tr>
<tr>
<td style="text-align:center">.status</td>
<td style="text-align:center">HTTP状态码，默认是200</td>
</tr>
<tr>
<td style="text-align:center">.headers</td>
<td style="text-align:center">Response对应的头部信息</td>
</tr>
<tr>
<td style="text-align:center">.body</td>
<td style="text-align:center">Response对应的内容信息，字符串类型</td>
</tr>
<tr>
<td style="text-align:center">.flags</td>
<td style="text-align:center">一组标记</td>
</tr>
<tr>
<td style="text-align:center">.request</td>
<td style="text-align:center">产生 Response类型对应的 Request对象</td>
</tr>
<tr>
<td style="text-align:center">.copy()</td>
<td style="text-align:center">复制该响应</td>
</tr>
</tbody>
</table>
<h4 id="Item类">Item类</h4>
<p>class scrapy.http.Item()</p>
<ul>
<li>Item对象表示一个从HTML页面中提取的信息内容</li>
<li>由 Spider生成,由 Item Pipeline处理</li>
<li>Item类似字典类型，可以按照字典类型操作</li>
</ul>
<p>Scrapy爬虫支持多种HTML信息提取方法：</p>
<ul>
<li>Beautiful Soup</li>
<li>Ixml</li>
<li>re</li>
<li>XPath Selector</li>
<li>CSS Selector</li>
</ul>
<h4 id="CSS-Selector基本使用">CSS Selector基本使用</h4>
<h3 id="例子-4">例子</h3>
<p>建立工程</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject BaiduStocks</span><br><span class="line"><span class="built_in">cd</span> BaiduStocks</span><br><span class="line">scrapy genspider stocks baidu.com</span><br></pre></td></tr></table></figure>
<p>修改<code>spiders\stocks.py</code>文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StocksSpider</span>(scrapy.Spider):<span class="comment">#必须继承自scrapy.Spider</span></span><br><span class="line">    name = <span class="string">&#x27;stocks&#x27;</span><span class="comment">#爬虫名字</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://quote.eastmoney.com/stocklist.html/&#x27;</span>]<span class="comment">#框架要爬取的初始页面</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">&#x27;a::attr(href)&#x27;</span>).extract():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                stock = re.findall(<span class="string">r&quot;[s][hz]\d&#123;6&#125;&quot;</span>,href)[<span class="number">0</span>]</span><br><span class="line">                url = <span class="string">&#x27;htps://gupiao.baidu.com/stock&#x27;</span> + stock + <span class="string">&#x27;.html&#x27;</span></span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse_stock)<span class="comment">#处理该url的回调函数</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_stock</span>(<span class="params">self, response</span>):</span><br><span class="line">        infoDict = &#123;&#125;</span><br><span class="line">        stockInfo = response.css(<span class="string">&#x27;.stock-bets&#x27;</span>)</span><br><span class="line">        name = stockInfo.css(<span class="string">&#x27;.bets-name&#x27;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        keyList = stockInfo.css(<span class="string">&#x27;dt&#x27;</span>).extract()</span><br><span class="line">        valueList = stockInfo.css(<span class="string">&#x27;dd&#x27;</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(keyList)):</span><br><span class="line">            key = re.findall(<span class="string">r&#x27;&gt;.*&lt;/dt&gt;&#x27;</span>, keyList[i])[<span class="number">0</span>][<span class="number">1</span>:-<span class="number">5</span>]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                val = re.findall(<span class="string">r&#x27;\d+\.?.*&lt;/dd&gt;&#x27;</span>, valueList[i])[<span class="number">0</span>][<span class="number">0</span>:-<span class="number">5</span>]</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                val = <span class="string">&#x27;--&#x27;</span></span><br><span class="line">            infoDict[key] = val</span><br><span class="line">        infoDict.update(</span><br><span class="line">            &#123;<span class="string">&#x27;股票名称&#x27;</span>: re.findall(<span class="string">r&#x27;\s.*\(&#x27;</span>, name)[<span class="number">0</span>].split()[<span class="number">0</span>] + \</span><br><span class="line">             re.findall(<span class="string">r&#x27;&gt;.*\&lt;&#x27;</span>, name)[<span class="number">0</span>][<span class="number">1</span>:-<span class="number">1</span>]&#125;)</span><br><span class="line">        <span class="keyword">yield</span> infoDict</span><br></pre></td></tr></table></figure>
<p>编写Pipelines</p>
<ul>
<li>配置pipelines.py文件</li>
<li>定义对爬取项（Scraped Item）的处理类</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaiduStocksPipeline</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaiduStocksInfoPipeline</span>(<span class="title class_ inherited__">object</span>):<span class="comment">#自己写的新的类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):<span class="comment">#爬虫被调用时对应的pipeline启动的方法</span></span><br><span class="line">        self.f = <span class="built_in">open</span>(<span class="string">&#x27;BaiduStocksInfo.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):<span class="comment">#爬虫关闭或结束时对应的pipeline方法</span></span><br><span class="line">        self.f.close()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):<span class="comment">#对每一个item项进行处理时对应的方法，pipeline中主体函数</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            line = <span class="built_in">str</span>(<span class="built_in">dict</span>(item)) + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">            self.f.write(line)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>将新的类让框架知道，<a target="_blank" rel="noopener" href="http://xn--settings-0n3mm27o.py">修改settings.py</a>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">&#x27; BaiduStocks.pipelines. BaiduStocksInfoPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;<span class="comment"># 修改该参数，由 BaiduStocks.pipelines. BaiduStocksPipeline 改为BaiduStocks.pipelines. BaiduStocksInfoPipeline</span></span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>执行程序：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl stocks</span><br></pre></td></tr></table></figure>
<p>优化：</p>
<p>settings.py文件提供如下配置：</p>
<table>
<thead>
<tr>
<th style="text-align:center">选项</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CONCURRENT_REQUESTS</td>
<td style="text-align:center">Downloader最大并发请求下载数量，默认32</td>
</tr>
<tr>
<td style="text-align:center">CONCURRENT_ITEMS</td>
<td style="text-align:center">Item Pipeline最大井发ITEM处理数量，默认100</td>
</tr>
<tr>
<td style="text-align:center">CONCURRENT_REQUESTS_PER_DOMAIN</td>
<td style="text-align:center">每个目标域名最大的并发请求数量，默认8</td>
</tr>
<tr>
<td style="text-align:center">CONCURRENT_ REQUESTS_PER_IP</td>
<td style="text-align:center">每个目标IP最大的并发请求数量，默认0，非0有效</td>
</tr>
</tbody>
</table>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">spaceman</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://nu-ll.github.io/2020/02/18/python%E7%88%AC%E8%99%AB/">http://nu-ll.github.io/2020/02/18/python爬虫/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://NU-LL.github.io" target="_blank">spaceman</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/NU-LL/image-host/raw/master/12.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/03/10/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA/"><img class="prev-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python数据分析与展示</div></div></a></div><div class="next-post pull-right"><a href="/2020/02/13/Mininet/"><img class="next-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Mininet</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/spaceman.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">spaceman</div><div class="author-info__description">CtrlC CtrlV大师</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">92</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/NU-LL"><i class="fab fa-github"></i><span>Github</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">白嫖一时爽，一直白嫖一直爽</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E5%90%91%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96%E5%92%8C%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90"><span class="toc-text">定向网络数据爬取和网页解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#get"><span class="toc-text">get</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E4%BB%A3%E7%A0%81%E6%A1%86%E6%9E%B6"><span class="toc-text">通用代码框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTTP%E5%8D%8F%E8%AE%AE%E5%8F%8Arequest%E5%BA%93%E6%96%B9%E6%B3%95"><span class="toc-text">HTTP协议及request库方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#HTTP%E5%8D%8F%E8%AE%AE"><span class="toc-text">HTTP协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#request%E5%BA%93%E6%96%B9%E6%B3%95"><span class="toc-text">request库方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Robots%E5%8D%8F%E8%AE%AE"><span class="toc-text">Robots协议</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%B5%E5%AE%88%E6%96%B9%E5%BC%8F"><span class="toc-text">遵守方式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B-3"><span class="toc-text">实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96"><span class="toc-text">网络爬虫与信息提取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BeautifulSoup%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%85%83%E7%B4%A0"><span class="toc-text">BeautifulSoup库的基本元素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTML%E9%81%8D%E5%8E%86"><span class="toc-text">HTML遍历</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTML%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%92%8C%E7%BC%96%E7%A0%81"><span class="toc-text">HTML格式化和编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E6%A0%87%E8%AE%B0"><span class="toc-text">信息标记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AE%B9%E6%9F%A5%E6%89%BE"><span class="toc-text">内容查找</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B-4"><span class="toc-text">实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%BA%93"><span class="toc-text">正则表达式库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%AC%A6"><span class="toc-text">操作符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Match%E5%AF%B9%E8%B1%A1"><span class="toc-text">Match对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0-10"><span class="toc-text">相关函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%89%E4%BB%B7%E7%94%A8%E6%B3%95"><span class="toc-text">等价用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%AA%E5%A9%AA%E5%8C%B9%E9%85%8D%E5%92%8C%E6%9C%80%E5%B0%8F%E5%8C%B9%E9%85%8D"><span class="toc-text">贪婪匹配和最小匹配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B-5"><span class="toc-text">实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy%E6%A1%86%E6%9E%B6"><span class="toc-text">Scrapy框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%92%8Crequest%E5%BA%93%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">和request库的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-2"><span class="toc-text">常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4"><span class="toc-text">步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B"><span class="toc-text">创建工程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%A7%E7%94%9F%E7%88%AC%E8%99%AB"><span class="toc-text">产生爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%88%AC%E8%99%AB"><span class="toc-text">配置爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%88%AC%E8%99%AB"><span class="toc-text">运行爬虫</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scrap%E7%88%AC%E8%99%AB%E7%9A%84%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4"><span class="toc-text">Scrap爬虫的使用步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Request%E7%B1%BB"><span class="toc-text">Request类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Response%E7%B1%BB"><span class="toc-text">Response类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Item%E7%B1%BB"><span class="toc-text">Item类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CSS-Selector%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-text">CSS Selector基本使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90-4"><span class="toc-text">例子</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/03/15/JetsonNano%E6%91%84%E5%83%8F%E5%A4%B4%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/" title="JetsonNano摄像头驱动开发指南">JetsonNano摄像头驱动开发指南</a><time datetime="2022-03-15T06:07:34.000Z" title="发表于 2022-03-15 14:07:34">2022-03-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/22/JetsonTX2%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/" title="JetsonTX2避坑指南">JetsonTX2避坑指南</a><time datetime="2022-02-21T17:46:24.000Z" title="发表于 2022-02-22 01:46:24">2022-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/13/python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8/" title="python迭代器与生成器">python迭代器与生成器</a><time datetime="2021-12-13T06:28:34.000Z" title="发表于 2021-12-13 14:28:34">2021-12-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/22/Arch%20Linux%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/" title="Arch Linux安装指南">Arch Linux安装指南</a><time datetime="2021-11-22T04:43:24.000Z" title="发表于 2021-11-22 12:43:24">2021-11-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/04/Arduino%E4%B8%AD%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9D%BF%E5%8D%A1/" title="Arduino中添加自定义板卡">Arduino中添加自定义板卡</a><time datetime="2021-11-04T10:37:40.000Z" title="发表于 2021-11-04 18:37:40">2021-11-04</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By spaceman</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><script type="text/javascript" src="https://api.uixsj.cn/hitokoto/w.php?code=js"></script><div id="xsjhitokoto"><script>xsjhitokoto()</script></div> <iframe scrolling="no" src="https://tianqiapi.com/api.php?style=tx&color=eee" frameborder="0" allowtransparency="false" align="middle" height="20"></iframe></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>