<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>python爬虫 | spaceman</title><meta name="description" content="定向网络数据爬取和网页解析 request库：http:&#x2F;&#x2F;www.python-request.org requests库官方文档中文版：http:&#x2F;&#x2F;cn.python-requests.org&#x2F;zh_CN&#x2F;latest&#x2F;index.html BeautifulSoup库官方文档中文版：http:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F; PEP"><meta name="keywords" content="python,爬虫"><meta name="author" content="spaceman"><meta name="copyright" content="spaceman"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="python爬虫"><meta name="twitter:description" content="定向网络数据爬取和网页解析 request库：http:&#x2F;&#x2F;www.python-request.org requests库官方文档中文版：http:&#x2F;&#x2F;cn.python-requests.org&#x2F;zh_CN&#x2F;latest&#x2F;index.html BeautifulSoup库官方文档中文版：http:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F; PEP"><meta name="twitter:image" content="https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg"><meta property="og:type" content="article"><meta property="og:title" content="python爬虫"><meta property="og:url" content="http://nu-ll.github.io/2020/02/18/python%E7%88%AC%E8%99%AB/"><meta property="og:site_name" content="spaceman"><meta property="og:description" content="定向网络数据爬取和网页解析 request库：http:&#x2F;&#x2F;www.python-request.org requests库官方文档中文版：http:&#x2F;&#x2F;cn.python-requests.org&#x2F;zh_CN&#x2F;latest&#x2F;index.html BeautifulSoup库官方文档中文版：http:&#x2F;&#x2F;beautifulsoup.readthedocs.io&#x2F;zh_CN&#x2F;latest&#x2F; PEP"><meta property="og:image" content="https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg"><meta property="article:published_time" content="2020-02-18T15:40:18.000Z"><meta property="article:modified_time" content="2020-03-04T06:42:28.419Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '2'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="http://nu-ll.github.io/2020/02/18/python%E7%88%AC%E8%99%AB/"><link rel="prev" title="Python数据分析与展示" href="http://nu-ll.github.io/2020/03/10/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA/"><link rel="next" title="Mininet" href="http://nu-ll.github.io/2020/02/13/Mininet/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://nu-ll.github.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: true,
  fancybox: false,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/spaceman.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">50</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">59</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fa fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#定向网络数据爬取和网页解析"><span class="toc-text"> 定向网络数据爬取和网页解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#get"><span class="toc-text"> get</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#通用代码框架"><span class="toc-text"> 通用代码框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#http协议及request库方法"><span class="toc-text"> HTTP协议及request库方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#http协议"><span class="toc-text"> HTTP协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#request库方法"><span class="toc-text"> request库方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#robots协议"><span class="toc-text"> Robots协议</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#遵守方式"><span class="toc-text"> 遵守方式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实例"><span class="toc-text"> 实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#网络爬虫与信息提取"><span class="toc-text"> 网络爬虫与信息提取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#beautifulsoup库的基本元素"><span class="toc-text"> BeautifulSoup库的基本元素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#html遍历"><span class="toc-text"> HTML遍历</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#html格式化和编码"><span class="toc-text"> HTML格式化和编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#信息标记"><span class="toc-text"> 信息标记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内容查找"><span class="toc-text"> 内容查找</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实例-2"><span class="toc-text"> 实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正则表达式库"><span class="toc-text"> 正则表达式库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#操作符"><span class="toc-text"> 操作符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#match对象"><span class="toc-text"> Match对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#相关函数"><span class="toc-text"> 相关函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#等价用法"><span class="toc-text"> 等价用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#贪婪匹配和最小匹配"><span class="toc-text"> 贪婪匹配和最小匹配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实例-3"><span class="toc-text"> 实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy框架"><span class="toc-text"> Scrapy框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#和request库的比较"><span class="toc-text"> 和request库的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#常用命令"><span class="toc-text"> 常用命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#步骤"><span class="toc-text"> 步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#创建工程"><span class="toc-text"> 创建工程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#产生爬虫"><span class="toc-text"> 产生爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#配置爬虫"><span class="toc-text"> 配置爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#运行爬虫"><span class="toc-text"> 运行爬虫</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scrap爬虫的使用步骤"><span class="toc-text"> Scrap爬虫的使用步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#request类"><span class="toc-text"> Request类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#response类"><span class="toc-text"> Response类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#item类"><span class="toc-text"> Item类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#css-selector基本使用"><span class="toc-text"> CSS Selector基本使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#例子"><span class="toc-text"> 例子</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">spaceman</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fa fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">python爬虫</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-02-18 23:40:18"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-02-18</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-03-04 14:42:28"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-03-04</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">12.5k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 55 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="定向网络数据爬取和网页解析"><a class="markdownIt-Anchor" href="#定向网络数据爬取和网页解析"></a> 定向网络数据爬取和网页解析</h2>
<p>request库：<a href="http://www.python-request.org" target="_blank" rel="noopener">http://www.python-request.org</a></p>
<p>requests库官方文档中文版：<a href="http://cn.python-requests.org/zh_CN/latest/index.html" target="_blank" rel="noopener">http://cn.python-requests.org/zh_CN/latest/index.html</a><br>
BeautifulSoup库官方文档中文版：<a href="http://beautifulsoup.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">http://beautifulsoup.readthedocs.io/zh_CN/latest/</a><br>
PEP8——Python代码规范：<a href="https://www.python.org/dev/peps/pep-0008/" target="_blank" rel="noopener">https://www.python.org/dev/peps/pep-0008/</a></p>
<p>简单入门：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> request</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"http://www.baidu.com"</span>)<span class="comment">#访问百度</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.status_code<span class="comment">#获取状态码</span></span><br><span class="line"><span class="number">200</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.encoding=<span class="string">'utf-8'</span><span class="comment">#更改编码</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text<span class="comment">#打印网页内容</span></span><br><span class="line"><span class="string">'&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class="bg s_ipt_wr"&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class="bg s_btn_wr"&gt;&lt;input type=submit id=su value=百度一下 class="bg s_btn"&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(\'&lt;a href="http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=\'+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&amp;")+ "bdorz_come=1")+ \'" name="tj_login" class="lb"&gt;登录&lt;/a&gt;\');&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n'</span></span><br></pre></td></tr></table></figure>
<p>常用的7个方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">requests.request()<span class="comment">#构造一个请求,支撑以下各方法的基础方法</span></span><br><span class="line">requests.get()<span class="comment">#获取HTML网页的主要方法,对应于HTTP的GET </span></span><br><span class="line">requests.head()<span class="comment">#获取HTML网页头信息的方法,对应于HTTP的HEAD </span></span><br><span class="line">requests.post()<span class="comment">#向HTML网页提交POST请求的方法,对应于HTTP的POST </span></span><br><span class="line">requests.put()<span class="comment">#向HTML网页提交PUT请求的方法,对应于HTTP的PUT </span></span><br><span class="line">requests.patch()<span class="comment">#向HTML网页提交局部修改请求,对应于HTTP的PATCH </span></span><br><span class="line">requests.delete()<span class="comment">#向HTML页面提交删除请求,对应于HTTP的DELETE</span></span><br></pre></td></tr></table></figure>
<ul>
<li>实际上底层都是使用了<code>request</code>方法来封装</li>
</ul>
<p>爬虫的尺寸：</p>
<ul>
<li>Requests库：小规模，数据量小，爬取速度不敏感（爬取网页 玩转网页）</li>
<li>Scrapy库：中规模，数据规模较大，爬取速度敏感（爬取网站 爬取系列网站）</li>
<li>定制开发：大规模，搜索引擎，爬取速度关键（爬取全网）</li>
</ul>
<h3 id="get"><a class="markdownIt-Anchor" href="#get"></a> get</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r = request.get(url)</span><br><span class="line"><span class="comment">#完整版</span></span><br><span class="line">r = request.get(url, params=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>get方法构造一个向服务器请求资源的Request对象（由request库内部生成）</li>
<li>r：返回一个包含服务器资源的Response对象（包括从服务器返回的所有资源）</li>
<li>url：拟获取页面的url链接</li>
<li>params:url中的额外参数,字典或字节流格式,可选</li>
<li>**kwargs:12个控制访问的参数</li>
</ul>
<p>Response对象常用属性：</p>
<ul>
<li><code>r.status_code</code>：HTTP请求的返回状态,200表示<strong>连接成功</strong>,404表示失败（其余各种数均为失败）</li>
<li><code>r.text</code>：HTTP响应内容的字符串形式,即,url应的页面内容</li>
<li><code>r.encoding</code>：从 HTTP header中猜测的响应内容编码方式（如果HTTP header中不存在，则默认为<strong>ISO-8859-1</strong>）</li>
<li><code>r.apparent_encoding</code>：从内容中分析出的响应内容编码方式(备选编码方式)</li>
<li><code>r.content</code>：HTTP响应内容的二进制形式（保存图片可能会用到）</li>
</ul>
<h3 id="通用代码框架"><a class="markdownIt-Anchor" href="#通用代码框架"></a> 通用代码框架</h3>
<p>request库的相关异常：</p>
<ul>
<li><code>requests.ConnectionError</code>：网络连接错误异常,如DNS查询失败、拒绝连接等</li>
<li><code>requests.HTTPError</code>：HTTP错误异常</li>
<li><code>requests.URLRequired</code>：URL缺失异常</li>
<li><code>requests.TooManyRedirects</code>：超过最大重定向次数,产生重定向异常</li>
<li><code>requests.ConnectTimeout</code>：连接远程服务器超时异常（仅仅指与远程服务器连接的时间）</li>
<li><code>requests.Timeout</code>：请求URL超时,产生超时异常（发出请求到获得内容的整个过程的时间）</li>
</ul>
<p>产生异常函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r.raise_for_status()<span class="comment">#如果不是200,产生异常requests.HTTPError</span></span><br></pre></td></tr></table></figure>
<p>通用代码框架：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()<span class="comment">#如果状态不是200,引发理 PError异常</span></span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r. text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    url = <span class="string">"http://www.baidu.com"</span></span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></table></figure>
<h3 id="http协议及request库方法"><a class="markdownIt-Anchor" href="#http协议及request库方法"></a> HTTP协议及request库方法</h3>
<h4 id="http协议"><a class="markdownIt-Anchor" href="#http协议"></a> HTTP协议</h4>
<p>HTTP, Hypertext Transfer Protocol,超文本传输协议，基于&quot;请求与响应&quot;模式的、无状态的应用层协议，采用URL作为定位网络资源的标识。URL是通过HTTP协议存取资源的Internet路径,一个URL对应一个数据资源。</p>
<p>URL格式：<code>http://host[:port][path]</code></p>
<ul>
<li>host:合法的 Internet主机域名或IP地址</li>
<li>port:端口号,缺省端囗为80</li>
<li>path:请求资源的路径</li>
</ul>
<p>HTTP协议对资源的操作：</p>
<ul>
<li><code>GET</code>：请求获取URL位置的资源</li>
<li><code>HEAD</code>：请求获取URL位置资源的响应消息报告,即获得该资源的头部信息</li>
<li><code>POST</code>：请求向URL位置的资源后附加新的数据</li>
<li><code>PUT</code>：请求向URL位置存储一个资源,覆盖原URL位置的资源</li>
<li><code>PATCH</code>：请求局部更新URL位置的资原,即改变该处资原的部分内容（节省网络带宽）</li>
<li><code>DELETE</code>：请求删除URL位置存储的资源</li>
</ul>
<p>注：上述方法和request库中的方法是一一对应的</p>
<h4 id="request库方法"><a class="markdownIt-Anchor" href="#request库方法"></a> request库方法</h4>
<p>由于网络安全的限制，一般只会使用到get，对于某些特别大的url链接只用head即可</p>
<p><strong>request方法</strong>：所有方法的基础方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.request(method, url, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>method:请求方式,对应其他get/put/post等7种方法</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">requests.request(<span class="string">'GET'</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">'HEAD'</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">'POST'</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">'PUT'</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">'PATCH'</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">'delete'</span>, url, **kwargs)</span><br><span class="line">requests.request(<span class="string">'OPTIONS'</span>, url, **kwargs)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>url:拟获取页面的url链接</p>
</li>
<li>
<p>**kwargs:控制访问的参数,共13个</p>
<ul>
<li>
<p>params:字典或字节序列,作为参数增加到url中</p>
  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>,<span class="string">'key2'</span>:<span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'GET'</span>,<span class="string">'http://python123.io/ws'</span>,params = kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.url)</span><br><span class="line">https://python123.io/ws?key1=value1&amp;key2=value2</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.request.url)<span class="comment">#发过去的链接</span></span><br><span class="line">https://python123.io/ws?key1=value1&amp;key2=value2</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>data:字典、字节序列或文件对象,作为 Request的内容</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>,<span class="string">'key2'</span>:<span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,data = kv)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>body = <span class="string">'主体内容'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,data = body)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>json:JSON格式的数据,作为 Request的内容</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,json = kv)<span class="comment">#赋值到服务器的json域上</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>headers:字典,HTTP定制头</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hd = &#123;<span class="string">'user-agent'</span>:<span class="string">'Chrome/10'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,headers = hd)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>cookies:字典或 Cookiejar, Request中的 cookie</p>
</li>
<li>
<p>auth:元组,支持HTTP认证功能</p>
</li>
<li>
<p>files:字典类型,传输文件</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fs = &#123;<span class="string">'file'</span>:open(<span class="string">'data.xls'</span>,<span class="string">'rb'</span>)&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'POST'</span>,<span class="string">'http://python123.io/ws'</span>,files = fs)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>timeout:设定超时时间,秒为单位（如果请求内容没有返回回来，会产生一个超时的异常）</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'GET'</span>,<span class="string">'http://www.baidu.com'</span>,timeout = <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>proxies:字典类型,设定访问代理服务器,可以增加登录认证</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pxs = &#123;<span class="string">'http'</span>:<span class="string">'http://user:pass@10.10.10.1:1234'</span>,<span class="string">'https'</span>:<span class="string">'https://10.10.10.1:4321'</span>&#125;<span class="comment">#增加http和https的代理，防止对爬虫的逆追踪</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.request(<span class="string">'GET'</span>,<span class="string">'http://www.baidu.com'</span>,proxies = pxs)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>allow_redirects:True/ False,默认为True,重定向开关</p>
</li>
<li>
<p>stream:True/ False,默认为True,获取内容立即下载开关</p>
</li>
<li>
<p>verify:True/ False,默认为True,认证SSL证书开关</p>
</li>
<li>
<p>cert:本地SSL证书路径</p>
</li>
</ul>
</li>
</ul>
<p><strong>get方法</strong>：获取网页</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get(url, params=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>params:url中的额外参数,字典或字节流格式,可选</li>
<li>**kwargs:12个控制访问的参数(request方法中除了params的12个访问参数)</li>
</ul>
<p><strong>head方法</strong>：用很少的流量获得资源的概要信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.head(url, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>**kwargs:13个控制访问的参数(与request方法中一样)</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.head(<span class="string">'http://httpbin.org/get'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.headers<span class="comment">#展示头部信息</span></span><br><span class="line">&#123;<span class="string">'Date'</span>: <span class="string">'Wed, 19 Feb 2020 04:58:13 GMT'</span>, <span class="string">'Content-Type'</span>: <span class="string">'application/json'</span>, <span class="string">'Content-Length'</span>: <span class="string">'305'</span>, <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>, <span class="string">'Server'</span>: <span class="string">'gunicorn/19.9.0'</span>, <span class="string">'Access-Control-Allow-Origin'</span>: <span class="string">'*'</span>, <span class="string">'Access-Control-Allow-Credentials'</span>: <span class="string">'true'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text<span class="comment">#展示全部内容</span></span><br><span class="line"><span class="string">''</span></span><br></pre></td></tr></table></figure>
<p><strong>post方法</strong>：向服务器提交新增数据。向 URL POST一个<strong>字典</strong>会自动编码为<strong>form</strong>(表单)，向 URL POST一个<strong>字符串</strong>会自动编码为<strong>data</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.post(url, data=<span class="literal">None</span>, json=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>data:字典、字节序列或文件, Request的内容</li>
<li>json:JSON格式的数据, Request的内容</li>
<li>**kwargs:剩下11个控制访问的参数(与request方法中一样)</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>payload = &#123;<span class="string">'key1'</span>:<span class="string">'value1'</span>,<span class="string">'key2'</span>:<span class="string">'value2'</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">'http://httpbin.org/post'</span>,data = payload)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"form"</span>: &#123;</span><br><span class="line">    <span class="string">"key1"</span>: <span class="string">"value1"</span>,</span><br><span class="line">    <span class="string">"key2"</span>: <span class="string">"value2"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">'http://httpbin.org/post'</span>,data = <span class="string">'ABC'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"data"</span>: <span class="string">"ABC"</span>,</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"form"</span>: &#123;&#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>put方法</strong>：与post方法类似，只不过会覆盖原有数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.put(url, data=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>data:字典、字节序列或文件, Request的内容</li>
<li>**kwargs:剩下12个控制访问的参数(与request方法中一样)</li>
</ul>
<p><strong>patch方法</strong>：向HTML网页提交局部修改请求,对应于HTTP的PATCH，能够节省网络带宽</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.patch(url, data=<span class="literal">None</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>data:字典、字节序列或文件, Request的内容</li>
<li>**kwargs:剩下12个控制访问的参数(与request方法中一样)</li>
</ul>
<p><strong>delete方法</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.patch(url, **kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>url：拟获取页面的url链接</li>
<li>**kwargs:13个控制访问的参数(与request方法中一样)</li>
</ul>
<h3 id="robots协议"><a class="markdownIt-Anchor" href="#robots协议"></a> Robots协议</h3>
<p>一些网站对网络爬虫的限制：</p>
<ul>
<li>来源审查:判断 User-Agent进行限制
<ul>
<li>检查来访HTTP协议头的User-Agent域或,只响应浏览器或友好爬虫的访问</li>
</ul>
</li>
<li>发布公告: Robots协议，Robots exclusion standard 网络爬虫排除标准
<ul>
<li>告知所有爬虫，网站的爬取策略，要求爬虫遵守.</li>
</ul>
</li>
</ul>
<p>Robots协议：</p>
<ul>
<li>作用:网站告知网络爬虫哪些页面可以抓取,哪些不行</li>
<li>形式:在网站根目录下的 robots.txt文件中写明了那些目录能够爬取，那些不能</li>
</ul>
<p>例子（京东Robots协议<a href="https://www.jd.com/robots.txt" target="_blank" rel="noopener">https://www.jd.com/robots.txt</a>）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">User-agent: * </span><br><span class="line">Disallow: /?* </span><br><span class="line">Disallow: /pop/*.html </span><br><span class="line">Disallow: /pinpai/*.html?* </span><br><span class="line">User-agent: EtaoSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: HuihuiSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: GwdangSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: WochachaSpider </span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure>
<ul>
<li><code>User-agent: *</code> ：对于任何的爬虫来源，都应该遵守如下规则</li>
<li><code>Disallow</code>：不允许访问的目录和文件</li>
<li><code>EtaoSpider</code>、<code>HuihuiSpider</code>、<code>GwdangSpider</code>、<code>WochachaSpider</code>：对这四类爬虫禁止爬取</li>
</ul>
<p>其他例子：</p>
<ul>
<li>百度：<a href="http://www.baudu.com/robots.txt" target="_blank" rel="noopener">http://www.baudu.com/robots.txt</a></li>
<li>新浪：<a href="http://www.sina.com.cn/robots.txt" target="_blank" rel="noopener">http://www.sina.com.cn/robots.txt</a></li>
<li>QQ：<a href="http://www.qq.com/robots.txt" target="_blank" rel="noopener">http://www.qq.com/robots.txt</a></li>
<li>QQ新闻：<a href="http://news.qq.com/robots.txt" target="_blank" rel="noopener">http://news.qq.com/robots.txt</a></li>
</ul>
<h4 id="遵守方式"><a class="markdownIt-Anchor" href="#遵守方式"></a> 遵守方式</h4>
<p>要求网络爬虫能够自动或人工识别 robots.txt,再进行内容爬取</p>
<p>Robots协议是建议但非约束性,网络爬虫可以不遵守,但存在法律风险.</p>
<h3 id="实例"><a class="markdownIt-Anchor" href="#实例"></a> 实例</h3>
<p>亚马逊商品获取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"https://www.amazon.cn/gp/product/B01M8L5Z3Y"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">'user-agent'</span>:<span class="string">'Mozilla/5.0'</span>&#125;</span><br><span class="line">    r = requests.get(url, headers=kv)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(r.text[<span class="number">1000</span>:<span class="number">2000</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<p>360、百度的搜索：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"http://www.baidu.com/s"</span><span class="comment">#百度</span></span><br><span class="line"><span class="comment">#url = "http://www.so.com/s"#360</span></span><br><span class="line">keyword = <span class="string">"python"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kv = &#123;<span class="string">'wd'</span>:keyword&#125;<span class="comment">#百度</span></span><br><span class="line">    <span class="comment">#kv = &#123;'q':keyword&#125;#360</span></span><br><span class="line">    r = requests.get(url, params=kv)</span><br><span class="line">    print(r.request.url)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    print(len(r.text))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<p>网络图片的爬取和存储：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">url = <span class="string">"http://image.nationalgeographic.com.cn/2017/0211/20170211061910157.jpg"</span></span><br><span class="line">root = <span class="string">"D://pics//"</span></span><br><span class="line">path = root+url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">            print(<span class="string">"文件保存成功"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"文件已存在"</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="网络爬虫与信息提取"><a class="markdownIt-Anchor" href="#网络爬虫与信息提取"></a> 网络爬虫与信息提取</h2>
<p>BeautifulSoup库：能够解析HTML和XML</p>
<p>BeautifulSoup库官方文档中文版：<a href="http://beautifulsoup.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">http://beautifulsoup.readthedocs.io/zh_CN/latest/</a></p>
<h3 id="beautifulsoup库的基本元素"><a class="markdownIt-Anchor" href="#beautifulsoup库的基本元素"></a> BeautifulSoup库的基本元素</h3>
<p>HTML/XML文档 &lt;==&gt; 标签树 &lt;==&gt; BeautifulSoup类，即BeautifulSoup类对应一个 HTMLIXML文档的全部内容.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#常用形式：</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(<span class="string">"&lt;html&gt;data&lt;/html&gt;"</span>,<span class="string">"html.parser"</span>)<span class="comment">#方式一</span></span><br><span class="line">soup2 = BeautifulSoup(open(<span class="string">"D://demo.html"</span>),<span class="string">"html.parser"</span>)<span class="comment">#方式二</span></span><br></pre></td></tr></table></figure>
<p>BeautifulSoup库的解析器：</p>
<ul>
<li>bs4的HTML解析器：<code>BeautifulSoup( mk, 'html.parser')</code>，需要安装bs4库</li>
<li>lxml的HTML解析器：<code>BeautifulSoup(mk,'lxml')</code>，需要安装lxml：<br>
<code>pip install Ixml</code></li>
<li>lxml的XML解析器：<code>BeautifulSoup(mk, ‘xml’)</code>，需要安装lxml：<code>pip install lxml</code></li>
<li>htmI5lib的解析器：<code>BeautifulSoup(mk, 'html5lib')</code>，需要安装html5lib：<code>pip install html5lib</code></li>
</ul>
<p>BeautifulSoup类的基本元素：</p>
<ul>
<li><code>Tag</code>：标签,最基本的信息组织单元,分别用&lt;&gt;和&lt;/&gt;标明开头和结尾</li>
<li><code>Name</code>：标签的名字,<p>…</p>的名字是’p’,格式:<tag>.name</tag></li>
<li><code>Attributes</code>：标签的属性,<strong>字典</strong>形式组织,格式:<tag>.attrs
<ul>
<li>无论标签有没有属性，总能获得一个attrs，无属性就是空</li>
</ul>
</tag></li>
<li><code>NavigableString</code>：标签内非属性字符串,&lt;&gt;…&lt;/&gt;中字符串,格式:<tag>.string</tag></li>
<li><code>Comment</code>：标签内字符串的注释部分,一种特殊的Comment类型</li>
</ul>
<p><img src="/2020/02/18/python%E7%88%AC%E8%99%AB/image-20200220123236026.png" alt="图解"></p>
<p>例子：</p>
<p>对于如下demo网页<a href="https://python123.io/ws/demo.html" target="_blank" rel="noopener">https://python123.io/ws/demo.html</a>，其内容为：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>This is a python demo page<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>The demo python introduces several python courses.<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"course"</span>&gt;</span>Python is a wonderful general-purpose programming language. You can learn Python from novice to</span><br><span class="line">        professional by tracking the following courses:</span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-268001"</span> <span class="attr">class</span>=<span class="string">"py1"</span> <span class="attr">id</span>=<span class="string">"link1"</span>&gt;</span>Basic Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span> and <span class="tag">&lt;<span class="name">a</span></span></span><br><span class="line"><span class="tag">            <span class="attr">href</span>=<span class="string">"http://www.icourse163.org/course/BIT-1001870001"</span> <span class="attr">class</span>=<span class="string">"py2"</span> <span class="attr">id</span>=<span class="string">"link2"</span>&gt;</span>Advanced Python<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>使用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup<span class="comment">#从bs4库中导入BeautifulSoup类</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)<span class="comment">#demo即为上述页面的一个变量</span></span><br><span class="line"><span class="comment">#也可以通过soup = BeautifulSoup(open("demo.html"),"html.parser")，从本地文件获取</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.title<span class="comment">#查看title</span></span><br><span class="line">&lt;title&gt;This is a python demo page&lt;/title&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag = soup.a<span class="comment">#获得a标签（只能获取第一个）</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag<span class="comment">#标签</span></span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(tag)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">bs4</span>.<span class="title">element</span>.<span class="title">Tag</span>'&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">tag</span>.<span class="title">attrs</span>#标签属性 字典类型</span></span><br><span class="line">&#123;'href': 'http://www.icourse163.org/course/BIT-268001', 'class': ['py1'], 'id': 'link1'&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tag.attrs[<span class="string">'class'</span>]</span><br><span class="line">[<span class="string">'py1'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(tag.attrs)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">dict</span>'&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">tag</span>.<span class="title">string</span>#字符串属性 </span></span><br><span class="line"><span class="class">'<span class="title">Basic</span> <span class="title">Python</span>'</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span><span class="params">(tag.string)</span></span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">bs4</span>.<span class="title">element</span>.<span class="title">NavigableString</span>'&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">soup</span>.<span class="title">a</span>.<span class="title">name</span>#获得<span class="title">a</span>标签的名字</span></span><br><span class="line"><span class="class">'<span class="title">a</span>'</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">soup</span>.<span class="title">a</span>.<span class="title">parent</span>.<span class="title">name</span>#获得<span class="title">a</span>标签的父亲的名字</span></span><br><span class="line"><span class="class">'<span class="title">p</span>'</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">soup</span>.<span class="title">a</span>.<span class="title">parent</span>.<span class="title">parent</span>.<span class="title">name</span>#获得<span class="title">a</span>标签的父亲的父亲的名字</span></span><br><span class="line"><span class="class">'<span class="title">body</span>'</span></span><br></pre></td></tr></table></figure>
<p>关于注释的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>newsoup = BeautifulSoup(<span class="string">"&lt;b&gt;&lt;!--This is a comment--&gt;&lt;/b&gt;&lt;p&gt;This is not a comment&lt;/p&gt;"</span>,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="comment">#注释</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>newsoup.b.string</span><br><span class="line"><span class="string">'This is a comment'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(newsoup.b.string)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">bs4</span>.<span class="title">element</span>.<span class="title">Comment</span>'&gt;</span></span><br><span class="line"><span class="class">#字符串</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">newsoup</span>.<span class="title">p</span>.<span class="title">string</span></span></span><br><span class="line"><span class="class">'<span class="title">This</span> <span class="title">is</span> <span class="title">not</span> <span class="title">a</span> <span class="title">comment</span>'</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span><span class="params">(newsoup.p.string)</span></span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">bs4</span>.<span class="title">element</span>.<span class="title">NavigableString</span>'&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>是字符串还是注释，需要根据<strong>类型</strong>去判断</li>
</ul>
<h3 id="html遍历"><a class="markdownIt-Anchor" href="#html遍历"></a> HTML遍历</h3>
<p>下行遍历：沿着根节点向叶子节点遍历的</p>
<p>上行遍历：沿着叶子结点向根节点遍历</p>
<p>平行遍历：在平行节点之间互相遍历</p>
<p>标签树的<strong>下行遍历</strong>：</p>
<ul>
<li><code>.contents</code>：子节点的列表,将<tag><strong>所有</strong>儿子节点存入列表</tag></li>
<li><code>.children</code>：子节点的迭代类型,与.contents类似,用于循环遍历儿子节点</li>
<li><code>.descendants</code>：子孙节点的迭代类型,包含所有子孙节点,用于循环遍历</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.head</span><br><span class="line">&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.head.contents</span><br><span class="line">[&lt;title&gt;This is a python demo page&lt;/title&gt;]</span><br><span class="line"><span class="comment">#.contents</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.body.contents</span><br><span class="line">['\n', &lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;, '\n', &lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;, '\n']</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(soup.body.contents)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.body.contents[<span class="number">1</span>]</span><br><span class="line">&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;</span><br><span class="line"><span class="comment">#.children 遍历儿子节点</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.body.children:</span><br><span class="line">    print(child)</span><br><span class="line"><span class="comment">#.descendants 遍历子孙节点</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.body.descendants:</span><br><span class="line">    print(child)</span><br></pre></td></tr></table></figure>
<ul>
<li>一个标签的子节点并不仅仅只有标签节点，也存在<strong>字符串节点</strong>，如：’\n’</li>
</ul>
<p>标签树的<strong>上行遍历</strong>：</p>
<ul>
<li><code>.parent</code>：节点的父亲标签</li>
<li><code>.parents</code>：节点先辈标签的迭代类型,用于循环遍历先辈节点</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="comment">#.parent</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.title.parent</span><br><span class="line">&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.html.parent</span><br><span class="line">&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;</span><br><span class="line">&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.parent<span class="comment">#空</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#.parents 上行遍历</span></span><br><span class="line"><span class="keyword">for</span> parent <span class="keyword">in</span> soup.a.parents:</span><br><span class="line">    <span class="keyword">if</span> parent <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        print(parent)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(parent.name)</span><br></pre></td></tr></table></figure>
<p>标签树的<strong>平行遍历</strong>：</p>
<ul>
<li>.next_sibling：返回按照HTML文本顺序的下一个平行节点标签</li>
<li>.previous_sibling：返回按照HTML文本顺序的上一个平行节点标签</li>
<li>.next_siblings：迭代类型,返回按照HTML文本顺序的后续所有平行节点标签</li>
<li>.previous_siblings：迭代类型,返回按照HTML文本顺序的前续所有平行节点标签</li>
</ul>
<p>条件：所有的平行遍历都发生在<strong>同一个父节点</strong>下的各节点间</p>
<p>注意：任何一个节点的平行、父亲、儿子节点是可能存在<strong>NavigableString</strong>类型的</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="comment">#.next_sibling</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.next_sibling</span><br><span class="line"><span class="string">' and '</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.next_sibling.next_sibling</span><br><span class="line">&lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;</span><br><span class="line"><span class="comment">#.previous_sibling</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.previous_sibling</span><br><span class="line"><span class="string">'Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.previous_sibling.previous_sibling<span class="comment">#空标签</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.a.parent</span><br><span class="line">&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"><span class="comment">#遍历后续节点：</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.next_siblings:</span><br><span class="line">    print(sibling)</span><br><span class="line"><span class="comment">#遍历前续节点</span></span><br><span class="line"><span class="keyword">for</span> sibling <span class="keyword">in</span> soup.a.previous_siblings:</span><br><span class="line">    print(sibling)</span><br></pre></td></tr></table></figure>
<h3 id="html格式化和编码"><a class="markdownIt-Anchor" href="#html格式化和编码"></a> HTML格式化和编码</h3>
<p>基于bs4库的<code>prettify()</code>方法</p>
<p>例子：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.prettify()</span><br><span class="line"><span class="string">'&lt;html&gt;\n &lt;head&gt;\n  &lt;title&gt;\n   This is a python demo page\n  &lt;/title&gt;\n &lt;/head&gt;\n &lt;body&gt;\n  &lt;p class="title"&gt;\n   &lt;b&gt;\n    The demo python introduces several python courses.\n   &lt;/b&gt;\n  &lt;/p&gt;\n  &lt;p class="course"&gt;\n   Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\n   &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;\n    Basic Python\n   &lt;/a&gt;\n   and\n   &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;\n    Advanced Python\n   &lt;/a&gt;\n   .\n  &lt;/p&gt;\n &lt;/body&gt;\n&lt;/html&gt;'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(soup.prettify())</span><br><span class="line">&lt;html&gt;</span><br><span class="line"> &lt;head&gt;</span><br><span class="line">  &lt;title&gt;</span><br><span class="line">   This <span class="keyword">is</span> a python demo page</span><br><span class="line">  &lt;/title&gt;</span><br><span class="line"> &lt;/head&gt;</span><br><span class="line"> &lt;body&gt;</span><br><span class="line">  &lt;p class="title"&gt;</span><br><span class="line">   &lt;b&gt;</span><br><span class="line">    The demo python introduces several python courses.</span><br><span class="line">   &lt;/b&gt;</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line">  &lt;p class="course"&gt;</span><br><span class="line">   Python <span class="keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="keyword">from</span> novice to professional by tracking the following courses:</span><br><span class="line">   &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;</span><br><span class="line">    Basic Python</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   <span class="keyword">and</span></span><br><span class="line">   &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;</span><br><span class="line">    Advanced Python</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   .</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line"> &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(soup.a.prettify())</span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;</span><br><span class="line"> Basic Python</span><br><span class="line">&lt;/a&gt;</span><br></pre></td></tr></table></figure>
<p>bs4将任何html文件或字符串都转化为了<strong>utf-8编码</strong></p>
<h3 id="信息标记"><a class="markdownIt-Anchor" href="#信息标记"></a> 信息标记</h3>
<p>信息标记的三种形式：</p>
<ul>
<li>
<p>XML（eXtensible Markup Language）：采取了以标签为主，来构建信息表达信息的方式（XML是HTML发展以来的一种通用信息表达形式）</p>
<ul>
<li>在标签中具有名字、属性，与HTML类似：<code>&lt;img src=&quot;china,jpg&quot; size=&quot;10&quot;&gt;...&lt;/img&gt;</code></li>
<li>如果标签中没有内容，可以采用缩写形式：<code>&lt;img src=&quot;china,jpg&quot; size=&quot;10&quot; /&gt;</code></li>
<li>可以嵌入注释：<code>&lt;!--This is acomment, very useful --&gt;</code></li>
</ul>
</li>
<li>
<p>JSON（JavsScript Object Notation）：有类型的键值对构建的信息表达方式</p>
<ul>
<li>规定：
<ul>
<li>键：对信息类型进行定义</li>
<li>值：对信息值的描述</li>
<li>键值对具有数据类型：无论是键还是值，均需要通过<code>&quot;</code>来表示字符串</li>
<li>当值中有多个信息的时候，采用<code>[,]</code>形式来组织：<code>&quot;name&quot;:[&quot;北京&quot;,&quot;延安&quot;]</code></li>
<li>键值对之间可以嵌套使用，嵌套时采用<code>{,}</code>书写：<code>&quot;name&quot;:{&quot;oldname&quot;:&quot;北京&quot;,&quot;newname&quot;:&quot;延安&quot;}</code></li>
</ul>
</li>
<li>好处：
<ul>
<li>对于JavaScript等编程语言来说，可以直接将JSON作为程序的一部分</li>
</ul>
</li>
</ul>
</li>
<li>
<p>YAML（YAML Aint Markup Language）：采用无类型键值对，在键值之间不采用任何双引号或相关的类型标记</p>
<ul>
<li>
<p>没有数据类型：<code>name:北京</code></p>
</li>
<li>
<p>可以通过缩进的关系表达所属关系</p>
</li>
<li>
<p>用<code>-</code>表达并联关系</p>
</li>
<li>
<p>用<code>|</code>表示整块数据</p>
</li>
<li>
<p>用<code>#</code>表示注释</p>
  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">key :</span> <span class="string">value</span></span><br><span class="line"><span class="attr">key :</span> <span class="comment">#Comment</span></span><br><span class="line"><span class="string">-value1</span></span><br><span class="line"><span class="string">-value2</span></span><br><span class="line"><span class="attr">key :</span></span><br><span class="line">    <span class="attr">dubkey :</span> <span class="string">subvalue</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>对比：</p>
<ul>
<li>XML最早的通用信息标记语言,可扩展性好,但繁琐.
<ul>
<li>Internet上的信息交互和传递</li>
</ul>
</li>
<li>JSON信息有类型,适合程序处理(js),较XML简洁.
<ul>
<li>移动应用云端和节点的信息通信,无注释.</li>
</ul>
</li>
<li>YAML信息无类型,文本信息比例最高,可读性好.
<ul>
<li>各类系统的配置文件,有注释易读.</li>
</ul>
</li>
</ul>
<p>信息提取的一般方法：</p>
<ul>
<li>完成解析信息的标记形式，再提取关键信息
<ul>
<li>优点：信息解析准确</li>
<li>缺点：提取过程繁琐，速度慢</li>
</ul>
</li>
<li>无视标记形式,直接搜索关键信息
<ul>
<li>优点:提取过程简洁,速度较快.</li>
<li>缺点:提取结果准确性与信息內容相关</li>
</ul>
</li>
<li>融合方法:结合形式解析与搜索方法,提取关键信息</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#融合方法:先查找a的标签 再解析</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">'a'</span>):</span><br><span class="line"><span class="meta">... </span>    print(link.get(<span class="string">'href'</span>))</span><br><span class="line">...</span><br><span class="line">http://www.icourse163.org/course/BIT<span class="number">-268001</span></span><br><span class="line">http://www.icourse163.org/course/BIT<span class="number">-1001870001</span></span><br></pre></td></tr></table></figure>
<h3 id="内容查找"><a class="markdownIt-Anchor" href="#内容查找"></a> 内容查找</h3>
<p>基本方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;&gt;.find_all(name,attrs,recursive,string,**kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>返回值：列表，储存查取结果</li>
<li>name：对标签名称的检索字符串，如果为True则输出所有标签信息，可以使用正则表达式</li>
<li>attrs：对标签属性值的检索字符串，可标注属性检索，只能够精确查找，否则需要正则表达式</li>
<li>recursive：是否对子孙所有节点进行检索，默认True</li>
<li>string：&lt;&gt;…&lt;/&gt;中字符串区域的检索字符串，只能够精确查找，否则需要正则表达式</li>
</ul>
<p>注意，由于find_all方法常用，可以简写为：</p>
<ul>
<li><code>&lt;tag&gt;.find_all(...)</code>等价于<code>&lt;tag&gt;(...)</code></li>
<li><code>soup.find_all(...)</code>等价于<code>soup(...)</code></li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">"https://python123.io/ws/demo.html"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>demo = r.text<span class="comment">#保存页面到变量demo</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="string">"html.parser"</span>)</span><br><span class="line"><span class="comment">#name</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">'a'</span>)</span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all([<span class="string">'a'</span>,<span class="string">'b'</span>])</span><br><span class="line">[&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;, &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(<span class="literal">True</span>):</span><br><span class="line"><span class="meta">... </span>    print(tag.name)</span><br><span class="line">...</span><br><span class="line">html</span><br><span class="line">head</span><br><span class="line">title</span><br><span class="line">body</span><br><span class="line">p</span><br><span class="line">b</span><br><span class="line">p</span><br><span class="line">a</span><br><span class="line">a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">'b'</span>)):<span class="comment">#使用正则</span></span><br><span class="line"><span class="meta">... </span>    print(tag.name)</span><br><span class="line">...</span><br><span class="line">body</span><br><span class="line">b</span><br><span class="line"><span class="comment">#attrs</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">'p'</span>,<span class="string">'course'</span>)<span class="comment">#检索p标签中带有course属性值的标签</span></span><br><span class="line">[&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:</span><br><span class="line">&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(id=<span class="string">'link1'</span>)<span class="comment">#属性域中id='link1'的标签  精确查找</span></span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(id=<span class="string">'link'</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(id=re.compile(<span class="string">'link'</span>))<span class="comment">#正则</span></span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="comment">#recursive</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">'a'</span>)</span><br><span class="line">[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(<span class="string">'a'</span>,recursive=<span class="literal">False</span>)</span><br><span class="line">[]</span><br><span class="line"><span class="comment">#string</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string = <span class="string">"Basic Python"</span>)<span class="comment">#精确</span></span><br><span class="line">[<span class="string">'Basic Python'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>soup.find_all(string = re.compile(<span class="string">"python"</span>))<span class="comment">#正则</span></span><br><span class="line">[<span class="string">'This is a python demo page'</span>, <span class="string">'The demo python introduces several python courses.'</span>]</span><br></pre></td></tr></table></figure>
<p>扩展方法（与find_all的参数一样）：</p>
<ul>
<li><code>&lt;&gt;.find()</code>：搜索且只返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_parents()</code>：在先辈节点中搜索,返回列表类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_parent()</code>：在先辈节点中返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_next_siblings()</code>：在后续平行节点中搜索,返回列表类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_next_sibling()</code>：在后续平行节点中返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_previous_siblings()</code>：在前序平行节点中搜索,返回列表类型,同<code>.find_all()</code>参数</li>
<li><code>&lt;&gt;.find_previous_sibling()</code>：在前序平行节点中返回一个结果,字符串类型,同<code>.find_all()</code>参数</li>
</ul>
<h3 id="实例-2"><a class="markdownIt-Anchor" href="#实例-2"></a> 实例</h3>
<p>中国大学排名定向爬虫</p>
<p>定向爬虫：仅对输入URL进行爬取,不扩展爬取.</p>
<p>爬取网页：<a href="http://www.zuihaodaxue.com/BCSR/xinxiyutongxingongcheng2019.html" target="_blank" rel="noopener">http://www.zuihaodaxue.com/BCSR/xinxiyutongxingongcheng2019.html</a>，且没有robots.txt文件</p>
<p>部分html代码：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tbody</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span> <span class="attr">class</span>=<span class="string">"bgfd"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"ranking"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"ranking"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"align-center"</span>&gt;</span>前1%<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"align-left"</span>&gt;</span>清华大学<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"../houtai/templates/images/subject/bo1.png"</span> <span class="attr">title</span>=<span class="string">"一级学科博士学位授权点"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"../houtai/templates/images/subject/zhong1.png"</span> <span class="attr">title</span>=<span class="string">"一级学科国家重点学科"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>1219<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout = <span class="number">30</span>)<span class="comment">#30s</span></span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fillUnivList</span><span class="params">(ulist, html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> soup.find(<span class="string">'tbody'</span>).children:</span><br><span class="line">        <span class="keyword">if</span> isinstance(tr,bs4.element.Tag):</span><br><span class="line">            tds = tr(<span class="string">'td'</span>)<span class="comment">#tr.find_all('td')简写</span></span><br><span class="line">            ulist.append([tds[<span class="number">0</span>].string, tds[<span class="number">3</span>].string, tds[<span class="number">6</span>].string])<span class="comment">#大学排名 大学名称 大学总分</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(<span class="string">"排名"</span>,<span class="string">"名称"</span>,<span class="string">"总分"</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(<span class="string">"&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;"</span>.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    uinfo = []</span><br><span class="line">    url = <span class="string">'http://www.zuihaodaxue.com/BCSR/xinxiyutongxingongcheng2019.html'</span></span><br><span class="line">    html = getHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, <span class="number">20</span>)<span class="comment">#只列出前20组</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>上述代码中，由于format输出过程中，采用英文空格填充，因为中英文间距宽度不同，所以会使得结果不会居中</p>
</li>
<li>
<p>为解决居中问题，可以将默认的填充字符由英文空格换成中文空格<code>ch(12288)</code>即可</p>
</li>
<li>
<p>修改后的<code>printUnivList</code>函数：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printUnivList</span><span class="params">(ulist, num)</span>:</span></span><br><span class="line">    tplt = <span class="string">"&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;"</span><span class="comment">#&#123;3&#125;是采用第三个参数，即中文空格chr(12288)</span></span><br><span class="line">    print(tplt.format(<span class="string">"排名"</span>,<span class="string">"名称"</span>,<span class="string">"总分"</span>,chr(<span class="number">12288</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(tplt.format(u[<span class="number">0</span>],u[<span class="number">1</span>],u[<span class="number">2</span>],chr(<span class="number">12288</span>)))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="正则表达式库"><a class="markdownIt-Anchor" href="#正则表达式库"></a> 正则表达式库</h2>
<ul>
<li>通用的字符串表达框架</li>
<li>用来<strong>简洁</strong>的表达一组字符串的表达式</li>
<li>是字符串表达”简洁“和”特征“思想的工具</li>
<li>判断某字符串的特征归属</li>
</ul>
<p>正则表达式是由<strong>字符</strong>和<strong>操作符</strong>构成的</p>
<h3 id="操作符"><a class="markdownIt-Anchor" href="#操作符"></a> 操作符</h3>
<table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.</td>
<td style="text-align:center">表示任何单个字符</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">[]</td>
<td style="text-align:center">字符集，对单个字符给出取值范围</td>
<td style="text-align:center">[abc]表示a、b、c，[a-z]表示a到z单个字符</td>
</tr>
<tr>
<td style="text-align:center">[^]</td>
<td style="text-align:center">非字符集，对单个字符给出排除范围</td>
<td style="text-align:center">[^abc]表示非a或b或c的单个字符</td>
</tr>
<tr>
<td style="text-align:center">*</td>
<td style="text-align:center">前一个字符0次或无限次扩展</td>
<td style="text-align:center">abc*表示ab、abc、abcc、abccc等</td>
</tr>
<tr>
<td style="text-align:center">+</td>
<td style="text-align:center">前一个字符1次或无限次扩展</td>
<td style="text-align:center">abc+表示abc、abcc、abccc等</td>
</tr>
<tr>
<td style="text-align:center">?</td>
<td style="text-align:center">前一个字符0次或1次扩展</td>
<td style="text-align:center">abc?表示abc、abcc、abccc等</td>
</tr>
<tr>
<td style="text-align:center">|</td>
<td style="text-align:center">左右表达式任意一个</td>
<td style="text-align:center">abc|def表示abc或者是def</td>
</tr>
<tr>
<td style="text-align:center">{m}</td>
<td style="text-align:center">扩展前一个字符m次</td>
<td style="text-align:center">ab{2}c表示abbc</td>
</tr>
<tr>
<td style="text-align:center">{m,n}</td>
<td style="text-align:center">扩展前一个字符m至n次（包含n）</td>
<td style="text-align:center">ab{1,2}c表示abc、abbc</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">匹配字符串开头</td>
<td style="text-align:center">^abc表示abc且在一个字符串的开头</td>
</tr>
<tr>
<td style="text-align:center">$</td>
<td style="text-align:center">匹配字符串结尾</td>
<td style="text-align:center">abc$表示abc且在一个字符串的结尾</td>
</tr>
<tr>
<td style="text-align:center">()</td>
<td style="text-align:center">分组标记，内部只能使用|操作符</td>
<td style="text-align:center">(abc)表示abc，(abc|def)表示abc或def</td>
</tr>
<tr>
<td style="text-align:center">\d</td>
<td style="text-align:center">数字，等价于[0-9]</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">\w</td>
<td style="text-align:center">单词字符，等价于[A-Za-z0-9_]</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h3 id="match对象"><a class="markdownIt-Anchor" href="#match对象"></a> Match对象</h3>
<p>一次匹配的结果，包含了很多匹配的相关信息，Match对象的具体类型为<code>re.Match</code></p>
<p>重要属性：</p>
<ul>
<li><code>.string</code>：待匹配的文本</li>
<li><code>.re</code>：匹配时使用的 pattern对象(即正则表达式)</li>
<li><code>.pos</code>：正则表达式搜索文本的开始位置</li>
<li><code>.endpos</code>：正则表达式搜索文本的结束位置</li>
</ul>
<p>常用方法：</p>
<ul>
<li><code>.group(0)</code>：获得匹配后的字符串</li>
<li><code>.start()</code>：匹配字符串在原始字符串的开始位置</li>
<li><code>.end()</code>：匹配字符串在原始字符串的结束位置</li>
<li><code>.span()</code>：返回(.start(), .end())</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'271035 TaiAn,WeiHai 264200'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.string</span><br><span class="line"><span class="string">'271035 TaiAn,WeiHai 264200'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.re</span><br><span class="line">re.compile(<span class="string">'[1-9]\\d&#123;5&#125;'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.pos</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.endpos</span><br><span class="line"><span class="number">26</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'271035'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.start()</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.end()</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span()</span><br><span class="line">(<span class="number">0</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure>
<h3 id="相关函数"><a class="markdownIt-Anchor" href="#相关函数"></a> 相关函数</h3>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>re.search()</td>
<td>在一个字符串中搜索匹配正则表达式的<strong>第一个位置</strong>,返回 match对象</td>
</tr>
<tr>
<td>re.match()</td>
<td>从一个字符串的<strong>开始位置起</strong>匹配正则表达式,返回 match对象</td>
</tr>
<tr>
<td>re.findall()</td>
<td>搜索字符串,以<strong>列表</strong>类型返回<strong>全部</strong>能匹配的子串</td>
</tr>
<tr>
<td>re.split()</td>
<td>将一个字符串按照正则表达式匹配结果进行<strong>分割</strong>,返回列表类型</td>
</tr>
<tr>
<td>re.finditer()</td>
<td>搜索字符串,返回一个匹配结果的<strong>迭代</strong>类型,每个迭代元素是 match对象</td>
</tr>
<tr>
<td>re.sub()</td>
<td>在一个字符串中<strong>替换</strong>所有匹配正则表达式的子串,返回替换后的字符串</td>
</tr>
</tbody>
</table>
<p>函数说明：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.search(pattern, string, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>在一个字符串中搜索匹配正则表达式的第一个位置，返回 match对象</p>
<ul>
<li>pattern：正则表达式的字符串或原生字符串表示
<ul>
<li>原生字符串（raw string）：即<code>r&quot;xxxx&quot;</code>类型字符串</li>
</ul>
</li>
<li>string：待匹配字符串</li>
<li>flags：正则表达式使用时的控制标记
<ul>
<li><code>re.I(re.IGNORECASE)</code>：<strong>忽略</strong>正则表达式的<strong>大小写</strong>，[A-Z]能够匹配小写字符</li>
<li><code>re.M(re.MULTILINE)</code>：正则表达式中的**^<strong>操作符能够将给定字符串的</strong>每行**当作匹配开始</li>
<li><code>re.S(re.DOTALL)</code>：正则表达式中的**.<strong>操作符能够匹配</strong>所有字符**（默认匹配<strong>除换行外</strong>的所有字符）</li>
</ul>
</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">match = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'TaiAn 271035,WeiHai 264200'</span>)</span><br><span class="line"><span class="keyword">if</span> match :</span><br><span class="line">    print(match.group(<span class="number">0</span>))</span><br><span class="line"><span class="comment">#输出 271035</span></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.match(pattern, string, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>从一个字符串的开始位置起匹配正则表达式，返回match对象</p>
<ul>
<li>参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">re.match()从字符串的起始位置开始匹配，如果起始位置匹配不成功，则匹配失败</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">match = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'TaiAn 271035,WeiHai 264200'</span>)</span><br><span class="line"><span class="keyword">if</span> match :</span><br><span class="line">    print(match.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(type(match))</span><br><span class="line"><span class="comment">#输出&lt;class 'NoneType'&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#匹配成功例子：</span></span><br><span class="line">match = re.match(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'271035 TaiAn,WeiHai 264200'</span>)</span><br><span class="line"><span class="keyword">if</span> match :</span><br><span class="line">    print(match.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(type(match))</span><br><span class="line"><span class="comment">#输出 '271035'</span></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(pattern, string, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>搜索字符串，以列表类型返回全部能匹配的子串</p>
<ul>
<li>参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">ls = re.findall(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'TaiAn 271035 WeiHai 264200 222222 115545'</span>)</span><br><span class="line"><span class="keyword">if</span> ls :</span><br><span class="line"> print(ls)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"> print(type(ls))</span><br><span class="line"></span><br><span class="line"><span class="comment">#['271035', '264200', '222222', '115545']</span></span><br></pre></td></tr></table></figure>
<p>注意：findall如果使用了<strong>分组</strong>，则输出的内容将是分组中的内容而非find到的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">xxx = <span class="string">"a123ca456c"</span></span><br><span class="line"></span><br><span class="line">ret = re.findall(<span class="string">r"a(123|456)c"</span>, xxx)</span><br><span class="line">print(ret)</span><br><span class="line"><span class="comment">#['123', '456']</span></span><br></pre></td></tr></table></figure>
<p>解决方法：</p>
<ul>
<li>加上问号来启用“不捕捉模式”</li>
<li>不用分组</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启用“不捕捉模式”</span></span><br><span class="line">ret = re.findall(<span class="string">r"a(?:123|456)c"</span>, xxx)</span><br><span class="line"><span class="comment">#不用分组</span></span><br><span class="line">ret = re.findall(<span class="string">r"a123c|a456c"</span>, xxx)</span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(pattern, string, maxsplit=<span class="number">0</span>, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</p>
<ul>
<li>maxsplit：最大分割数，剩余部分作为最后一个元素输出</li>
<li>其余参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'TaiAn271035WeiHai264200wo222222nihao115545abc'</span>)</span><br><span class="line">[<span class="string">'TaiAn'</span>, <span class="string">'WeiHai'</span>, <span class="string">'wo'</span>, <span class="string">'nihao'</span>, <span class="string">'abc'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.split(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'TaiAn271035WeiHai264200wo222222nihao115545abc'</span>,maxsplit=<span class="number">2</span>)</span><br><span class="line">[<span class="string">'TaiAn'</span>, <span class="string">'WeiHai'</span>, <span class="string">'wo222222nihao115545abc'</span>]</span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.finditer(pattern, string, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是 match对象</p>
<ul>
<li>参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> m <span class="keyword">in</span> re.finditer(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'TaiAn271035WeiHai264200wo222222nihao115545abc'</span>) :</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> m:</span><br><span class="line"><span class="meta">... </span>        print(m.group(<span class="number">0</span>))</span><br><span class="line"><span class="meta">... </span>        print(type(m))</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>        print(<span class="string">"null"</span>)</span><br><span class="line">...</span><br><span class="line"><span class="number">271035</span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">re</span>.<span class="title">Match</span>'&gt;</span></span><br><span class="line"><span class="class">264200</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">re</span>.<span class="title">Match</span>'&gt;</span></span><br><span class="line"><span class="class">222222</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">re</span>.<span class="title">Match</span>'&gt;</span></span><br><span class="line"><span class="class">115545</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">re</span>.<span class="title">Match</span>'&gt;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(pattern, repl, string, count=<span class="number">0</span>, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>用一个新的字符串替换所有匹配正则表达式的子串，返回替换后的字符串</p>
<ul>
<li>repl：替换匹配字符串的字符串</li>
<li>count：匹配的最大替换次数</li>
<li>其余参数同<code>search</code>函数</li>
</ul>
<blockquote>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>re.sub(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'隐藏邮政编码'</span>,<span class="string">'TaiAn271035WeiHai264200wo222222nihao115545abc'</span>)</span><br><span class="line"><span class="string">'TaiAn隐藏邮政编码WeiHai隐藏邮政编码wo隐藏邮政编码nihao隐藏邮政编码abc'</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="等价用法"><a class="markdownIt-Anchor" href="#等价用法"></a> 等价用法</h3>
<ul>
<li>
<p>函数式用法：一次性操作</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rst = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>,<span class="string">'BIT 100081'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>面向对象用法：编译后的多次操作（能够加快程序运行速度）</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pat = re.compile(<span class="string">r'[1-9]\d&#123;5&#125;'</span>)</span><br><span class="line">rst = pat.search(<span class="string">'BIT 100081'</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>compile函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">regex = re.compile(pattern, flags=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>将正则表达式的字符串形式编译成正则表达式对象</p>
<ul>
<li>pattern：正则表达式的字符串或原生字符串表示</li>
<li>flags：正则表达式使用时的控制标记</li>
</ul>
<p>注意：这里regex才是正则表达式（对象），代表了一组字符串。同时regex对象也含有上述re库提供的的六个方法，但是需要将方法中的<code>pattern</code>参数去除</p>
<h3 id="贪婪匹配和最小匹配"><a class="markdownIt-Anchor" href="#贪婪匹配和最小匹配"></a> 贪婪匹配和最小匹配</h3>
<p>Re库<strong>默认</strong>釆用贪婪匹配，即输出匹配<strong>最长</strong>的子串</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'PY.*N'</span>,<span class="string">'PYANBNCNDN'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'PYANBNCNDN'</span></span><br></pre></td></tr></table></figure>
<p>最小匹配：输出匹配<strong>最短</strong>的子串，具体方法为 在匹配不同长度的操作符后 加个<code>?</code>即可</p>
<p>具体扩展的操作符：</p>
<table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">*?</td>
<td style="text-align:center">前一个字符0次或无限次扩展,最小匹配</td>
</tr>
<tr>
<td style="text-align:center">+?</td>
<td style="text-align:center">前一个字符1次或无限次扩展,最小匹配</td>
</tr>
<tr>
<td style="text-align:center">??</td>
<td style="text-align:center">前一个字符0次或1次扩展,最小匹配</td>
</tr>
<tr>
<td style="text-align:center">{m,n}?</td>
<td style="text-align:center">扩展前一个字符m至n次(含n),最小匹配</td>
</tr>
</tbody>
</table>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match = re.search(<span class="string">r'PY.*?N'</span>,<span class="string">'PYANBNCNDN'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>match.group(<span class="number">0</span>)</span><br><span class="line"><span class="string">'PYAN'</span></span><br></pre></td></tr></table></figure>
<h3 id="实例-3"><a class="markdownIt-Anchor" href="#实例-3"></a> 实例</h3>
<p>淘宝商品价格爬取</p>
<p>搜索接口：<a href="https://s.taobao.com/search?q=%E7%AF%AE%E7%90%83" target="_blank" rel="noopener">https://s.taobao.com/search?q=篮球</a><br>
翻页接口：第二页 <a href="https://s.taobao.com/search?q=%E7%AF%AE%E7%90%83&amp;s=44" target="_blank" rel="noopener">https://s.taobao.com/search?q=篮球&amp;s=44</a><br>
第三页 <a href="https://s.taobao.com/search?q=%E7%AF%AE%E7%90%83&amp;s=88" target="_blank" rel="noopener">https://s.taobao.com/search?q=篮球&amp;s=88</a></p>
<p>用爬虫爬淘宝，得到的页面是登录页面，想要跳过这个页面，需要提前在浏览器中登录淘宝，并获取hearders信息（关键是<strong>cookie</strong>和User-Agent）用于模拟用户登录，并作为参数传给requests.get(url,headers = header)，获取方法如下：</p>
<p>首先登陆淘宝账号，然后按 F12 进入检查，在上面的 network 的第一行中拖到最后，找到最上方以search？开头的一栏，右键 Copy–&gt;Copy as URL(bash)，然后打开这个网站： <a href="https://curl.trillworks.com/" target="_blank" rel="noopener">https://curl.trillworks.com/</a> 在里面把复制的内容放进去，选择 Python 然后会发现右边有一个 headers:{省略…}，把这个 headers 放进代码，用一个变量储存，然后在代码中的r equest.get(url,headers=你刚才复制的内容，也就是那个变量）,这个时候你再请求 request.text 返回的就是你要的页面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtmlText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        header =  &#123;</span><br><span class="line">    <span class="string">'authority'</span>: <span class="string">'s.taobao.com'</span>,</span><br><span class="line">    <span class="string">'pragma'</span>: <span class="string">'no-cache'</span>,</span><br><span class="line">    <span class="string">'cache-control'</span>: <span class="string">'no-cache'</span>,</span><br><span class="line">    <span class="string">'upgrade-insecure-requests'</span>: <span class="string">'1'</span>,</span><br><span class="line">    <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'</span>,</span><br><span class="line">    <span class="string">'referer'</span>: ,</span><br><span class="line">    <span class="string">'accept-encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">    <span class="string">'accept-language'</span>: <span class="string">'zh-CN,zh;q=0.9'</span>,</span><br><span class="line">    <span class="string">'cookie'</span>: ,</span><br><span class="line">&#125;<span class="comment">#隐去了cookie信息和referer信息</span></span><br><span class="line">        r = requests.get(url,headers = header)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"爬取失败"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parsePage</span><span class="params">(ilist,html)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        plt = re.findall(<span class="string">r'\"view_price\":\"\d+\.\d*\"'</span>,html)</span><br><span class="line">        tlt = re.findall(<span class="string">r'\"raw_title\":\".*?\"'</span>,html)</span><br><span class="line">        <span class="comment">#print(tlt)</span></span><br><span class="line">        print(len(plt))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(plt)):</span><br><span class="line">            price = eval(plt[i].split(<span class="string">':'</span>)[<span class="number">3</span>])  <span class="comment"># eval：去掉双引号或单引号</span></span><br><span class="line">            title = tlt[i].split(<span class="string">'\"'</span>)[<span class="number">3</span>]  <span class="comment"># 防止名字中出现:</span></span><br><span class="line">            ilist.append([title,price])</span><br><span class="line">        <span class="comment">#print(ilist)</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">"解析出错"</span>)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printGoodsList</span><span class="params">(ilist,num)</span>:</span></span><br><span class="line">    print(<span class="string">"====================================================================================================="</span>)</span><br><span class="line">    tplt = <span class="string">"&#123;0:&lt;3&#125;\t&#123;1:&lt;30&#125;\t&#123;2:&gt;6&#125;"</span></span><br><span class="line">    print(tplt.format(<span class="string">"序号"</span>,<span class="string">"商品名称"</span>,<span class="string">"价格"</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> ilist:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> count &lt;= num:   </span><br><span class="line">            print(tplt.format(count,g[<span class="number">0</span>],g[<span class="number">1</span>]))</span><br><span class="line">    print(<span class="string">"====================================================================================================="</span>)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    goods = <span class="string">"篮球"</span></span><br><span class="line">    depth = <span class="number">1</span></span><br><span class="line">    start_url = <span class="string">"https://s.taobao.com/search?q="</span>+goods</span><br><span class="line">    infoList = []</span><br><span class="line">    num = <span class="number">20</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = start_url + <span class="string">'$S='</span> + str(<span class="number">44</span>*i)</span><br><span class="line">            html = getHtmlText(url)</span><br><span class="line">            parsePage(infoList,html)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    printGoodsList(infoList,num)</span><br><span class="line">    </span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p>股票数据定向爬取：</p>
<p>步骤1：从中财网http://quote.cfi.cn/stockList.aspx获取股票列表</p>
<p>步骤2：根据股票列表获取股票的url，通过每个url获取股票信息</p>
<p>步骤3：将结果保存到文件中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#股票数据定向爬虫</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"> </span><br><span class="line"><span class="comment">#函数功能：原始数据爬取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtmlText</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="comment">#r.encoding = r.apparent_encoding</span></span><br><span class="line">        r.encoding = <span class="string">'utf-8'</span></span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        <span class="comment">#print(r.text[-500:])</span></span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        traceback.print_exc()</span><br><span class="line"> </span><br><span class="line">        </span><br><span class="line"><span class="comment">#函数功能：获取股票列表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStockList</span><span class="params">(lst,stockListURL)</span>:</span></span><br><span class="line">    ra = [<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>]</span><br><span class="line">    <span class="comment">#ra = [11]</span></span><br><span class="line">    count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ra:</span><br><span class="line">        stock_list_html = getHtmlText(stockListURL+str(i))</span><br><span class="line">        soup = BeautifulSoup(stock_list_html,<span class="string">"html.parser"</span>)</span><br><span class="line">        a = soup.find_all(<span class="string">'a'</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">            <span class="keyword">try</span> :</span><br><span class="line">                href = i.attrs[<span class="string">"href"</span>]</span><br><span class="line">                stock_a = re.search(<span class="string">r'\d&#123;6&#125;.html$'</span>,href)</span><br><span class="line">                <span class="keyword">if</span> stock_a:</span><br><span class="line">                    count += <span class="number">1</span></span><br><span class="line">                    lst.append(stock_a.group(<span class="number">0</span>))</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                traceback.print_exc()</span><br><span class="line">    <span class="keyword">return</span> count    </span><br><span class="line"> </span><br><span class="line"><span class="comment">#函数功能：进入每个股票的链接，爬取对应股票的相关信息               </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStockInfo</span><span class="params">(lis,stockInfoURL,fpath,count)</span>:</span></span><br><span class="line">    ready_count = <span class="number">0</span></span><br><span class="line">    f = open(fpath,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> lis[:<span class="number">100</span>]:</span><br><span class="line">        stock_info_html = getHtmlText(stockInfoURL+str(j))</span><br><span class="line">        <span class="comment">#print(stock_info_html)</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> stock_info_html == <span class="string">''</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment">#每个股票存为字典，数据处理较麻烦，有些数据有“杂音”，需单独给出if判断，或在正则中约束</span></span><br><span class="line">            infoDict = &#123; &#125;</span><br><span class="line">            soup = BeautifulSoup(stock_info_html,<span class="string">"html.parser"</span>)</span><br><span class="line">            stockInfo = soup.find(<span class="string">'div'</span>,attrs=&#123;<span class="string">'id'</span>:<span class="string">'act_quote'</span>&#125;)</span><br><span class="line">            name = stockInfo.find(<span class="string">'div'</span>,attrs=&#123;<span class="string">'class'</span>:<span class="string">'Lfont'</span>&#125;).string</span><br><span class="line">            <span class="comment">#print(name)</span></span><br><span class="line">            infoDict.update(&#123;<span class="string">'股票名称'</span>: name&#125;)</span><br><span class="line">            stockDetialInfo = stockInfo.find(<span class="string">'table'</span>,attrs=&#123;<span class="string">'id'</span>:<span class="string">'quotetab_stock'</span>&#125;)</span><br><span class="line">            td = stockDetialInfo.find_all(<span class="string">"td"</span>)</span><br><span class="line">            <span class="comment">#print(td)</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> td:</span><br><span class="line">                <span class="comment">#print(item.get_text())</span></span><br><span class="line">                text= item.get_text()</span><br><span class="line">                <span class="keyword">if</span>(text==<span class="string">"业绩预告"</span>):</span><br><span class="line">                    print(<span class="string">"hear"</span>)</span><br><span class="line">                    key = <span class="string">"业绩预告"</span></span><br><span class="line">                    real_val = <span class="string">"业绩预告"</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    text_split = re.split(<span class="string">':|：'</span>,text)<span class="comment">#网站程序员分号用了中文和英文两种……</span></span><br><span class="line">                    key = text_split[<span class="number">0</span>]</span><br><span class="line">                    val = text_split[<span class="number">1</span>]</span><br><span class="line">                    real_val = re.search(<span class="string">r'(-?\d+.?\d*[%|手|万|元]?)|(--)|(正无穷大)'</span>,val).group(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                infoDict[key] = real_val</span><br><span class="line">            f.write(str(infoDict)+<span class="string">'\n'</span>) <span class="comment">#每个股票字典数据转为字符串写入文件</span></span><br><span class="line">            ready_count += <span class="number">1</span></span><br><span class="line">            print(<span class="string">'\r当前第&#123;0:&#125;个,共&#123;1:&#125;个'</span>.format(ready_count,count)) <span class="comment">#打印进度</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">'\r当前第&#123;0:&#125;个,共&#123;1:&#125;个'</span>.format(ready_count,count))</span><br><span class="line">            traceback.print_exc()</span><br><span class="line">    f.close()</span><br><span class="line">   </span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    lst = []</span><br><span class="line">    stock_list_url = <span class="string">"http://quote.cfi.cn/stockList.aspx?t="</span> <span class="comment">#股票列表，翻页接口</span></span><br><span class="line">    stock_info_url = <span class="string">"http://quote.cfi.cn/"</span>                  <span class="comment">#每个股票的链接都是http://quote.cfi.cn/000000.html的形式。000000代表六位的股票代码</span></span><br><span class="line">    output_path = <span class="string">"D:\ArticleForProgram\PythonProgram\Spider\StockInfo.txt"</span> <span class="comment">#改成自己的</span></span><br><span class="line">    stock_count = getStockList(lst,stock_list_url)</span><br><span class="line">    getStockInfo(lst,stock_info_url,output_path,stock_count)</span><br><span class="line"> </span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h2 id="scrapy框架"><a class="markdownIt-Anchor" href="#scrapy框架"></a> Scrapy框架</h2>
<p>安装scrapy：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br><span class="line">scrapy -h</span><br></pre></td></tr></table></figure>
<p>框架：</p>
<p><img src="/2020/02/18/python%E7%88%AC%E8%99%AB/image-20200224175001094.png" alt="总体框架图"></p>
<p>Engine模块（无需修改）：</p>
<ul>
<li>控制所有模块之间的数据流</li>
<li>根据条件触发事件</li>
</ul>
<p>Download模块（无需修改）：</p>
<ul>
<li>根据用户请求下载网页</li>
</ul>
<p>Scheduler模块（无需修改）：</p>
<ul>
<li>对所有爬取请求进行调度管理</li>
</ul>
<p>Downloader Middleware中间件（一般无需修改）：</p>
<ul>
<li>实施 Engine、 Scheduler和 Downloader之间进行用户可配置的控制</li>
<li>用户可以通过该中间件的编写来修改、丢弃、新增请求或响应</li>
</ul>
<p><strong>Spider模块</strong>：</p>
<ul>
<li>解析 Downloader返回的响应( Response)</li>
<li>产生爬取项( scraped item)</li>
<li>产生额外的爬取请求( Request)</li>
</ul>
<p><strong>Item Pipelines模块</strong>：</p>
<ul>
<li>以流水线方式处理 Spider产生的爬取项.</li>
<li>由一组操作顺序组成,类似流水线,每个操作是一个Item Pipeline类型.</li>
<li>可能操作包括:清理、检验和查重爬取项中的HTML数据、将数据存储到数据库.</li>
</ul>
<p>Spider Middleware中间件：</p>
<ul>
<li>对请求和肥取项的再处理</li>
<li>功能包括修改、丢弃、新增请求或爬取项</li>
</ul>
<h3 id="和request库的比较"><a class="markdownIt-Anchor" href="#和request库的比较"></a> 和request库的比较</h3>
<p>相同点：</p>
<ul>
<li>两者都可以进行页面请求和肥取, Python肥吧虫的两个重要技术路线.</li>
<li>两者可用性都好,文档丰富,入门简单.</li>
<li>两者都没有处理js、提交表单、应对验证码等功能(可扩展).</li>
</ul>
<p>不同点：</p>
<table>
<thead>
<tr>
<th style="text-align:center">request</th>
<th style="text-align:center">Scrapy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">页面级爬虫</td>
<td style="text-align:center">网站级爬虫</td>
</tr>
<tr>
<td style="text-align:center">功能库</td>
<td style="text-align:center">框架</td>
</tr>
<tr>
<td style="text-align:center">并发性考虑不足,性能较差</td>
<td style="text-align:center">并发性好,性能较高</td>
</tr>
<tr>
<td style="text-align:center">重点在于页面下载</td>
<td style="text-align:center">重点在于爬虫结构</td>
</tr>
<tr>
<td style="text-align:center">定制灵活</td>
<td style="text-align:center">一般定制灵活,深度定制困难</td>
</tr>
<tr>
<td style="text-align:center">上手十分简单</td>
<td style="text-align:center">入门稍难</td>
</tr>
</tbody>
</table>
<h3 id="常用命令"><a class="markdownIt-Anchor" href="#常用命令"></a> 常用命令</h3>
<p>Scrapy是为持续运行设计的专业爬虫框架，提供操作的Scrap命令行，其格式为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy &lt;<span class="built_in">command</span>&gt; [options] [args]</span><br></pre></td></tr></table></figure>
<p>常用命令（command）</p>
<table>
<thead>
<tr>
<th style="text-align:center">命令</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">格式</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>startproject</strong></td>
<td style="text-align:center">创建一个新工程</td>
<td style="text-align:center">scrapy startproject <name> [dir]</name></td>
</tr>
<tr>
<td style="text-align:center"><strong>genspider</strong></td>
<td style="text-align:center">创建一个爬虫</td>
<td style="text-align:center">scrapy genspider [options] <name> [domain]</name></td>
</tr>
<tr>
<td style="text-align:center">settings</td>
<td style="text-align:center">获得爬虫配置信息</td>
<td style="text-align:center">scrapy settings [options]</td>
</tr>
<tr>
<td style="text-align:center"><strong>crawl</strong></td>
<td style="text-align:center">运行一个爬虫</td>
<td style="text-align:center">scrapy crawl <spider></spider></td>
</tr>
<tr>
<td style="text-align:center">list</td>
<td style="text-align:center">列出工程中所有爬虫</td>
<td style="text-align:center">scrapy list</td>
</tr>
<tr>
<td style="text-align:center">shell</td>
<td style="text-align:center">启动URL调试命令行</td>
<td style="text-align:center">scrapy shell <url></url></td>
</tr>
</tbody>
</table>
<h3 id="步骤"><a class="markdownIt-Anchor" href="#步骤"></a> 步骤</h3>
<h4 id="创建工程"><a class="markdownIt-Anchor" href="#创建工程"></a> 创建工程</h4>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject demo</span><br></pre></td></tr></table></figure>
<p>会产生如下文件：</p>
<ul>
<li>demo/：外层目录
<ul>
<li>scrapy.cfg：部署 Scrap爬虫的配置文件（服务器上用，本地无需）</li>
<li>demo/：Scrap框架的用户自定义 Python代码
<ul>
<li>__init__.py：初始化脚本</li>
<li><a href="http://items.py" target="_blank" rel="noopener">items.py</a>：Items代码模板(继承类)</li>
<li><a href="http://middlewares.py" target="_blank" rel="noopener">middlewares.py</a>：Middlewares代码模板(继承类)</li>
<li><a href="http://pipelines.py" target="_blank" rel="noopener">pipelines.py</a>：Pipelines代码模板(继承类)</li>
<li>settings：Scrap爬虫的配置文件</li>
<li>spiders/：Spiders代码模板目录(继承类)
<ul>
<li>__pycache__/：缓存目录,无需修改</li>
<li>__init__.py：初始化脚本</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="产生爬虫"><a class="markdownIt-Anchor" href="#产生爬虫"></a> 产生爬虫</h4>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd </span><br><span class="line">scrapy genspider demopython123 python123.io<span class="comment">#名字 网站</span></span><br></pre></td></tr></table></figure>
<p>注意：爬虫名字不能和工程同名</p>
<p>会在<code>demo\demo\spiders\</code>下增加<code>demopython123.py</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demopython123Spider</span><span class="params">(scrapy.Spider)</span>:</span><span class="comment">#必须继承自scrapy.Spider</span></span><br><span class="line">    name = <span class="string">'demopython123'</span><span class="comment">#爬虫名字</span></span><br><span class="line">    allowed_domains = [<span class="string">'python123.io'</span>]<span class="comment">#要爬取的域名</span></span><br><span class="line">    start_urls = [<span class="string">'http://python123.io/'</span>]<span class="comment">#框架要爬取的初始页面</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>parse()</code>用于处理响应,解析内容形成字典,发现新的URL爬取请求</li>
</ul>
<h4 id="配置爬虫"><a class="markdownIt-Anchor" href="#配置爬虫"></a> 配置爬虫</h4>
<p>修改<code>demopython123.py</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demopython123Spider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'demopython123'</span></span><br><span class="line">    <span class="comment">#allowed_domains = ['python123.io']</span></span><br><span class="line">    start_urls = [<span class="string">'http://python123.io/ws/demo.html'</span>]<span class="comment">#需要爬取的页面</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#response：从网络中返回内容所存储的或对应的对象</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span><span class="comment">#爬取功能</span></span><br><span class="line">        fname = response.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">with</span> open(fname,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        sele.log(<span class="string">'Save file %s.'</span> % fname)</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h4 id="运行爬虫"><a class="markdownIt-Anchor" href="#运行爬虫"></a> 运行爬虫</h4>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl demopython123</span><br></pre></td></tr></table></figure>
<p>捕获页面最终会在<code>\demo\demo.html</code>处</p>
<p>但是实际上，生成的<code>demopython123.py</code>文件是简化版，完整版的如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demopython123Spider</span><span class="params">(scrapy.Spider)</span>:</span><span class="comment">#必须继承自scrapy.Spider</span></span><br><span class="line">    name = <span class="string">'demopython123'</span><span class="comment">#爬虫名字</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_request</span><span class="params">(self)</span>:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://python123.io/ws/demo.html'</span></span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>完整版和简化版的区别就在于将简化版中的start_urls变量改为了利用<code>yield</code>生成器的函数start_request</p>
<h3 id="scrap爬虫的使用步骤"><a class="markdownIt-Anchor" href="#scrap爬虫的使用步骤"></a> Scrap爬虫的使用步骤</h3>
<ul>
<li>步骤1:创建一个工程和 Spider模板</li>
<li>步骤2:编写 Spider</li>
<li>步骤3:编写 Item Pipeline</li>
<li>步骤4:优化配置策略</li>
</ul>
<p>涉及到的类：</p>
<ul>
<li>Request类：向网络上提交请求的内容</li>
<li>Response类：从网络中爬取内容的封装类</li>
<li>Item类：由Spider产生的信息而封装的类</li>
</ul>
<h4 id="request类"><a class="markdownIt-Anchor" href="#request类"></a> Request类</h4>
<p>class scrapy.http.Request()</p>
<ul>
<li>表示一个Request对象</li>
<li>由 Spider生成,由 Downloader执行.</li>
</ul>
<p>属性或方法：</p>
<table>
<thead>
<tr>
<th style="text-align:center">属性或方法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.url</td>
<td style="text-align:center">Request对应的请求URL地址</td>
</tr>
<tr>
<td style="text-align:center">.method</td>
<td style="text-align:center">对应的请求方法，‘GET’、'POST’等</td>
</tr>
<tr>
<td style="text-align:center">.headers</td>
<td style="text-align:center">字典类型风格的请求头</td>
</tr>
<tr>
<td style="text-align:center">.body</td>
<td style="text-align:center">请求内容主体，字符串类型</td>
</tr>
<tr>
<td style="text-align:center">.meta</td>
<td style="text-align:center">用户添加的扩展信息，在 Scrapy内部模块间传递信息使用</td>
</tr>
<tr>
<td style="text-align:center">.copy()</td>
<td style="text-align:center">复制该请求</td>
</tr>
</tbody>
</table>
<h4 id="response类"><a class="markdownIt-Anchor" href="#response类"></a> Response类</h4>
<p>class scrapy.http.Response()</p>
<ul>
<li>Response对象表示一个HTTP响应</li>
<li>由 Downloader生成,由 Spider处理</li>
</ul>
<p>属性或方法：</p>
<table>
<thead>
<tr>
<th style="text-align:center">属性或方法</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">.url</td>
<td style="text-align:center">Response对应的请求URL地址</td>
</tr>
<tr>
<td style="text-align:center">.status</td>
<td style="text-align:center">HTTP状态码，默认是200</td>
</tr>
<tr>
<td style="text-align:center">.headers</td>
<td style="text-align:center">Response对应的头部信息</td>
</tr>
<tr>
<td style="text-align:center">.body</td>
<td style="text-align:center">Response对应的内容信息，字符串类型</td>
</tr>
<tr>
<td style="text-align:center">.flags</td>
<td style="text-align:center">一组标记</td>
</tr>
<tr>
<td style="text-align:center">.request</td>
<td style="text-align:center">产生 Response类型对应的 Request对象</td>
</tr>
<tr>
<td style="text-align:center">.copy()</td>
<td style="text-align:center">复制该响应</td>
</tr>
</tbody>
</table>
<h4 id="item类"><a class="markdownIt-Anchor" href="#item类"></a> Item类</h4>
<p>class scrapy.http.Item()</p>
<ul>
<li>Item对象表示一个从HTML页面中提取的信息内容</li>
<li>由 Spider生成,由 Item Pipeline处理</li>
<li>Item类似字典类型，可以按照字典类型操作</li>
</ul>
<p>Scrapy爬虫支持多种HTML信息提取方法：</p>
<ul>
<li>Beautiful Soup</li>
<li>Ixml</li>
<li>re</li>
<li>XPath Selector</li>
<li>CSS Selector</li>
</ul>
<h4 id="css-selector基本使用"><a class="markdownIt-Anchor" href="#css-selector基本使用"></a> CSS Selector基本使用</h4>
<h3 id="例子"><a class="markdownIt-Anchor" href="#例子"></a> 例子</h3>
<p>建立工程</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject BaiduStocks</span><br><span class="line">cd BaiduStocks</span><br><span class="line">scrapy genspider stocks baidu.com</span><br></pre></td></tr></table></figure>
<p>修改<code>spiders\stocks.py</code>文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StocksSpider</span><span class="params">(scrapy.Spider)</span>:</span><span class="comment">#必须继承自scrapy.Spider</span></span><br><span class="line">    name = <span class="string">'stocks'</span><span class="comment">#爬虫名字</span></span><br><span class="line">    start_urls = [<span class="string">'http://quote.eastmoney.com/stocklist.html/'</span>]<span class="comment">#框架要爬取的初始页面</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'a::attr(href)'</span>).extract():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                stock = re.findall(<span class="string">r"[s][hz]\d&#123;6&#125;"</span>,href)[<span class="number">0</span>]</span><br><span class="line">                url = <span class="string">'htps://gupiao.baidu.com/stock'</span> + stock + <span class="string">'.html'</span></span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse_stock)<span class="comment">#处理该url的回调函数</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_stock</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        infoDict = &#123;&#125;</span><br><span class="line">        stockInfo = response.css(<span class="string">'.stock-bets'</span>)</span><br><span class="line">        name = stockInfo.css(<span class="string">'.bets-name'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        keyList = stockInfo.css(<span class="string">'dt'</span>).extract()</span><br><span class="line">        valueList = stockInfo.css(<span class="string">'dd'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(keyList)):</span><br><span class="line">            key = re.findall(<span class="string">r'&gt;.*&lt;/dt&gt;'</span>, keyList[i])[<span class="number">0</span>][<span class="number">1</span>:<span class="number">-5</span>]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                val = re.findall(<span class="string">r'\d+\.?.*&lt;/dd&gt;'</span>, valueList[i])[<span class="number">0</span>][<span class="number">0</span>:<span class="number">-5</span>]</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                val = <span class="string">'--'</span></span><br><span class="line">            infoDict[key] = val</span><br><span class="line">        infoDict.update(</span><br><span class="line">            &#123;<span class="string">'股票名称'</span>: re.findall(<span class="string">r'\s.*\('</span>, name)[<span class="number">0</span>].split()[<span class="number">0</span>] + \</span><br><span class="line">             re.findall(<span class="string">r'&gt;.*\&lt;'</span>, name)[<span class="number">0</span>][<span class="number">1</span>:<span class="number">-1</span>]&#125;)</span><br><span class="line">        <span class="keyword">yield</span> infoDict</span><br></pre></td></tr></table></figure>
<p>编写Pipelines</p>
<ul>
<li>配置pipelines.py文件</li>
<li>定义对爬取项（Scraped Item）的处理类</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaiduStocksPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaiduStocksInfoPipeline</span><span class="params">(object)</span>:</span><span class="comment">#自己写的新的类</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span><span class="comment">#爬虫被调用时对应的pipeline启动的方法</span></span><br><span class="line">        self.f = open(<span class="string">'BaiduStocksInfo.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span><span class="comment">#爬虫关闭或结束时对应的pipeline方法</span></span><br><span class="line">        self.f.close()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span><span class="comment">#对每一个item项进行处理时对应的方法，pipeline中主体函数</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            line = str(dict(item)) + <span class="string">'\n'</span></span><br><span class="line">            self.f.write(line)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>将新的类让框架知道，<a href="http://xn--settings-0n3mm27o.py" target="_blank" rel="noopener">修改settings.py</a>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">' BaiduStocks.pipelines. BaiduStocksInfoPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;<span class="comment"># 修改该参数，由 BaiduStocks.pipelines. BaiduStocksPipeline 改为BaiduStocks.pipelines. BaiduStocksInfoPipeline</span></span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>执行程序：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl stocks</span><br></pre></td></tr></table></figure>
<p>优化：</p>
<p>settings.py文件提供如下配置：</p>
<table>
<thead>
<tr>
<th style="text-align:center">选项</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CONCURRENT_REQUESTS</td>
<td style="text-align:center">Downloader最大并发请求下载数量，默认32</td>
</tr>
<tr>
<td style="text-align:center">CONCURRENT_ITEMS</td>
<td style="text-align:center">Item Pipeline最大井发ITEM处理数量，默认100</td>
</tr>
<tr>
<td style="text-align:center">CONCURRENT_REQUESTS_PER_DOMAIN</td>
<td style="text-align:center">每个目标域名最大的并发请求数量，默认8</td>
</tr>
<tr>
<td style="text-align:center">CONCURRENT_ REQUESTS_PER_IP</td>
<td style="text-align:center">每个目标IP最大的并发请求数量，默认0，非0有效</td>
</tr>
</tbody>
</table>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">spaceman</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://nu-ll.github.io/2020/02/18/python%E7%88%AC%E8%99%AB/">http://nu-ll.github.io/2020/02/18/python爬虫/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://NU-LL.github.io" target="_blank">spaceman</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/NU-LL/image-host/raw/master/12.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/03/10/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA/"><img class="prev_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python数据分析与展示</div></div></a></div><div class="next-post pull_right"><a href="/2020/02/13/Mininet/"><img class="next_cover" src="https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Mininet</div></div></a></div></nav></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By spaceman</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="/js/third-party/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script><script src="/js/third-party/ClickShowText.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>