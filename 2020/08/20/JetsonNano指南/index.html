<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>JetsonNano指南 | spaceman</title><meta name="keywords" content="JetsonNano"><meta name="author" content="spaceman"><meta name="copyright" content="spaceman"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="JetsonNano指南  注意，本指南原本只针对4GB版本使用，后期因为使用2GB版本而新增加了一部分内容，有区别的均已经标注  具体资源请参照JetsonNano开发者套件（2GB版本：Jetson Nano 2GB Developer Kit）、Jetson Linux开发手册、Jetson Zoo（各种开源框架及其安装说明） 一、入门 1.准备  SD卡：大于16G，最好64G，class">
<meta property="og:type" content="article">
<meta property="og:title" content="JetsonNano指南">
<meta property="og:url" content="http://nu-ll.github.io/2020/08/20/JetsonNano%E6%8C%87%E5%8D%97/index.html">
<meta property="og:site_name" content="spaceman">
<meta property="og:description" content="JetsonNano指南  注意，本指南原本只针对4GB版本使用，后期因为使用2GB版本而新增加了一部分内容，有区别的均已经标注  具体资源请参照JetsonNano开发者套件（2GB版本：Jetson Nano 2GB Developer Kit）、Jetson Linux开发手册、Jetson Zoo（各种开源框架及其安装说明） 一、入门 1.准备  SD卡：大于16G，最好64G，class">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg">
<meta property="article:published_time" content="2020-08-20T12:02:54.000Z">
<meta property="article:modified_time" content="2022-05-12T15:35:39.512Z">
<meta property="article:author" content="spaceman">
<meta property="article:tag" content="JetsonNano">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://nu-ll.github.io/2020/08/20/JetsonNano%E6%8C%87%E5%8D%97/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'JetsonNano指南',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-12 23:35:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/spaceman.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">101</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fas fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">spaceman</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fas fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">JetsonNano指南</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-08-20T12:02:54.000Z" title="发表于 2020-08-20 20:02:54">2020-08-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-12T15:35:39.512Z" title="更新于 2022-05-12 23:35:39">2022-05-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">12.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>54分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="JetsonNano指南"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>JetsonNano指南</h1>
<blockquote>
<p>注意，本指南原本只针对4GB版本使用，后期因为使用2GB版本而新增加了一部分内容，有区别的均已经标注</p>
</blockquote>
<p>具体资源请参照<a target="_blank" rel="noopener" href="https://developer.nvidia.com/embedded/jetson-nano-developer-kit">JetsonNano开发者套件</a>（2GB版本：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/embedded/jetson-nano-2gb-developer-kit">Jetson Nano 2GB Developer Kit</a>）、<a target="_blank" rel="noopener" href="https://docs.nvidia.com/jetson/l4t/index.html">Jetson Linux开发手册</a>、<a target="_blank" rel="noopener" href="https://elinux.org/Jetson_Zoo">Jetson Zoo</a>（各种开源框架及其安装说明）</p>
<h2 id="一、入门">一、入门</h2>
<h3 id="1-准备">1.准备</h3>
<ul>
<li>SD卡：大于16G，最好64G，class10， 下载<a target="_blank" rel="noopener" href="https://developer.nvidia.com/jetson-nano-sd-card-image">Jetson Nano Developer Kit SD Card Image</a>SD卡镜像（2GB版本： <a target="_blank" rel="noopener" href="https://developer.nvidia.com/jetson-nano-2gb-sd-card-image">Jetson Nano 2GB Developer Kit SD Card Image</a>），并用 <a target="_blank" rel="noopener" href="https://www.sdcard.org/downloads/formatter_4/eula_windows/">SD Memory Card Formatter for Windows</a>格式化SD卡然后用<a target="_blank" rel="noopener" href="https://www.balena.io/etcher">Etcher</a>刷写入SD卡（仅限于Windows）</li>
<li>Micro-USB电源线（最大支持5V2A）或专用电源线（最大5V4A，推荐，该方式需要将跳线帽接上。2GB无需关心，4GB版本默认接上）</li>
<li>USB无线网络适配器：可选</li>
</ul>
<h3 id="2-开始">2.开始</h3>
<p>将microSD卡（已写入系统映像）插入Jetson Nano模块底部的插槽中。接上各种外设即可进入系统</p>
<p>目前安装的最新版JetPack SDK为4.4，具体包含内容可以参见<a target="_blank" rel="noopener" href="https://developer.nvidia.com/embedded/jetpack">官方链接</a></p>
<h2 id="二、基本环境搭建">二、基本环境搭建</h2>
<h3 id="1-更换国内源">1.更换国内源</h3>
<p>更换为<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/">清华源</a>，注意这里采用的是ARM设备的源，对应的是<code>ubuntu-ports</code>镜像：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">mv</span> /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">sudo vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure>
<p>对应的配置文件为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预发布软件源，不建议启用</span></span><br><span class="line"><span class="comment"># deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse</span></span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-proposed main restricted universe multiverse</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>阿里源：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.aliyun.com/ubuntu-ports/ bionic main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu-ports/ bionic main restricted universe multiverse</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu-ports/ bionic-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu-ports/ bionic-security main restricted universe multiverse</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu-ports/ bionic-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu-ports/ bionic-updates main restricted universe multiverse</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu-ports/ bionic-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu-ports/ bionic-backports main restricted universe multiverse</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu-ports/ bionic-proposed main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu-ports/ bionic-proposed main restricted universe multiverse</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>更新：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure>
<h3 id="2-安装CUDA">2.安装CUDA</h3>
<p>由于Jeston Nano中已经安装了CUDA，但是需要更改环境变量之后，才能够查询到版本信息，所以首先添加环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>在最后添加：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_HOME=/usr/local/cuda-10.2</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda-10.2/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<p>保存后更新：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>检查：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure>
<h3 id="3-配置python">3.配置python</h3>
<blockquote>
<p>注意：</p>
<ul>
<li>目前anaconda官方已经支持arm64位版本，但是实测目前能够安装上，但是不能正常的创建环境——2021/7/20</li>
<li>推荐使用<a target="_blank" rel="noopener" href="https://github.com/conda-forge/miniforge">conda-forge/miniforge: A conda-forge distribution.</a>，支持conda命令，能够正常的创建环境，但是只能使用conda-forge源，不推荐换源（换源之后尝试过创建环境失败）</li>
</ul>
</blockquote>
<p>由于Jetson Nano中已经预装了Python3.6版本，所以可以直接安装pip。</p>
<p>在终端中输入下述命令进行安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-pip python3-dev python3-venv</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>python3-venv</code>是管理虚拟环境的包，由于conda没有arm版本的，所以推荐用<code>venv</code>管理虚拟环境</p>
</li>
<li>
<p>可以此时同时安装<code>autoenv</code>自动激活插件，配合<code>venv</code>使用（注意换源）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install autoenv</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>autoenv需要在<code>.bashrc</code>最后添加以下脚本才能使用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> `<span class="built_in">which</span> activate.sh`</span><br></pre></td></tr></table></figure>
<ul>
<li>如果找不到<code>activate.sh</code>，一般都在<code>~/.local/bin/activate.sh</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>安装完成后此时的pip是9.01版本，需要对pip进行一下升级，否则后面在安装其它Python库的时候会出问题。这里顺带着将pip的源换了：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时换源升级pip</span></span><br><span class="line">python3 -m pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"><span class="comment"># 换源</span></span><br><span class="line">python3 -m pip config <span class="built_in">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"><span class="comment"># 测试版本</span></span><br><span class="line">python3 -m pip --version</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>换源之后的pip源保存在<code>/home/jetson/.config/pip/pip.conf</code>下</p>
</li>
<li>
<p>阿里源：<code>https://mirrors.aliyun.com/pypi/simple</code></p>
<ul>
<li>
<p>阿里源记得在配置文件<code>~/.config/pip/pip.conf</code>中加入以下选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure>
<p>否则会在用pip下载时一直弹出警告</p>
</li>
</ul>
</li>
</ul>
<p>安装常用库（还是建议在虚拟环境中用pip安装）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-scipy</span><br><span class="line">sudo apt-get install python3-pandas</span><br><span class="line">sudo apt-get install python3-sklearn</span><br></pre></td></tr></table></figure>
<h3 id="4-安装Code-OSS">4.安装Code OSS</h3>
<blockquote>
<p>不再推荐，VSC已经支持arm版本</p>
</blockquote>
<p>原生的VS Code并不适用于Jetson Nano，当前，还没有针对Jetson Nano这样的ARM设备的VS Code正式版本。但是，由于它是开源的，所以任何人都可以编译一个版本。其中，Code-OSS就是这样一款嵌入式环境下的“VS Code”。Code-OSS基于VS Code，它并不仅仅是一个代码编辑器，它具有用于管理整个项目文件夹而不是单个脚本的内置资源管理器功能以及丰富的第三方插件。实际上Code-OSS几乎具备了VS Code的所有完整功能，因此用它作为代码编辑器来编辑代码，例如python，会使得整个开发过程更加便捷。</p>
<p>官方的VSC-OSS没有ARM版本的，但是<a target="_blank" rel="noopener" href="https://packagecloud.io/headmelted/codebuilds">该网址</a>为第三方对ARM的适配版本，只需选择后缀带有arm64(aarch64)的，单击后进入详情页面后，找到对应的wget命令即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget --content-disposition https://packagecloud.io/headmelted/codebuilds/packages/debian/stretch/code-oss_1.45.0-1586135971_arm64.deb/download.deb</span><br></pre></td></tr></table></figure>
<p>下载后直接安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i code-oss_1.45.0-1586135971_arm64.deb</span><br></pre></td></tr></table></figure>
<h3 id="5-安装OPENCV">5.安装OPENCV</h3>
<blockquote>
<p>手动编译参考链接：<a target="_blank" rel="noopener" href="https://github.com/mdegans/nano_build_opencv">Build OpenCV on Nvidia Jetson Nano</a>（手动编译opencv脚本，详见后文）、<a target="_blank" rel="noopener" href="https://jkjung-avt.github.io/opencv-on-nano/">Installing OpenCV 3.4.6 on Jetson Nano</a></p>
<p>如果在conda环境中，可以直接通过pip安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-contrib-python</span><br></pre></td></tr></table></figure>
<p>四种opencv的区别：</p>
<ul>
<li>opencv-python: 只包含opencv库的主要模块. 一般不推荐安装</li>
<li>opencv-contrib-python: 包含主要模块和contrib模块, 功能基本完整, 推荐安装</li>
<li>opencv-python-headless: 和opencv-python一样, 但是没有GUI功能, 无外设系统可用</li>
<li>opencv-contrib-python-headless: 和opencv-contrib-python一样但是没有GUI功能. 无外设系统可用</li>
</ul>
<p>注意：</p>
<ol>
<li>
<p>如果需要安装QT，带GUI的版本会与QT冲突</p>
</li>
<li>
<p>上述几种opencv均不带GStreamer支持，而jetson Nano上读取csi摄像头需要通过GStreamer读取，可以通过以下命令查询当前opencv版本的支持情况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="built_in">print</span>(cv2.getBuildInformation())</span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<p>默认自带opencv 4.1.1，可以通过如下命令测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo opencv_version</span><br></pre></td></tr></table></figure>
<p>其中opencv的：</p>
<ul>
<li>头文件目录为：<code>/usr/include/opencv4</code></li>
<li>库文件目录为：<code>/usr/lib/aarch64-linux-gnu</code></li>
<li>常用链接库：<code>-lopencv_core -lopencv_imgcodecs -lopencv_imgproc -lopencv_highgui -lopencv_objdetect -lopencv_videoio</code></li>
</ul>
<h4 id="5-1python环境">5.1python环境</h4>
<p>默认系统的python版本分别为python3.6和python2.7，所以在系统中使用这两个版本是不需要任何设置的，此时可以直接<code>import cv2</code>即可</p>
<p>但是如果当前环境不是上述两个版本，或者说是在虚拟环境中，则需要设置下opecv</p>
<blockquote>
<p>注意：</p>
<ol>
<li>使用pip安装的opencv默认是cpu版本的，不能全部发挥出jetson的性能。</li>
<li>不推荐直接使用系统环境的python，推荐自己创建虚拟环境。（系统带的python中有些库需要通过apt安装）</li>
</ol>
</blockquote>
<p>一般来说有如下两种方式：</p>
<ol>
<li>链接系统默认的opencv到对应的python环境中（仅适用于虚拟环境和系统的python<strong>版本一致</strong>时，在虚拟环境中直接将系统环境中的opencv库链接过来）</li>
<li>重新编译opencv，并链接到python环境中（该方式详见第三章）</li>
</ol>
<p>这里先采用上述第一种方式。一般来说，jetson中默认的opencv库放在如下两个路径：</p>
<ol>
<li><code>/usr/lib/python3.6/dist-packages/cv2/python-3.6/cv2.cpython-36m-aarch64-linux-gnu.so</code>：系统默认python3.6版本的库文件</li>
<li><code>/usr/lib/python2.7/dist-packages/cv2/python-2.7/cv2.so</code>：系统默认python2.7的库文件</li>
</ol>
<p>找到目前使用的python环境，将上述库文件链接到<code>site-packages</code>文件夹下即可（如果没有就自行创建）。一般来说有如下两种情况：</p>
<ol>
<li>系统中的python路径：<code>/usr/lib/python3.8/site-packages/</code></li>
<li>虚拟环境中的python路径：<code>./env/lib/python3.8/site-packages/</code></li>
</ol>
<p>之后创建opencv库的软连接到目标python环境中即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s opencv库文件(xxx.so) cv2.so</span><br></pre></td></tr></table></figure>
<h4 id="5-2摄像头读取">5.2摄像头读取</h4>
<h5 id="读取摄像头参数">读取摄像头参数</h5>
<p>针对硬件的各种参数，可以通过以下命令获取：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">sudo apt install v4l-utils</span><br><span class="line"><span class="comment"># 检测摄像头</span></span><br><span class="line">v4l2-ctl --list-devices</span><br><span class="line"><span class="comment"># 检测摄像头支持的格式</span></span><br><span class="line">v4l2-ctl -d /dev/video1 --list-formats-ext</span><br><span class="line"><span class="comment"># 检查摄像头设置</span></span><br><span class="line">v4l2-ctl -d /dev/video1 --list-ctrls</span><br></pre></td></tr></table></figure>
<h5 id="读取CSI摄像头异常">读取CSI摄像头异常</h5>
<p>如果因为有另一个任务使用同一摄像头（挂起或活动）而导致当前任务不能使用该摄像头并报错时，可以通过如下方式重置 nvargus-daemon 来解决：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service nvargus-daemon restart</span><br></pre></td></tr></table></figure>
<h5 id="CSI摄像头">CSI摄像头</h5>
<p>读取CSI摄像头主要使用Gstreamer，可以通过如下命令测试摄像头：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nvgstcapture</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">gst-launch-1.0 nvarguscamerasrc sensor-id=0 sensor-mode=3 ! <span class="string">&#x27;video/x-raw(memory:NVMM),width=3820, height=2464, framerate=21/1, format=NV12&#x27;</span> ! nvvidconv flip-method=0 ! <span class="string">&#x27;video/x-raw,width=960, height=616&#x27;</span> ! nvvidconv ! nvegltransform ! nveglglessink -e</span><br></pre></td></tr></table></figure>
<p>如下参数也可以（指定默认摄像头与采集模式）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gst-launch-1.0 nvarguscamerasrc ! <span class="string">&#x27;video/x-raw(memory:NVMM),width=3820, height=2464, framerate=21/1, format=NV12&#x27;</span> ! nvvidconv flip-method=0 ! <span class="string">&#x27;video/x-raw,width=960, height=616&#x27;</span> ! nvvidconv ! nvegltransform ! nveglglessink -e</span><br></pre></td></tr></table></figure>
<hr>
<p>opencv中的调用方法：</p>
<p>python：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置gstreamer管道参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gstreamer_pipeline</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sensor_id=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">    sensor_mode=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">    capture_width=<span class="number">1280</span>, <span class="comment">#摄像头预捕获的图像宽度</span></span></span><br><span class="line"><span class="params">    capture_height=<span class="number">720</span>, <span class="comment">#摄像头预捕获的图像高度</span></span></span><br><span class="line"><span class="params">    display_width=<span class="number">1280</span>, <span class="comment">#窗口显示的图像宽度</span></span></span><br><span class="line"><span class="params">    display_height=<span class="number">720</span>, <span class="comment">#窗口显示的图像高度</span></span></span><br><span class="line"><span class="params">    framerate=<span class="number">60</span>,       <span class="comment">#捕获帧率</span></span></span><br><span class="line"><span class="params">    flip_method=<span class="number">0</span>,      <span class="comment">#是否旋转图像</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        <span class="string">&quot;nvarguscamerasrc sensor-id=%d sensor-mode=%d ! &quot;</span></span><br><span class="line">        <span class="string">&quot;video/x-raw(memory:NVMM), &quot;</span></span><br><span class="line">        <span class="string">&quot;width=(int)%d, height=(int)%d, &quot;</span></span><br><span class="line">        <span class="string">&quot;format=(string)NV12, framerate=(fraction)%d/1 ! &quot;</span></span><br><span class="line">        <span class="string">&quot;nvvidconv flip-method=%d ! &quot;</span></span><br><span class="line">        <span class="string">&quot;video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! &quot;</span></span><br><span class="line">        <span class="string">&quot;videoconvert ! &quot;</span></span><br><span class="line">        <span class="string">&quot;video/x-raw, format=(string)BGR ! appsink&quot;</span></span><br><span class="line">        % (</span><br><span class="line">            sensor_id,</span><br><span class="line">            sensor_mode,</span><br><span class="line">            capture_width,</span><br><span class="line">            capture_height,</span><br><span class="line">            framerate,</span><br><span class="line">            flip_method,</span><br><span class="line">            display_width,</span><br><span class="line">            display_height,</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 创建管道 </span></span><br><span class="line">	<span class="built_in">print</span>(gstreamer_pipeline())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#管道与视频流绑定</span></span><br><span class="line">    cap = cv2.VideoCapture(gstreamer_pipeline(flip_method=<span class="number">0</span>), cv2.CAP_GSTREAMER)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cap.isOpened():</span><br><span class="line">        window_handle = cv2.namedWindow(<span class="string">&quot;CSI Camera&quot;</span>, cv2.WINDOW_AUTOSIZE)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 逐帧显示</span></span><br><span class="line">        <span class="keyword">while</span> cv2.getWindowProperty(<span class="string">&quot;CSI Camera&quot;</span>, <span class="number">0</span>) &gt;= <span class="number">0</span>:</span><br><span class="line">            ret_val, img = cap.read()</span><br><span class="line">            cv2.imshow(<span class="string">&quot;CSI Camera&quot;</span>, img)</span><br><span class="line"></span><br><span class="line">            keyCode = cv2.waitKey(<span class="number">30</span>) &amp; <span class="number">0xFF</span>         </span><br><span class="line">            <span class="keyword">if</span> keyCode == <span class="number">27</span>:<span class="comment"># ESC键退出</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        cap.release()</span><br><span class="line">        cv2.destroyAllWindows()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;打开摄像头失败&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>注意：jetson Nano 中，需要 opencv 支持 GStreamer 才可以从 csi 摄像头中读取数据，可以通过以下命令查询是否支持 GStreamer ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="built_in">print</span>(cv2.getBuildInformation())</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>C++：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/objdetect.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/imgproc/types_c.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/videoio.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"><span class="function">string <span class="title">gstreamer_pipeline</span> <span class="params">(<span class="type">int</span> sensor_id, <span class="type">int</span> sensor_mode, <span class="type">int</span> capture_width, <span class="type">int</span> capture_height, <span class="type">int</span> display_width, <span class="type">int</span> display_height, <span class="type">int</span> framerate, <span class="type">int</span> flip_method)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;nvarguscamerasrc sensor-id=&quot;</span> + <span class="built_in">to_string</span>(sensor_id) + <span class="string">&quot; sensor-mode=&quot;</span> + <span class="built_in">to_string</span>(sensor_mode) + <span class="string">&quot; ! video/x-raw(memory:NVMM), width=(int)&quot;</span> + <span class="built_in">to_string</span>(capture_width) + <span class="string">&quot;, height=(int)&quot;</span> +</span><br><span class="line">        <span class="built_in">to_string</span>(capture_height) + <span class="string">&quot;, format=(string)NV12, framerate=(fraction)&quot;</span> + <span class="built_in">to_string</span>(framerate) +</span><br><span class="line">        <span class="string">&quot;/1 ! nvvidconv flip-method=&quot;</span> + <span class="built_in">to_string</span>(flip_method) + <span class="string">&quot; ! video/x-raw, width=(int)&quot;</span> + <span class="built_in">to_string</span>(display_width) + <span class="string">&quot;, height=(int)&quot;</span> +</span><br><span class="line">        <span class="built_in">to_string</span>(display_height) + <span class="string">&quot;, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">( <span class="type">int</span> argc, <span class="type">char</span>** argv )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> capture_width = <span class="number">1280</span> ;</span><br><span class="line">    <span class="type">int</span> capture_height = <span class="number">720</span> ;</span><br><span class="line">    <span class="type">int</span> display_width = <span class="number">1280</span> ;</span><br><span class="line">    <span class="type">int</span> display_height = <span class="number">720</span> ;</span><br><span class="line">    <span class="type">int</span> framerate = <span class="number">60</span> ;</span><br><span class="line">    <span class="type">int</span> flip_method = <span class="number">0</span> ;</span><br><span class="line">    <span class="type">int</span> sensor_id = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> sensor_mode = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建管道</span></span><br><span class="line">    string pipeline = <span class="built_in">gstreamer_pipeline</span>(sensor_id,</span><br><span class="line">                                         sensor_mode,</span><br><span class="line">                                         capture_width,</span><br><span class="line">                                         capture_height,</span><br><span class="line">                                         display_width,</span><br><span class="line">                                         display_height,</span><br><span class="line">                                         framerate,</span><br><span class="line">                                         flip_method);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;使用gstreamer管道: \n\t&quot;</span> &lt;&lt; pipeline &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//管道与视频流绑定</span></span><br><span class="line">    <span class="function">VideoCapture <span class="title">cap</span><span class="params">(pipeline, CAP_GSTREAMER)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(!cap.<span class="built_in">isOpened</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        std::cout&lt;&lt;<span class="string">&quot;打开摄像头失败.&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建显示窗口</span></span><br><span class="line">    <span class="built_in">namedWindow</span>(<span class="string">&quot;CSI Camera&quot;</span>, WINDOW_AUTOSIZE);</span><br><span class="line">    Mat img;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//逐帧显示</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!cap.<span class="built_in">read</span>(img))</span><br><span class="line">        &#123;</span><br><span class="line">            std::cout&lt;&lt;<span class="string">&quot;捕获失败&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">imshow</span>(<span class="string">&quot;CSI Camera&quot;</span>,img);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> keycode = cv::<span class="built_in">waitKey</span>(<span class="number">30</span>) &amp; <span class="number">0xff</span> ; <span class="comment">//ESC键退出</span></span><br><span class="line">        <span class="keyword">if</span> (keycode == <span class="number">27</span>) <span class="keyword">break</span> ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cap.<span class="built_in">release</span>();</span><br><span class="line">    <span class="built_in">destroyAllWindows</span>() ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p>NVIDIA提供了一个基于python的cam库：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA-AI-IOT/jetcam">JetCam</a>，可以通过用过该库来调用摄像头（本质上还是调用Gstreamer）：</p>
<ol>
<li>
<p>下载源码，解压</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip jetcam-master.zip</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>安装</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> jetcam-master</span><br><span class="line">sudo python3 setup.py install</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> jetcam.csi_camera <span class="keyword">import</span> CSICamera</span><br><span class="line">camera = CSICamera(capture_device=<span class="number">0</span>, width=<span class="number">224</span>, height=<span class="number">224</span>, capture_width=<span class="number">1080</span>, capture_height=<span class="number">720</span>, capture_fps=<span class="number">30</span>)</span><br><span class="line">image = camera.read()  <span class="comment"># BGR8</span></span><br><span class="line"><span class="built_in">print</span>(image.shape)</span><br><span class="line"><span class="built_in">print</span>(camera.value.shape)</span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    image = camera.read()</span><br><span class="line">    cv2.imshow(<span class="string">&quot;CSI Camera&quot;</span>, image)</span><br><span class="line">    kk = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> kk == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):  <span class="comment"># 按下 q 键，退出</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h5 id="USB摄像头">USB摄像头</h5>
<p>opencv中的调用方法：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv2.<span class="built_in">VideoCapture</span>(<span class="number">0</span>)</span><br><span class="line">cv2.<span class="built_in">VideoCapture</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>JetCam库中的调用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> jetcam.usb_camera <span class="keyword">import</span> USBCamera</span><br><span class="line">camera = USBCamera(capture_device=<span class="number">1</span>)</span><br><span class="line">image = camera.read()</span><br><span class="line"><span class="built_in">print</span>(image.shape)</span><br><span class="line"><span class="built_in">print</span>(camera.value.shape)</span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    image = camera.read()</span><br><span class="line">    cv2.imshow(<span class="string">&quot;USB Camera&quot;</span>, image)</span><br><span class="line">    kk = cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> kk == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):  <span class="comment"># 按下 q 键，退出</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h3 id="6-安装VNC服务">6.安装VNC服务</h3>
<p>注意：该方案目前在JetPack SDK 4.4上失效，暂时未找到解决方法</p>
<ol>
<li>
<p>解决bug</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;key name=<span class="string">&#x27;enabled&#x27;</span> <span class="built_in">type</span>=<span class="string">&#x27;b&#x27;</span>&gt;</span><br><span class="line">  &lt;summary&gt;Enable remote access to the desktop&lt;/summary&gt;</span><br><span class="line">  &lt;description&gt;</span><br><span class="line">    If <span class="literal">true</span>, allows remote access to the desktop via the RFB</span><br><span class="line">    protocol. Users on remote machines may <span class="keyword">then</span> connect to the</span><br><span class="line">    desktop using a VNC viewer.</span><br><span class="line">  &lt;/description&gt;</span><br><span class="line">  &lt;default&gt;<span class="literal">false</span>&lt;/default&gt;</span><br><span class="line">&lt;/key&gt;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>安装必备软件</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install vino</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>安装VNC server</p>
<p>自带有VNC，只需设置使能即可：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">ln</span> -s ../vino-server.server /usr/lib/systemd/user/graphical-session.target.wants</span><br></pre></td></tr></table></figure>
<p>配置VNC server</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gsettings <span class="built_in">set</span> org.gnome.Vino enabled <span class="literal">true</span></span><br><span class="line">gsettings <span class="built_in">set</span> org.gnome.Vino prompt-enabled <span class="literal">false</span></span><br><span class="line">gsettings <span class="built_in">set</span> org.gnome.Vino require-encryption  <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>设置密码</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gsettings <span class="built_in">set</span> org.gnome.Vino authentication-methods <span class="string">&quot;[&#x27;vnc&#x27;]&quot;</span></span><br><span class="line">gsettings <span class="built_in">set</span> org.gnome.Vino vnc-password $(<span class="built_in">echo</span> -n <span class="string">&#x27;thepassword&#x27;</span>|<span class="built_in">base64</span>)</span><br></pre></td></tr></table></figure>
<p>重启机器</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>连接VNC server：用VNC客户端连接即可</p>
</li>
<li>
<p>设置桌面分辨率：由显示器决定，默认640*480，可以通过编辑<code>/etc/X11/xorg.conf</code>文件，加入以下内容修改分辨率：</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Section <span class="string">&quot;Screen&quot;</span></span><br><span class="line">   Identifier    <span class="string">&quot;Default Screen&quot;</span></span><br><span class="line">   Monitor       <span class="string">&quot;Configured Monitor&quot;</span></span><br><span class="line">   Device        <span class="string">&quot;Tegra0&quot;</span></span><br><span class="line">   SubSection <span class="string">&quot;Display&quot;</span></span><br><span class="line">       Depth    24</span><br><span class="line">       Virtual 1280 800 <span class="comment"># Modify the resolution by editing these values</span></span><br><span class="line">   EndSubSection</span><br><span class="line">EndSection</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>注意：VNC server只有当用户登录后才能使用，如果希望VNC能够自动启动，可以使能自动登录功能</p>
</blockquote>
<h3 id="实验：水流检测代码环境搭建">实验：水流检测代码环境搭建</h3>
<p>注意，这里需要用到以下几个包：</p>
<ul>
<li>opencv</li>
<li>numpy</li>
<li>matplotlib</li>
<li>skimage</li>
</ul>
<p>其中<code>skimage</code>对python的最低版本支持为3.7，所以需要先安装<strong>python3.7以上</strong>版本，并基于此创建虚拟环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install python3.8 python3.8-dev python3.8-venv</span><br><span class="line">python3.8 -m venv waterspeed-env</span><br><span class="line"><span class="comment"># 在虚拟环境中直接下载安装：</span></span><br><span class="line">pip install numpy skimage matplotlib</span><br></pre></td></tr></table></figure>
<ul>
<li>下载安装过程会比较漫长，因为有些包没有arm64平台的，需要在本地编译</li>
</ul>
<h4 id="手动编译并安装opencv">手动编译并安装opencv</h4>
<blockquote>
<p>如果仅仅是编译 python 中的 opencv，推荐 opencv 官方的 python：<a target="_blank" rel="noopener" href="https://github.com/opencv/opencv-python">opencv/opencv-python: Automated CI toolchain to produce precompiled opencv-python, opencv-python-headless, opencv-contrib-python and opencv-contrib-python-headless packages</a></p>
<p>跟着 Manual builds 章节手动编译即可</p>
<p>一般来说，jetson Nano上需要添加以下环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启多核心编译（parallel build）</span></span><br><span class="line"><span class="built_in">export</span> CMAKE_BUILD_PARALLEL_LEVEL=$(<span class="built_in">nproc</span>)</span><br><span class="line"><span class="comment"># 导出编译opencv的环境变量</span></span><br><span class="line"><span class="built_in">export</span> CMAKE_ARGS=<span class="string">&quot;-DWITH_GSTREAMER=ON -DWITH_LIBV4L=ON -DWITH_OPENGL=ON -DWITH_QT=5 -DWITH_V4L=ON&quot;</span></span><br><span class="line"><span class="comment"># 编译完整包（包含主要模块和 contrib/额外模块）</span></span><br><span class="line"><span class="built_in">export</span> ENABLE_CONTRIB=1</span><br><span class="line"><span class="comment"># 编译没有界面支持的opencv</span></span><br><span class="line"><span class="comment"># export ENABLE_HEADLESS=1</span></span><br><span class="line">pip wheel . --verbose <span class="comment"># 开始编译</span></span><br><span class="line"><span class="comment"># 或者通过以下 pip 命令根据当前上下文环境编译安装（不采用官方提供的镜像）</span></span><br><span class="line"><span class="comment"># pip install --no-binary opencv-contrib-python opencv-contrib-python -v</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>编译过程中需要 qt5 的支持，此时需要已经安装 qt5：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install qt5-default</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>编译完成后会在当前目录下生成最后的 whl 文件</p>
</li>
<li>
<p>安装numpy时需要通过conda安装（会提供其他依赖），opencv-python项目中提供的numpy（pip仓库的也没有）没有提供这些依赖</p>
</li>
<li>
<p>有时候编译过程中会因为之前的缓存而导致最后链接时失败，此时删除_skbuild文件夹即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -r _skbuild</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<h5 id="编译-2">编译</h5>
<blockquote>
<p>手动完整编译一次opencv 4.4.0在jetson nano 2GB上预计5~6小时</p>
</blockquote>
<p>opencv比较特殊，推荐直接编译然后创建软连接的方式安装，当然也可以通过apt的方式直接安装（该方式安装的是cpu版本，且已经过时（系统环境默认带了opencv），仅供参考）：[[第一次用Jetson Nano 就上手]OpenCV基础应用](<a target="_blank" rel="noopener" href="https://www.rs-online.com/designspark/jetson-nano-opencv-1-cn">https://www.rs-online.com/designspark/jetson-nano-opencv-1-cn</a>)</p>
<blockquote>
<p>可以根据前文提到的GitHub上的开源脚本来一部编译、配置opencv：<a target="_blank" rel="noopener" href="https://github.com/mdegans/nano_build_opencv">Build OpenCV on Nvidia Jetson Nano</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span>  https://github.com/mdegans/nano_build_opencv.git</span><br></pre></td></tr></table></figure>
<ul>
<li>需要有梯子从外网拉取代码opencv源码</li>
</ul>
</blockquote>
<p>下载对应的仓库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --depth 1 --branch 4.4.0 https://github.com/opencv/opencv.git</span><br><span class="line">git <span class="built_in">clone</span> --depth 1 --branch 4.4.0 https://github.com/opencv/opencv_contrib.git</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：上述<code>4.4.0</code>是opencv的版本号，需要自己根据github仓库分支确定</li>
</ul>
<p>配置opencv：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 到opencv/build（没有build就自己创建）下执行</span></span><br><span class="line">cmake -D BUILD_EXAMPLES=OFF \</span><br><span class="line">        -D BUILD_opencv_python2=ON \</span><br><span class="line">        -D BUILD_opencv_python3=ON \</span><br><span class="line">        -D CMAKE_BUILD_TYPE=RELEASE \</span><br><span class="line">        -D CMAKE_INSTALL_PREFIX=/home/jetson/opencv \</span><br><span class="line">        -D CUDA_ARCH_BIN=5.3,6.2,7.2 \</span><br><span class="line">        -D CUDA_ARCH_PTX= \</span><br><span class="line">        -D CUDA_FAST_MATH=ON \</span><br><span class="line">        -D CUDNN_VERSION=<span class="string">&#x27;8.0&#x27;</span> \</span><br><span class="line">        -D EIGEN_INCLUDE_PATH=/usr/include/eigen3 \</span><br><span class="line">        -D ENABLE_NEON=ON \</span><br><span class="line">        -D OPENCV_DNN_CUDA=ON \</span><br><span class="line">        -D OPENCV_ENABLE_NONFREE=ON \</span><br><span class="line">        -D OPENCV_EXTRA_MODULES_PATH=/home/jetson/package/nano_build_opencv/build_opencv/opencv_contrib/modules \</span><br><span class="line">        -D OPENCV_GENERATE_PKGCONFIG=ON \</span><br><span class="line">        -D WITH_CUBLAS=ON \</span><br><span class="line">        -D WITH_CUDA=ON \</span><br><span class="line">        -D WITH_CUDNN=ON \</span><br><span class="line">        -D WITH_GSTREAMER=ON \</span><br><span class="line">        -D WITH_LIBV4L=ON \</span><br><span class="line">        -D WITH_OPENGL=ON \</span><br><span class="line">        ..</span><br></pre></td></tr></table></figure>
<ul>
<li>注意以下配置需要自定义：
<ul>
<li><code>CMAKE_INSTALL_PREFIX</code>：指定的安装目录，不推荐到全局目录（需要sudo权限）</li>
<li><code>OPENCV_EXTRA_MODULES_PATH</code>：外部模块目录，即<code>opencv_contrib/modules</code></li>
</ul>
</li>
</ul>
<p>编译并安装到本地：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译</span></span><br><span class="line">make -j4</span><br><span class="line"><span class="comment"># 安装到指定目录</span></span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>编译过程中如果遇到以下问题：</p>
<ul>
<li><code>fatal error: boostdesc_bgm.i: No such file or directory</code>：网络问题，编译时还需要下载一部分文件，此时无法下载完成，所以失败。
<ol>
<li>详见<a target="_blank" rel="noopener" href="https://github.com/opencv/opencv_contrib/issues/1301">fatal error: boostdesc_bgm.i: No such file or directory · Issue #1301</a>最后一部分，给出了缺少文件的下载链接，手动下载放到对应文件夹即可</li>
<li>不断重试，直至成功下载完成缺少的文件</li>
</ol>
</li>
</ul>
</li>
<li>
<p>建议安装之后通过如下方式打包备份opencv：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打包</span></span><br><span class="line">tar -jcvf opencv4.4.0.tar.bz2 ./opencv</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar jxvf opencv4.4.0.tar.bz2</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="链接到python虚拟环境">链接到python虚拟环境</h5>
<p>经历过上述步骤后，opencv正确的安装到了指定的路径，此时需要将opencv的库链接到python中来：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找到刚刚编译的opencv的python库路径</span></span><br><span class="line"><span class="built_in">cd</span> opencv/lib/python3.8/site-packages/cv2/python-3.8</span><br><span class="line"><span class="comment"># 重命名库文件</span></span><br><span class="line"><span class="built_in">mv</span> cv2.cpython-36m-xxx-linux-gnu.so cv2.so</span><br><span class="line"><span class="comment"># 去虚拟环境中的site-packages文件夹</span></span><br><span class="line"><span class="built_in">cd</span> ./env/lib/python3.8/site-packages/</span><br><span class="line"><span class="comment"># 如果不是虚拟环境就直接去家目录的的全局python环境下</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"><span class="comment"># 链接库文件</span></span><br><span class="line"><span class="built_in">ln</span> -s ~/opencv/lib/python3.8/site-packages/cv2/python-3.8/cv2.so cv2.so</span><br></pre></td></tr></table></figure>
<p>此时，opencv可以通过如下方式测试版本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">cv2.__version__</span><br><span class="line"><span class="built_in">print</span>(cv2.getBuildInformation())</span><br></pre></td></tr></table></figure>
<h4 id="pytorch安装">pytorch安装</h4>
<blockquote>
<p>官方参考链接：<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-8-0-now-available/72048">PyTorch for Jetson - version 1.8.0 now available</a></p>
</blockquote>
<p>对于Python 2.7与Python 3.6来说，在上面的链接中找到合适的版本直接下载安装即可，对于其他版本的python需要自己手动从源码编译</p>
<h5 id="编译-3">编译</h5>
<blockquote>
<p>注意：</p>
<ul>
<li>该过程在jetson nano 4GB版本上需要12小时左右（不包括torchvision）</li>
<li>自带的4G ram+2G swap小了，编译时会报工具链错误，这里直接将虚拟内存加到了10G</li>
<li>最好单独创建一个虚拟环境进行编译</li>
</ul>
</blockquote>
<ol>
<li>
<p>打开交换分区（如果有则 不需要）：<a target="_blank" rel="noopener" href="https://docs.rackspace.com/support/how-to/create-a-linux-swap-file/">Create a Linux swap file</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建交换分区文件（dd或fallocate二选一即可）</span></span><br><span class="line"><span class="comment"># sudo dd if=/dev/zero of=/swapfile bs=64M count=16#count的大小就是增加的swap空间的大小，64M是块大小，所以空间大小是bs*count=1024MB</span></span><br><span class="line">sudo fallocate -l 8G /mnt/8GB.swap</span><br><span class="line"><span class="comment"># 格式化成swap格式</span></span><br><span class="line">sudo mkswap /mnt/8GB.swap</span><br><span class="line"><span class="comment"># 使用刚才创建的swap空间</span></span><br><span class="line">sudo swapon /mnt/8GB.swap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证swap是否打开</span></span><br><span class="line">free -h</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译完成后关闭并删除swap</span></span><br><span class="line">sudo swapoff /mnt/8GB.swap</span><br><span class="line">sudo <span class="built_in">rm</span> /mnt/8GB.swap</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>打开最高性能模式：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo nvpmodel -m 0     <span class="comment"># on Xavier NX, use -m 2  instead (15W 6-core mode)</span></span><br><span class="line">sudo jetson_clocks</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>下载源码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># git clone --recursive --branch v1.8.0 http://github.com/pytorch/pytorch # 拉取1.8.0版本</span></span><br><span class="line"><span class="comment"># git submodule update --init --recursive  # 若上述拉取子模块的过程中失败。可以用该命令继续拉取</span></span><br><span class="line">git <span class="built_in">clone</span> --recursive --branch &lt;version&gt; http://github.com/pytorch/pytorch</span><br><span class="line"><span class="built_in">cd</span> pytorch</span><br></pre></td></tr></table></figure>
<ul>
<li>若拉取子模块没有问题，但是最后子模块文件夹下没有文件，可以通过删除文件夹继续执行拉取子模块命令解决</li>
</ul>
</li>
<li>
<p>打补丁（防止在jetson上报错）</p>
<ul>
<li>JetPack 4.4.1 - <a target="_blank" rel="noopener" href="https://gist.github.com/dusty-nv/ce51796085178e1f38e3c6a1663a93a1#file-pytorch-1-8-jetpack-4-4-1-patch"><code>pytorch-1.8-jetpack-4.4.1.patch</code></a></li>
<li>JetPack 4.4.1 - <a target="_blank" rel="noopener" href="https://gist.github.com/dusty-nv/ce51796085178e1f38e3c6a1663a93a1#file-pytorch-1-7-jetpack-4-4-1-patch"><code>pytorch-1-7-jetpack-4-4-1.patch</code></a></li>
<li>JetPack 4.4 GA - <a target="_blank" rel="noopener" href="https://gist.github.com/dusty-nv/ce51796085178e1f38e3c6a1663a93a1#file-pytorch-1-6-jetpack-4-4-patch"><code>pytorch-1.6-jetpack-4.4-GA.patch</code></a></li>
<li>JetPack 4.4 DP - <a target="_blank" rel="noopener" href="https://gist.github.com/dusty-nv/ce51796085178e1f38e3c6a1663a93a1"><code>pytorch-diff-jetpack-4.4.patch</code></a></li>
<li>JetPack 4.2 / 4.3 - <a target="_blank" rel="noopener" href="https://gist.github.com/dusty-nv/8a8bbf52d4f0c0999d07436484bb2988"><code>pytorch-diff-jetpack-4.2.patch</code></a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> pytorch</span><br><span class="line">patch -p1 &lt; pytorch-1.8-jetpack-4.4.1.patch</span><br></pre></td></tr></table></figure>
<ul>
<li>如果有<code>.rej</code>文件则表示打补丁失败，一般是代码冲突。需要打开<code>.rej</code>以及相应的<code>.orig</code>文件对比一下找到冲突在哪，解决掉冲突即可</li>
</ul>
</li>
<li>
<p>配置构建选项</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> USE_NCCL=0</span><br><span class="line"><span class="comment">#如果要启用OpenMPI后端，请跳过此设置</span></span><br><span class="line"><span class="built_in">export</span> USE_DISTRIBUTED=0</span><br><span class="line"><span class="built_in">export</span> USE_QNNPACK=0</span><br><span class="line"><span class="built_in">export</span> USE_PYTORCH_QNNPACK=0</span><br><span class="line"><span class="built_in">export</span> TORCH_CUDA_ARCH_LIST=<span class="string">&quot;5.3;6.2;7.2&quot;</span></span><br><span class="line"><span class="comment">#没有前面的&#x27;v&#x27;，如1.3.0表示PyTorch v1.3.0</span></span><br><span class="line"><span class="built_in">export</span> PYTORCH_BUILD_VERSION=&lt;version&gt;</span><br><span class="line"><span class="built_in">export</span> PYTORCH_BUILD_NUMBER=1</span><br><span class="line"><span class="built_in">export</span> MAX_JOBS=4</span><br></pre></td></tr></table></figure>
<ul>
<li>注意，<code>#</code>符号不能加入</li>
</ul>
</li>
<li>
<p>编译生成<code>.whl</code>文件</p>
<ol>
<li>
<p>对于python2：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python-pip cmake libopenblas-dev</span><br><span class="line">pip install -U pip</span><br><span class="line"></span><br><span class="line">sudo pip install -U setuptools</span><br><span class="line">sudo pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line">pip install scikit-build --user</span><br><span class="line">pip install ninja --user</span><br><span class="line"></span><br><span class="line">python setup.py bdist_wheel</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>对于python3：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-pip cmake libopenblas-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># pip3 install -r requirements.txt</span></span><br><span class="line">pip install astunparse future numpy psutil pyyaml requests setuptools six typing_extensions dataclasses</span><br><span class="line">pip3 install scikit-build</span><br><span class="line">pip3 install ninja</span><br><span class="line"></span><br><span class="line">python3 setup.py bdist_wheel</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>最后生成的路径为：<code>./dist/torch-1.9.0-cp39-cp39-linux_aarch64.whl</code>，通过<code>pip install torch-1.9.0-cp39-cp39-linux_aarch64.whl</code>即可安装</p>
</li>
</ol>
<h5 id="验证">验证</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;CUDA available: &#x27;</span> + <span class="built_in">str</span>(torch.cuda.is_available()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;cuDNN version: &#x27;</span> + <span class="built_in">str</span>(torch.backends.cudnn.version()))</span><br><span class="line">a = torch.cuda.FloatTensor(<span class="number">2</span>).zero_()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Tensor a = &#x27;</span> + <span class="built_in">str</span>(a))</span><br><span class="line">b = torch.randn(<span class="number">2</span>).cuda()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Tensor b = &#x27;</span> + <span class="built_in">str</span>(b))</span><br><span class="line">c = a + b</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Tensor c = &#x27;</span> + <span class="built_in">str</span>(c))</span><br><span class="line"><span class="comment"># torchvision</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="built_in">print</span>(torchvision.__version__)</span><br></pre></td></tr></table></figure>
<h5 id="torchvision安装">torchvision安装</h5>
<p>注意torchvision与pytorch的对应关系：<a target="_blank" rel="noopener" href="https://github.com/pytorch/vision">pytorch/vision: Datasets, Transforms and Models specific to Computer Vision</a>，具体如下：</p>
<ul>
<li>PyTorch v1.0 - torchvision v0.2.2</li>
<li>PyTorch v1.1 - torchvision v0.3.0</li>
<li>PyTorch v1.2 - torchvision v0.4.0</li>
<li>PyTorch v1.3 - torchvision v0.4.2</li>
<li>PyTorch v1.4 - torchvision v0.5.0</li>
<li>PyTorch v1.5 - torchvision v0.6.0</li>
<li>PyTorch v1.6 - torchvision v0.7.0</li>
<li>PyTorch v1.7 - torchvision v0.8.1</li>
<li>PyTorch v1.8 - torchvision v0.9.0</li>
<li>PyTorch v1.9 - torchvision v0.10.0</li>
</ul>
<p>pip直接安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torchvision</span><br></pre></td></tr></table></figure>
<p>手动编译：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装必备包</span></span><br><span class="line">sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libavcodec-dev libavformat-dev libswscale-dev</span><br><span class="line"><span class="comment"># clone对应项目源码 注意版本要对应（需要加v，如v0.10.0）</span></span><br><span class="line">git <span class="built_in">clone</span> --branch &lt;version&gt; https://github.com/pytorch/vision torchvision</span><br><span class="line"><span class="built_in">cd</span> torchvision</span><br><span class="line"><span class="built_in">export</span> BUILD_VERSION=0.x.0  <span class="comment"># 0.x.0是torchvision的版本号</span></span><br><span class="line"><span class="built_in">export</span> MAX_JOBS=4  <span class="comment"># 这种方式（parallel）似乎并不起作用</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/60759623/python-setuptools-editable-install-with-parallel-build</span></span><br><span class="line">python setup.py build -j4 --verbose  <span class="comment"># 多核编译</span></span><br><span class="line">python3 setup.py install --user</span><br><span class="line"><span class="built_in">cd</span> ../  <span class="comment"># 尝试从构建目录加载 torchvision 将导致导入错误</span></span><br><span class="line"><span class="comment"># 下面这句在python2.7以及torchvision 0.5.0 以下需要</span></span><br><span class="line">pip install <span class="string">&#x27;pillow&lt;7&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="安装FCOS环境">安装FCOS环境</h4>
<blockquote>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/tianzhi0549/FCOS">tianzhi0549/FCOS: FCOS: Fully Convolutional One-Stage Object Detection (ICCV’19)</a></p>
</blockquote>
<p>配置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建新的虚拟环境（python需要&gt;=3.7）</span></span><br><span class="line">python3.8 -m venv fcos-venv</span><br><span class="line"><span class="comment"># 编写自动激活脚本（需要安装autoenv插件）</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;source fcos-venv/bin/activate&quot;</span> &gt; .<span class="built_in">env</span></span><br><span class="line"><span class="comment"># 激活虚拟环境</span></span><br><span class="line"><span class="built_in">source</span> fcos-venv/bin/activate</span><br><span class="line"><span class="comment"># 升级虚拟环境自带的pip</span></span><br><span class="line">pip install --upgrade pip -i https://mirrors.aliyun.com/pypi/simple</span><br><span class="line"><span class="comment"># clone项目</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/tianzhi0549/FCOS.git</span><br></pre></td></tr></table></figure>
<p>安装依赖：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ninja yacs cython matplotlib tqdm scikit-image</span><br></pre></td></tr></table></figure>
<p>继续安装上一节编译好后的opencv：[链接到python虚拟环境](# 链接到python虚拟环境)</p>
<h2 id="三、深度学习">三、深度学习</h2>
<blockquote>
<p>参考链接：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/embedded/learn/tutorials">Tutorials | NVIDIA Developer</a>：官方总链接</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/embedded/twodaystoademo">Two Days to a Demo | NVIDIA Developer</a>：动手实验</li>
<li><a target="_blank" rel="noopener" href="https://github.com/dusty-nv/jetson-inference#training">jetson-inference: Hello AI World guide to deploying deep-learning inference networks and deep vision primitives with TensorRT and NVIDIA Jetson</a>：通过docker来快速部署</li>
<li><a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-8-0-now-available/72048">PyTorch for Jetson - version 1.8.0 now available</a>：pytorch安装</li>
</ol>
</blockquote>
<h3 id="1-jetson-inference项目">1.jetson-inference项目</h3>
<p><a target="_blank" rel="noopener" href="https://github.com/dusty-nv/jetson-inference">jetson-inference</a> 是官方出品，用于快速上手的项目。通过使用NVIDIA TensorRT将神经网络有效地部署到Jetson上，并利用图形优化，内核融合和使用FP16/INT8精度的方式提高了性能</p>
<h4 id="1-1环境搭建">1.1环境搭建</h4>
<blockquote>
<p>前提是需要在JetPack上。一般来说通过SD卡安装的系统都已经满足该要求</p>
</blockquote>
<p>该项目有两种方式进行搭建：</p>
<ol>
<li>docker</li>
<li>直接编译源码再安装到系统中</li>
</ol>
<h5 id="docker方式">docker方式</h5>
<p>该方式需要下载位于 <a target="_blank" rel="noopener" href="https://hub.docker.com/r/dustynv/jetson-inference/tags">DockerHub</a> 的容器（900M左右），国内可能比较慢，且需要JetPack的版本和容器的版本匹配。以下方法可以获得当前JetPack的版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">head</span> -n 1 /etc/nv_tegra_release</span><br><span class="line"><span class="comment"># R32 (release), REVISION: 4.4, GCID: 23942405, BOARD: t210ref, EABI: aarch64, DATE: Fri Oct 16 19:44:43 UTC 2020</span></span><br></pre></td></tr></table></figure>
<ul>
<li>上方第二行为返回值，其版本为<code>R32.4.4</code></li>
</ul>
<p>通过以下方式安装并运行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --recursive https://github.com/dusty-nv/jetson-inference</span><br><span class="line"><span class="built_in">cd</span> jetson-inference</span><br><span class="line">docker/run.sh</span><br></pre></td></tr></table></figure>
<p>上述<code>run.sh</code>脚本会执行以下几件事：</p>
<ol>
<li>
<p>自动检测JetPack版本并自动拉取docker image</p>
</li>
<li>
<p>自动挂载设备，以便在容器中使用：</p>
<ul>
<li>
<p><code>jetson-inference/data</code> (存储网络模型，序列化的TensorRT引擎和测试镜像)</p>
<ul>
<li><code>jetson-inference/data/images/test</code>：建议将容器内部生成的图像保存在此处，对应容器中的路径为：<code>images/test</code></li>
</ul>
</li>
<li>
<p><code>jetson-inference/python/training/classification/data</code> (存储分类训练数据集)</p>
</li>
<li>
<p><code>jetson-inference/python/training/classification/models</code> (存储PyTorch训练的分类模型)</p>
</li>
<li>
<p><code>jetson-inference/python/training/detection/ssd/data</code> (存储检测训练数据集)</p>
</li>
<li>
<p><code>jetson-inference/python/training/detection/ssd/models</code> (存储PyTorch培训的检测模型)</p>
</li>
<li>
<p>摄像头节点</p>
</li>
<li>
<p>如果想将其他文件挂载进容器，可以通过传入如下参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker/run.sh --volume /my/host/path:/my/container/path</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>根据选择自动下载模型权重文件</p>
</li>
</ol>
<h5 id="源码方式">源码方式</h5>
<p>执行以下命令即可在本机编译这个项目</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install git cmake libpython3-dev python3-numpy</span><br><span class="line">git <span class="built_in">clone</span> --recursive https://github.com/dusty-nv/jetson-inference</span><br><span class="line"><span class="built_in">cd</span> jetson-inference</span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ../</span><br><span class="line"><span class="comment">#  cmake -D BUILD_DEPS=NO ../ # 配置时不检查依赖（不运行CMakePreBuild.sh下载模型）</span></span><br><span class="line"><span class="comment"># 下载模型（可选）</span></span><br><span class="line"><span class="built_in">cd</span> ../tools</span><br><span class="line">./download-models.sh</span><br><span class="line"><span class="comment"># 安装PyTorch（可选，迁移学习用）</span></span><br><span class="line"><span class="built_in">cd</span> ../build</span><br><span class="line">./install-pytorch.sh</span><br><span class="line"><span class="comment"># 编译工程</span></span><br><span class="line"><span class="built_in">cd</span> jetson-inference/build</span><br><span class="line">make -j$(<span class="built_in">nproc</span>)</span><br><span class="line">sudo make install</span><br><span class="line">sudo ldconfig</span><br></pre></td></tr></table></figure>
<p>构建完毕后的镜像会在<code>jetson-inference/build/aarch64</code>中，执行<code>make install</code>会将其安装到系统中（ <code>/usr/local/</code>处），其结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">|-build</span><br><span class="line">   \aarch64</span><br><span class="line">      \bin             生成示例二进制文件的位置</span><br><span class="line">         \networks     网络模型的存储位置</span><br><span class="line">         \images       测试图像的存储位置</span><br><span class="line">      \include         头文件位置</span><br><span class="line">      \lib             构建的lib库位置</span><br></pre></td></tr></table></figure>
<ul>
<li><code>make install</code>后，python包<a target="_blank" rel="noopener" href="https://rawgit.com/dusty-nv/jetson-inference/python/docs/html/python/jetson.inference.html"><code>jetson.inference</code></a> 和 <a target="_blank" rel="noopener" href="https://rawgit.com/dusty-nv/jetson-inference/python/docs/html/python/jetson.utils.html"><code>jetson.utils</code></a> 也会一同安装到<code>/usr/lib/python*/dist-packages/</code>下</li>
</ul>
<h4 id="1-2推理">1.2推理</h4>
<h5 id="1-2-1分类（ImageNet）">1.2.1分类（ImageNet）</h5>
<h5 id="1-2-2检测（DetectNet）">1.2.2检测（DetectNet）</h5>
<p>是用自带例子进行检测，能够在图像、视频、摄像头中检测，具体的输入输出流支持与切换可以参考官方文档： <a target="_blank" rel="noopener" href="https://github.com/dusty-nv/jetson-inference/blob/master/docs/aux-streaming.md">Camera Streaming and Multimedia</a>。自带以下俩个例子：</p>
<ul>
<li><code>detectnet.cpp</code> (C++)</li>
<li><code>detectnet.py</code>(Python)</li>
</ul>
<p>命令行参数如下：</p>
<ul>
<li><code>--network</code>：修改模型文件，默认的检测模型为SSD-Mobilenet-v2</li>
<li><code>--overlay</code>：以逗号为分隔符的一个组合，包括<code>box</code>, <code>labels</code>, <code>conf</code>, 和<code>none</code>，默认为<code>--overlay=box,labels,conf</code>，即显示边框、标签和置信度</li>
<li><code>--alpha</code>：设置覆盖时使用的 alpha 混合值（默认值为 120）</li>
<li><code>--threshold</code>： 设置检测的最小阈值（默认值为 0.5）</li>
</ul>
<h5 id="1-2-3语义分割（SegNet）">1.2.3语义分割（SegNet）</h5>
<h4 id="1-3训练">1.3训练</h4>
<h3 id="2-tensorRT-yolov5">2.tensorRT+yolov5</h3>
<blockquote>
<p>参考链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/jkjung-avt/tensorrt_demos">jkjung-avt/tensorrt_demos: TensorRT MODNet, YOLOv4, YOLOv3, SSD, MTCNN, and GoogLeNet</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/tensorrt/index.html">NVIDIA Deep Learning TensorRT Documentation</a></li>
</ul>
</blockquote>
<h4 id="2-1-PyCUDA安装">2.1 PyCUDA安装</h4>
<p>为了使用TensorRT Python API，需要安装pycuda，版本为2019.1.2，从<a target="_blank" rel="noopener" href="https://pypi.org/project/pycuda/#history">PyPI</a>处下载对应的版本即可</p>
<blockquote>
<p>通过pip仓库安装的方式会出问题：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置环境变量 使用系统自带的nvcc</span></span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=/usr/local/cuda  <span class="comment"># 实际链接到了/usr/local/cuda-10.2</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$CUDA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBARY_PATH=<span class="variable">$CUDA_HOME</span>/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">pip install --global-option=build_ext --global-option=<span class="string">&quot;-I/usr/local/cuda/include&quot;</span> --global-option=<span class="string">&quot;-L/usr/local/cuda/lib64&quot;</span> pycuda --user -v</span><br></pre></td></tr></table></figure>
<p>通过以下方式安装没有问题：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置环境变量 使用系统自带的nvcc</span></span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=/usr/local/cuda  <span class="comment"># 实际链接到了/usr/local/cuda-10.2</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$CUDA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBARY_PATH=<span class="variable">$CUDA_HOME</span>/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">pip install <span class="string">&#x27;pycuda&lt;2021.1&#x27;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>手动编译并安装pycuda（参考<a target="_blank" rel="noopener" href="https://github.com/jkjung-avt/tensorrt_demos">jkjung-avt/tensorrt_demos</a>项目中的<code>tensorrt_demos/ssd/install_pycuda.sh</code>）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置环境变量 使用系统自带的nvcc</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/local/cuda-10.2/bin</span><br><span class="line"><span class="comment"># 安装相关依赖</span></span><br><span class="line">sudo apt-get install build-essential python3-dev</span><br><span class="line">sudo apt-get install libboost-python-dev libboost-thread-dev</span><br><span class="line">pip install setuptools</span><br><span class="line"><span class="comment"># 从 https://pypi.org/project/pycuda/#files 处下载pycuda的源码包</span></span><br><span class="line">tar xzvf pycuda-2019.1.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> pycuda-2019.1.2</span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">boost_pylib=$(<span class="built_in">basename</span> /usr/lib/aarch64-linux-gnu/libboost_python*-py3?.so)  <span class="comment"># libboost_python3-py36.so</span></span><br><span class="line">boost_pylibname=<span class="variable">$&#123;boost_pylib%.so&#125;</span>  <span class="comment"># libboost_python3-py36</span></span><br><span class="line">boost_pyname=<span class="variable">$&#123;boost_pylibname/lib/&#125;</span>  <span class="comment"># boost_python3-py36</span></span><br><span class="line">python ./configure.py --python-exe=/home/jetson/mambaforge/envs/yolov5/bin/python --cuda-root=/usr/local/cuda --cudadrv-lib-dir=/usr/lib/aarch64-linux-gnu --boost-inc-dir=/usr/include --boost-lib-dir=/usr/lib/aarch64-linux-gnu --boost-python-libname=<span class="variable">$&#123;boost_pyname&#125;</span> --boost-thread-libname=boost_thread --no-use-shipped-boost</span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">make -j4</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>
<ul>
<li>注意更换python路径</li>
<li>可执行程序的路径可以通过<code>where</code>命令获取</li>
</ul>
<h4 id="2-2-cuDNN安装">2.2 cuDNN安装</h4>
<p>NVIDIA CUDA 深度神经网络库 (cuDNN) 是经 GPU 加速的深度神经网络基元库。cuDNN 可大幅优化标准例程（例如用于前向传播和反向传播的卷积层、池化层、归一化层和激活层）的实施。</p>
<blockquote>
<p>注意：jetson中默认已经安装cuDNN 8，无需再次安装</p>
</blockquote>
<p>根据后面tensorRT的要求，需要安装cuDNN8.1.1，根据<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-811/install-guide/index.html">官方安装手册</a>，先去<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN home page</a>下载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -xzvf cudnn-x.x-linux-x64-v8.x.x.x.tgz</span><br><span class="line"><span class="comment"># 将以下文件复制到 CUDA Toolkit 目录中</span></span><br><span class="line">sudo <span class="built_in">cp</span> cuda/include/cudnn*.h /usr/local/cuda/include </span><br><span class="line">sudo <span class="built_in">cp</span> -P cuda/lib64/libcudnn* /usr/local/cuda/lib64 </span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>
<p>另一种直接通过apt安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libcudnn8</span><br><span class="line">sudo apt install libcudnn8-dev</span><br></pre></td></tr></table></figure>
<h4 id="2-3-tensorRT安装">2.3 tensorRT安装</h4>
<p>NVIDIA TensorRT 是用于高性能深度学习推理的 SDK。此 SDK 包含深度学习推理优化器和运行时环境，可为深度学习推理应用提供低延迟和高吞吐量。</p>
<blockquote>
<p>注意：jetson中已经自带有tensorRT，通过<code>dpkg -l | grep TensorRT</code>命令可以查看， 但是在conda的虚拟环境中不能使用，通过以下两种方式可以在conda中使用：</p>
<ol>
<li>
<p>设置环境变量<code>PYTHONPATH</code>后，在激活conda环境即可载入原始python环境中自带的tensorRT</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PYTHONPATH=/usr/lib/python3.6/dist-packages:<span class="variable">$PYTHONPATH</span></span><br><span class="line">conda activate yolov5</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>从原始环境中拷贝</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r /usr/lib/python3.6/dist-packages/tensorrt* /home/jetson/mambaforge/envs/yolov5/lib/python3.6/site-packages</span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<p>需要条件：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA 10.2</a>, <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">11.0 update 1</a>, <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">11.1 update 1</a>, or <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">11.2 update 1</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/cudnn/release-notes/rel_8.html#rel-811">cuDNN 8.1.1</a></li>
<li>TensorFlow 1.15.3以上</li>
<li>Pytorch 1.5.0测试通过</li>
<li>ONNX 1.6.0测试通过</li>
<li>python3（可选）</li>
<li>PyCUDA &gt;= 2019.1.1（可选）</li>
</ul>
<p>去<a target="_blank" rel="noopener" href="https://developer.nvidia.com/tensorrt">官网</a>下载tar方式的安装包，注意版本选择为TensorRT 7.2.3（后缀EA为Early Access），根据官方教程<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-723/install-guide/index.html">TensorRT 7.2.3 安装指南</a>安装，选取tar的安装方式</p>
<blockquote>
<p>各种包的对比：</p>
<p>deb、rpm包：</p>
<ul>
<li>自动安装依赖</li>
<li>需要sudo</li>
<li>对于TensorRT安装在哪个位置没有灵活性</li>
<li>需要使用 Debian 或 RPM 软件包安装 CUDA Toolkit 和 cuDNN。</li>
<li>不允许同时安装一个以上的 TensorRT 次要版本</li>
</ul>
<p>tar包：提供了更多的灵活性，例如同时安装多个版本的 TensorRT。但是需要确保已经安装了必要的依赖项，并且必须自己管理 LD_LIBRARY_PATH</p>
<p>zip包：是当前用于 Windows 的唯一选项。它不支持除 Windows 之外的任何其他平台。确保您已经安装了必要的依赖项</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar xzvf TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn8.1.tar.gz</span><br><span class="line"><span class="comment"># 将 TensorRT 中的 lib 目录的绝对路径添加到环境变量 LD_LIBRARY_PATH 中：</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/home/jetson/TensorRT-7.2.3.4/lib</span><br><span class="line"><span class="comment"># 安装 Python TensorRT</span></span><br><span class="line"><span class="built_in">cd</span> TensorRT-7.2.3.4/python</span><br><span class="line">pip install tensorrt-7.2.3.4-cp36-none-linux_x86_64.whl</span><br><span class="line"><span class="comment"># 安装 Python UFF 轮文件。仅当您计划将 TensorRT 与 TensorFlow 结合使用时才需要这样做</span></span><br><span class="line"><span class="built_in">cd</span> TensorRT-7.2.3.4/uff</span><br><span class="line">pip install uff-0.6.9-py2.py3-none-any.whl</span><br><span class="line"><span class="built_in">which</span> convert-to-uff <span class="comment"># 检查</span></span><br><span class="line"><span class="comment"># 安装 Python graphsurgeon</span></span><br><span class="line"><span class="built_in">cd</span> TensorRT-7.2.3.4/graphsurgeon</span><br><span class="line">pip install graphsurgeon-0.4.5-py2.py3-none-any.whl</span><br><span class="line"><span class="comment"># 安装 Python onnx-graphsurgeon</span></span><br><span class="line"><span class="built_in">cd</span> TensorRT-7.2.3.4/onnx_graphsurgeon</span><br><span class="line">pip install onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl</span><br></pre></td></tr></table></figure>
<ul>
<li>注意TensorRT的版本号与python的版本号</li>
<li>整个安装过程在conda中，所以无需区分pip2、pip3，同时无需使用sudo</li>
</ul>
<h4 id="2-4-模型转换">2.4 模型转换</h4>
<h5 id="2-4-1-方案一（暂未通过）">2.4.1 方案一（暂未通过）</h5>
<blockquote>
<p>参考链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/issues/251">TFLite, ONNX, CoreML Export · Issue #251 · ultralytics/yolov5</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/jkjung-avt/tensorrt_demos#yolov4">jkjung-avt/tensorrt_demos: TensorRT MODNet, YOLOv4, YOLOv3, SSD, MTCNN, and GoogLeNet</a></li>
</ul>
</blockquote>
<p>安装onnx：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mamba install onnx</span><br></pre></td></tr></table></figure>
<p>编译<code>libyolo_layer.so</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;HOME&#125;</span>/project/tensorrt_demos/plugins</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<p>模型转换 *.pt --&gt; *.onnx --&gt; tensorrt：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去yolov5仓库 将pt转成onnx</span></span><br><span class="line"><span class="built_in">cd</span> yolov5-master</span><br><span class="line">python export.py --weights ../yolov5n_person.pt --include onnx --dynamic</span><br><span class="line"><span class="comment"># 回tensorrt_demos仓库 将onnx转成tensorrt</span></span><br><span class="line"><span class="built_in">cd</span> -</span><br><span class="line">python onnx_to_tensorrt.py -m ../../yolov5n_person.onnx</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>如果上述步骤中出现错误：ImportError: /usr/lib/aarch64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.26’ not found ，则需要降低scipy版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mamba install scipy==1.3.1</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>实测上述问题不能在jetson nano上解决，需要通过设置<code>LD_LIBRARY_PATH</code>环境变量修改链接库到conda内部：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/home/jetson/mambaforge/envs/yolov5/lib/</span><br><span class="line"><span class="comment"># 检查对应的库中是否存需要的符号：</span></span><br><span class="line">strings /home/jetson/mambaforge/envs/yolov5/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="2-4-2-方案二">2.4.2 方案二</h5>
<blockquote>
<p>参考链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/wang-xinyu/pytorchx">wang-xinyu/pytorchx: Implement popular deep learning networks in pytorch, used by tensorrtx.</a></li>
</ul>
</blockquote>
<p>参考上述链接中的<a target="_blank" rel="noopener" href="https://github.com/wang-xinyu/tensorrtx/tree/5f1b048a29e2fcd9eb85b780c89b90a4f052a3b7/yolov5">tensorrtx/yolov5/README.md</a>即可</p>
<p>采用<a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/releases">YOLOv5s</a>，推理时间在71ms左右，相比原来未经过tensorRT加速的网络快30ms左右</p>
<h4 id="2-5-DeepStream">2.5 DeepStream</h4>
<blockquote>
<p>参考链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html">NVIDIA DeepStream SDK Developer Guide — DeepStream 6.0 Release documentation</a></li>
</ul>
</blockquote>
<p>DeepStream 是一个流分析工具包，用于构建 AI 驱动的应用程序。它将流数据作为输入——来自 USB/CSI 摄像头、来自文件的视频或通过 RTSP 的流，并使用人工智能和计算机视觉从像素中生成洞察力，以便更好地了解环境。 DeepStream SDK 可以成为许多视频分析解决方案的基础层，例如了解智慧城市中的交通和行人、医院中的健康和安全监控、零售中的自助结账和分析、制造工厂中的组件缺陷检测等。</p>
<p>DeepStream需要librdkafka 库，该库是 Apache Kafka 协议的 C 库实现，提供生产者、消费者和管理客户端。它的设计考虑了消息传递的可靠性和高性能，目前的数据是生产者每秒超过 100 万条消息，消费者每秒超过 300 万条消息。</p>
<p>根据上述DeepStream SDK的开发手册中的<a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_Quickstart.html#jetson-setup">Quickstart Guide — DeepStream 6.0 Release documentation</a>，安装jetson上的DeepStream 即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">sudo apt install libssl1.0.0 libgstreamer1.0-0 gstreamer1.0-tools gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav libgstrtspserver-1.0-0 libjansson4=2.11-1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装librdkafka</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/edenhill/librdkafka.git</span><br><span class="line"><span class="comment"># 配置、编译librdkafka</span></span><br><span class="line"><span class="built_in">cd</span> librdkafka</span><br><span class="line">git reset --hard 7101c2310341ab3f4675fc565f64f0967e135a6a</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line"><span class="comment"># 将生成的库复制到 deepstream 目录：</span></span><br><span class="line">sudo <span class="built_in">mkdir</span> -p /opt/nvidia/deepstream/deepstream-6.0/lib</span><br><span class="line">sudo <span class="built_in">cp</span> /usr/local/lib/librdkafka* /opt/nvidia/deepstream/deepstream-6.0/lib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装最新的 NVIDIA BSP</span></span><br><span class="line">sudo vi /etc/apt/sources.list.d/nvidia-l4t-apt-source.list</span><br><span class="line"><span class="comment"># 在如下所示的 deb 命令中更改存储库名称和下载 URL：</span></span><br><span class="line">deb https://repo.download.nvidia.com/jetson/common r32.6 main</span><br><span class="line">deb https://repo.download.nvidia.com/jetson/t210 r32.6 main  <span class="comment"># t210为Jetson Nano</span></span><br><span class="line"><span class="comment"># 更新</span></span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install --reinstall nvidia-l4t-gstreamer</span><br><span class="line"><span class="comment"># 使用以下命令安装最新的 L4T MM 和 L4T Core 软件包：</span></span><br><span class="line">sudo apt install --reinstall nvidia-l4t-multimedia</span><br><span class="line">sudo apt install --reinstall nvidia-l4t-core</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 DeepStream SDK</span></span><br><span class="line"><span class="comment"># 方法一：使用SDK Manager（详见官方手册）</span></span><br><span class="line"><span class="comment"># 方法二：使用tar包</span></span><br><span class="line"><span class="comment"># 从https://developer.nvidia.com/deepstream_sdk_v6.0.0_jetsontbz2处下载tar包</span></span><br><span class="line"><span class="comment"># 输入以下命令以提取并安装 DeepStream SDK：</span></span><br><span class="line">sudo tar -xvf deepstream_sdk_v6.0.0_jetson.tbz2 -C /</span><br><span class="line"><span class="built_in">cd</span> /opt/nvidia/deepstream/deepstream-6.0</span><br><span class="line">sudo ./install.sh</span><br><span class="line">sudo ldconfig</span><br><span class="line"><span class="comment"># 方法三：使用deb包</span></span><br><span class="line"><span class="comment"># 从https://developer.nvidia.com/deepstream-6.0_6.0.0-1_arm64deb处下载deb包</span></span><br><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">sudo apt install libgstrtspserver-1.0-0 libgstreamer-plugins-base1.0-dev</span><br><span class="line">sudo dpkg -i ./deepstream-6.0_6.0.0-1_arm64.deb</span><br></pre></td></tr></table></figure>
<p>使用官方用例测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/nvidia/deepstream/deepstream-6.0/samples/configs/deepstream-app/</span><br><span class="line">deepstream-app -c source8_1080p_dec_infer-resnet_tracker_tiled_display_fp16_nano.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>如果发生<a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/failed-to-create-element-src-bin-muxer/65285">Failed to create element ‘src_bin_muxer’</a>错误，根据上述帖子中的内容，删除缓存即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> <span class="variable">$&#123;HOME&#125;</span>/.cache/gstreamer-1.0/registry.aarch64.bin</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="2-5-1-deepstream-app-配置">2.5.1 deepstream-app 配置</h5>
<p>汇总表：</p>
<table>
<thead>
<tr>
<th>组名</th>
<th>配置组</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#application-group">Application Group</a></td>
<td>与特定组件无关的应用程序配置</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#tiled-display-group">Tiled-display Group</a></td>
<td>应用程序中的平铺显示</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#source-group">Source Group</a></td>
<td>源属性。可以有多个来源。这些组必须命名为：[source0], [source1] …</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#streammux-group">Streammux Group</a></td>
<td>指定流复用组件（streammux）的属性和修改其行为</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#preprocess-group">Preprocess Group</a></td>
<td>指定预处理组件的属性和修改行为</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#primary-gie-and-secondary-gie-group">Primary GIE and Secondary GIE Group</a></td>
<td>指定主 GIE 的属性并修改其行为。指定辅助 GIE 的属性并修改其行为。这些组必须命名为：[secondary-gie0], [secondary-gie1] …</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#tracker-group">Tracker Group</a></td>
<td>指定对象跟踪器的属性并修改其行为</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#message-converter-group">Message Converter Group</a></td>
<td>指定消息转换器组件的属性和修改其行为</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#message-consumer-group">Message Consumer Group</a></td>
<td>指定属性并修改消息使用者组件的行为。管道可以包含多个消息使用者组件。组必须命名为 [message-consumer0], [message-consumer1] …</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#osd-group">OSD Group</a></td>
<td>指定属性并修改在每一帧上覆盖文本和矩形的屏幕显示 (on-screen display，OSD) 组件</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#sink-group">Sink Group</a></td>
<td>指定表示输出（例如用于渲染、编码和文件保存的显示和文件）的接收器组件（sink components）的属性并修改其行为。管道可以包含多个接收器。组必须命名为：[sink0], [sink1] …</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#tests-group">Tests Group</a></td>
<td>诊断和调试。这组是实验性的</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_ref_app_deepstream.html#nvds-analytics-group">NvDs-analytics Group</a></td>
<td>指定 nvdsanalytics 插件配置文件，并在应用程序中添加插件</td>
</tr>
</tbody>
</table>
<h6 id="Application-Group">Application Group</h6>
<table>
<thead>
<tr>
<th>Key</th>
<th>Meaning</th>
<th>Type and Value</th>
<th>Example</th>
<th>Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>enable-perf-measurement</td>
<td>指示是否启用应用程序性能测量</td>
<td>Boolean</td>
<td>enable-perf-measurement=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>perf-measurement-interval-sec</td>
<td>采样和打印性能指标的时间间隔（以秒为单位）</td>
<td>Integer, &gt;0</td>
<td>perf-measurement-interval-sec=10</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>gie-kitti-output-dir</td>
<td>应用程序以 KITTI 格式存储的主检测器输出的路径名</td>
<td>String</td>
<td>gie-kitti-output-dir=­/home/­ubuntu/­kitti_data/</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>kitti-track-output-dir</td>
<td>应用程序以 KITTI 格式存储的跟踪器输出的路径名</td>
<td>String</td>
<td>kitti-track-output-dir=­/home/­ubuntu/­kitti_data_tracker/</td>
<td>dGPU, Jetson</td>
</tr>
</tbody>
</table>
<h6 id="Tiled-display-Group">Tiled-display Group</h6>
<table>
<thead>
<tr>
<th>Key</th>
<th>Meaning</th>
<th>Type and Value</th>
<th>Example</th>
<th>Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>enable</td>
<td>表示是否启用平铺显示。当用户设置enable=2时，第一个键值为link-to-emux=1的[sink]组应被链接到demuxer的src_[source_id]垫，其中source_id是在相应的[sink]组中设置的键值</td>
<td>Integer, <br>0 = disabled<br>1 = tiler-enabled <br>2 = tiler-and-parallel-demux-to-sink-enabled</td>
<td>enable=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>rows</td>
<td>平铺二维数组中的行数</td>
<td>Integer, &gt;0</td>
<td>rows=5</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>columns</td>
<td>平铺二维数组中的列数</td>
<td>Integer, &gt;0</td>
<td>columns=6</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>width</td>
<td>平铺二维阵列的宽度，以像素为单位</td>
<td>Integer, &gt;0</td>
<td>width=1280</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>height</td>
<td>平铺二维阵列的高度，以像素为单位</td>
<td>Integer, &gt;0</td>
<td>height=720</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>gpu-id</td>
<td>在多个 GPU 的情况下，组件将使用 GPU</td>
<td>Integer, ≥0</td>
<td>gpu-id=0</td>
<td>dGPU</td>
</tr>
<tr>
<td>nvbuf-memory-type</td>
<td>组件为输出缓冲区分配的内存类型。<br>0 (nvbuf-mem-default)：特定于平台的默认类型<br>1 (nvbuf-mem-cuda-pinned): pinned/host CUDA 内存<br>2（nvbuf-mem-cuda-device）：设备CUDA内存<br>3（nvbuf-mem-cuda-unified）：统一CUDA内存<br>对于 dGPU：所有值均有效。<br>对于 Jetson：只有 0（零）有效。</td>
<td>Integer, 0, 1, 2, or 3</td>
<td>nvbuf-memory-type=3</td>
<td>dGPU, Jetson</td>
</tr>
</tbody>
</table>
<h6 id="Source-Group">Source Group</h6>
<p>DeepStream 应用程序支持多个同步源。对于每个源，必须在配置文件中添加一个单独的组，组名为 source%d 形式</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Meaning</th>
<th>Type and Value</th>
<th>Example</th>
<th>Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>enable</td>
<td>启用或禁用源</td>
<td>Boolean</td>
<td>enable=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>type</td>
<td>输入源类型；输入源的其他属性取决于此类型。<br>1：相机（V4L2）<br>2：URI<br>3：多个URI<br>4：RTSP<br>5：相机（CSI）（仅限Jetson）</td>
<td>Integer, 1, 2, 3, 4, or 5</td>
<td>type=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>uri</td>
<td>编码流的 URI。 URI 可以是文件、HTTP URI 或 RTSP 实时源。当 type=2 或 3 时有效。对于 MultiURI，%d 格式说明符也可用于指定多个源。应用程序从 0 迭代到 num-sources 以生成实际的 URI</td>
<td>String</td>
<td>uri=file:///home/ubuntu/source.mp4 uri=http://127.0.0.1/source.mp4 uri=rtsp://127.0.0.1/source1 uri=file:///home/ubuntu/source_%d.mp4</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>num-sources</td>
<td>输入源数量。仅当 type=3 时有效</td>
<td>Integer, ≥0</td>
<td>num-sources=2</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>intra-decode-enable</td>
<td>启用或禁用仅内部解码（intra-only decode）</td>
<td>Boolean</td>
<td>intra-decode-enable=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>num-extra-surfaces</td>
<td>除解码器给出的最小解码曲面外的曲面数。可用于管理管道中解码器输出缓冲区的数量</td>
<td>Integer, ≥0 and ≤24</td>
<td>num-extra-surfaces=5</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>gpu-id</td>
<td>在多个 GPU 的情况下，组件使用的 GPU</td>
<td>Integer, ≥0</td>
<td>gpu-id=1</td>
<td>dGPU</td>
</tr>
<tr>
<td>camera-id</td>
<td>要添加到元数据的输入源的唯一 ID（可选）</td>
<td>Integer, ≥0</td>
<td>camera-id=2</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>camera-width</td>
<td>从相机请求的帧宽度，以像素为单位。当type=1或5时有效</td>
<td>Integer, &gt;0</td>
<td>camera-width=1920</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>camera-height</td>
<td>从相机请求的帧高度，以像素为单位。当type=1或5时有效</td>
<td>Integer, &gt;0</td>
<td>camera-height=1080</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>camera-fps-n</td>
<td>指定相机请求的帧速率分数的分子部分，以帧/秒为单位。当 type=1 或 5 时有效</td>
<td>Integer, &gt;0</td>
<td>camera-fps-n=30</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>camera-fps-d</td>
<td>指定相机请求的帧速率分数的分母部分，以帧/秒为单位。当 type = 1 或 5 时有效</td>
<td>Integer, &gt;0</td>
<td>camera-fps-d=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>camera-v4l2-dev-node</td>
<td>V4L2设备节点编号。例如，/dev/video<num> 为打开 V4L2 相机路径。当类型设置（源类型）为 1 时有效</num></td>
<td>Integer, &gt;0</td>
<td>camera-v4l2-dev-node=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>latency</td>
<td>以毫秒为单位的抖动缓冲区大小；仅适用于 RTSP 流</td>
<td>Integer, ≥0</td>
<td>latency=200</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>camera-csi-sensor-id</td>
<td>摄像头模块的传感器 ID。当类型（源类型）为 5 时有效</td>
<td>Integer, ≥0</td>
<td>camera-csi-sensor-id=1</td>
<td>Jetson</td>
</tr>
<tr>
<td>drop-frame-interval</td>
<td>丢帧间隔。例如，5 表示解码器每五帧输出一次； 0 表示不丢帧。</td>
<td>Integer,</td>
<td>drop-frame-interval=5</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>cudadec-memtype</td>
<td>用于为类型 2,3 或 4 的源分配输出缓冲区的 CUDA 内存元素类型。不适用于 CSI 或 USB 相机源<br>0 (memtype_device)：使用 cudaMalloc() 分配的设备内存。<br>1 (memtype_pinned)：使用 cudaMallocHost() 分配的主机/固定内存。<br>2 (memtype_unified)：使用 cudaMallocManaged() 分配的统一内存。</td>
<td>Integer, 0, 1, or 2</td>
<td>cudadec-memtype=1</td>
<td>dGPU</td>
</tr>
<tr>
<td>nvbuf-memory-type</td>
<td>元素为 nvvideoconvert 的输出缓冲区分配的 CUDA 内存类型，对于类型 1 的源有用。<br>0（nvbuf-mem-default，特定于平台的默认值<br>1 (nvbuf-mem-cuda-pinned)：固定/主机 CUDA 内存。<br>2 (nvbuf-mem-cuda-device)：设备 CUDA 内存。<br>3 (nvbuf-mem-cuda-unified)：统一CUDA内存。<br>对于 dGPU：所有值均有效。<br>对于 Jetson：只有 0（零）有效。</td>
<td>Integer, 0, 1, 2, or 3</td>
<td>nvbuf-memory-type=3</td>
<td>dGPU,Jetson</td>
</tr>
<tr>
<td>select-rtp-protocol</td>
<td>用于 RTP 的传输协议。当 type（源类型）为 4 时有效<br>0：UDP + UDP 组播 + TCP<br>4：仅 TCP</td>
<td>Integer, 0 or 4</td>
<td>select-rtp-protocol=4</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>rtsp-reconnect-interval-sec</td>
<td>在强制重新连接之前从 RTSP 源接收到最后一个数据后等待的超时时间（以秒为单位）。将其设置为 0 将禁用重新连接。当 type（源类型）为 4 时有效</td>
<td>Integer, ≥0</td>
<td>rtsp-reconnect-interval-sec=60</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>rtsp-reconnect-attempts</td>
<td>尝试重新连接的最大次数。将其设置为 -1 意味着将无限尝试重新连接。当源类型为 4 且 rtsp-reconnect-interval-sec 为非零正值时有效。</td>
<td>Integer, ≥-1</td>
<td>rtsp-reconnect-attempts=2</td>
<td></td>
</tr>
<tr>
<td>smart-record</td>
<td>触发智能记录的方法。<br>0：禁用<br>1：只能通过云消息<br>2：云消息+本地事件</td>
<td>Integer, 0, 1 or 2</td>
<td>smart-record=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-dir-path</td>
<td>保存录制文件的目录路径。默认使用当前目录</td>
<td>String</td>
<td>smart-rec-dir-path=/home/nvidia/</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-file-prefix</td>
<td>录制视频的文件名前缀。默认情况下，Smart_Record 是前缀。对于唯一的文件名，必须为每个源提供唯一的前缀</td>
<td>String</td>
<td>smart-rec-file-prefix=Cam1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-cache</td>
<td>以秒为单位的智能记录缓存大小</td>
<td>Integer, ≥0</td>
<td>smart-rec-cache=20</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-container</td>
<td>录制视频的容器格式。支持 MP4 和 MKV 容器</td>
<td>Integer, 0 or 1</td>
<td>smart-rec-container=0</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-start-time</td>
<td>从现在开始记录的提前秒数。例如。如果 t0 是当前时间，N 是开始时间（以秒为单位），这意味着录制将从 t0 – N 开始。显然要使其工作，视频缓存大小必须大于 N</td>
<td>Integer, ≥0</td>
<td>smart-rec-start-time=5</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-default-duration</td>
<td>如果未生成停止事件。此参数将确保在预定义的默认持续时间后停止录制</td>
<td>Integer, ≥0</td>
<td>smart-rec-default-duration=20</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-duration</td>
<td>以秒为单位的记录持续时间</td>
<td>Integer, ≥0</td>
<td>smart-rec-duration=15</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>smart-rec-interval</td>
<td>这是 SR 启动/停止事件生成的时间间隔（以秒为单位）</td>
<td>Integer, ≥0</td>
<td>smart-rec-interval=10</td>
<td>dGPU, Jetson</td>
</tr>
</tbody>
</table>
<h6 id="Streammux-Group">Streammux Group</h6>
<p>[streammux] 组指定和修改 Gst-nvstreammux 插件的属性</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Meaning</th>
<th>Type and Value</th>
<th>Example</th>
<th>Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>gpu-id</td>
<td>GPU element is to use in case of multiple GPUs.</td>
<td>Integer, ≥0</td>
<td>gpu-id=1</td>
<td>dGPU</td>
</tr>
<tr>
<td>live-source</td>
<td>通知多路复用器（muxer），输入源是实时的</td>
<td>Boolean</td>
<td>live-source=0</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>buffer-pool-size</td>
<td>Muxer 输出缓冲池中的缓冲区数</td>
<td>Integer, &gt;0</td>
<td>buffer-pool-size=4</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>batch-size</td>
<td>Muxer batch size.</td>
<td>Integer, &gt;0</td>
<td>batch-size=4</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>batched-push-timeout</td>
<td>在第一个缓冲区可用后，推送批次（batch）后的超时时间（以微秒为单位），即使没有形成完整的批次（batch）</td>
<td>Integer, ≥−1</td>
<td>batched-push-timeout=40000</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>width</td>
<td>多路复用器（Muxer）输出宽度（以像素为单位）</td>
<td>Integer, &gt;0</td>
<td>width=1280</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>height</td>
<td>多路复用器（Muxer）输出高度（以像素为单位）</td>
<td>Integer, &gt;0</td>
<td>height=720</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>enable-padding</td>
<td>在通过添加黑带（black bands）进行缩放时是否保持源纵横比</td>
<td>Boolean</td>
<td>enable-padding=0</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>nvbuf-memory-type</td>
<td>组件为输出缓冲区分配的 CUDA 内存类型。<br>0（nvbuf-mem-default，特定于平台的默认值<br>1 (nvbuf-mem-cuda-pinned)：固定/主机 CUDA 内存。<br>2 (nvbuf-mem-cuda-device)：设备 CUDA 内存。<br>3 (nvbuf-mem-cuda-unified)：统一CUDA内存。<br>对于 dGPU：所有值均有效。<br>对于 Jetson：只有 0（零）有效。</td>
<td>Integer, 0, 1, 2, or 3</td>
<td>nvbuf-memory-type=3</td>
<td>dGPU</td>
</tr>
<tr>
<td>attach-sys-ts-as-ntp</td>
<td>对于实时源，当流式传输 RTSP 时，混合缓冲区（muxed buffer）应将关联的 NvDsFrameMeta-&gt;ntp_timestamp 设置为系统时间或服务器的 NTP 时间。<br>如果设置为 1，系统时间戳将作为 ntp 时间戳附加。<br>如果设置为 0，则将附加来自 rtspsrc 的 ntp 时间戳（如果可用）。</td>
<td>Boolean</td>
<td>attach-sys-ts-as-ntp=0</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>config-file-path</td>
<td>此key仅对新streammux有效。请参阅插件手册“New Gst nvstreammux”部分了解更多信息。mux配置文件的绝对或相对（DS配置文件位置）路径</td>
<td>String</td>
<td>config-file-path=config_mux_source30.txt</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>sync-inputs</td>
<td>在批处理之前对输入帧进行时间同步</td>
<td>Boolean</td>
<td>sync-inputs=0 (default)</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>max-latency</td>
<td>实时模式下的额外延迟，以允许上游花费更长的时间来为当前位置（以纳秒为单位）生成缓冲区</td>
<td>Integer, ≥0</td>
<td>max-latency=0 (default)</td>
<td>dGPU, Jetson</td>
</tr>
</tbody>
</table>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvstreammux2.html">Gst-nvstreammux New (Beta) — DeepStream 6.0 Release documentation (nvidia.com)</a></li>
</ul>
<h6 id="Preprocess-Group">Preprocess Group</h6>
<p>[pre-process] 组用于在管道中添加 nvdspreprocess 插件。仅支持主 GIE 的预处理</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Meaning</th>
<th>Type and Value</th>
<th>Example</th>
<th>Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>enable</td>
<td>Enables or disables the plugin.</td>
<td>Boolean</td>
<td>enable=1</td>
<td>dGPU, Jetson</td>
</tr>
<tr>
<td>config-file</td>
<td>Configuration file path for nvdspreprocess plugin</td>
<td>String</td>
<td>config-file=config_preprocess.txt</td>
<td>dGPU, Jetson</td>
</tr>
</tbody>
</table>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvdspreprocess.html">Gst-nvdspreprocess (Alpha) — DeepStream 6.0 Release documentation (nvidia.com)</a></li>
</ul>
<h6 id="Primary-GIE-and-Secondary-GIE-Group">Primary GIE and Secondary GIE Group</h6>
<p>DeepStream应用程序支持多个二级GIE（GPU Inference Engines）。对于每个次要GIE，必须将名为 secondary-gie%d 的单独组添加到配置文件中</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Meaning</th>
<th>Type and Value</th>
<th>Example</th>
<th>Platforms/ GIEs*</th>
</tr>
</thead>
<tbody>
<tr>
<td>enable</td>
<td>是否必须启用主 GIE</td>
<td>Boolean</td>
<td>enable=1</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>gie-unique-id</td>
<td>要分配给 nvinfer 实例的唯一组件 ID。用于标识实例生成的元数据</td>
<td>Integer, &gt;0</td>
<td>gie-unique-id=2</td>
<td>Both</td>
</tr>
<tr>
<td>gpu-id</td>
<td>在多个 GPU 的情况下，组件将使用的 GPU</td>
<td>Integer, ≥0</td>
<td>gpu-id=1</td>
<td>dGPU, Both GIEs</td>
</tr>
<tr>
<td>model-engine-file</td>
<td>模型预生成序列化引擎文件的绝对路径名</td>
<td>String</td>
<td>model-engine-file=­…/…/ models/­Primary_Detector/­resnet10. caffemodel_b4_int8.engine</td>
<td>Both GIEs</td>
</tr>
<tr>
<td>nvbuf-memory-type</td>
<td>CUDA 内存元素的类型是分配给输出缓冲区。<br>0 (nvbuf-mem-default)：特定于平台的默认值<br>1 (nvbuf-mem-cuda-pinned): pinned/host CUDA 内存<br>2（nvbuf-mem-cuda-device）：设备CUDA内存<br>3（nvbuf-mem-cuda-unified）：统一CUDA内存<br>对于 dGPU：所有值均有效。<br>对于 Jetson：只有 0（零）有效。</td>
<td>Integer, 0, 1, 2, or 3</td>
<td>nvbuf-memory-type=3</td>
<td>dGPU, Jetson Primary GIE</td>
</tr>
<tr>
<td>config-file</td>
<td>指定 Gst-nvinfer 插件属性的配置文件的路径名。它可能包含此表中描述的任何属性，但配置文件本身除外。属性必须在名为 [property] 的组中定义。有关参数的更多详细信息，请参阅 DeepStream 4.0 插件手册中的“Gst-nvinfer 文件配置规范”。</td>
<td>String</td>
<td>config-file=¬/home/-ubuntu/-config_infer_resnet.txt For complete examples, see the sample file samples/¬configs/-deepstream-app/-config_infer_resnet.txt or the deepstream-test2 sample application.</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>batch-size</td>
<td>在一个批次中要一起推断的帧（P.GIE）/对象（S.GIE）的数量</td>
<td>Integer, &gt;0 Integer, &gt;0</td>
<td>batch-size=2</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>interval</td>
<td>跳过推理的连续批次数</td>
<td>Integer, &gt;0 Integer, &gt;0</td>
<td>interval=2</td>
<td>dGPU, Jetson Primary GIE</td>
</tr>
<tr>
<td>bbox-border-color</td>
<td>特定类 ID 的对象的边框颜色，以 RGBA 格式指定。key的格式必须为 bbox-border-color<class-id>。可以为多个类 ID 多次标识此属性。如果未为类 ID 标识此属性，则不会为该类 ID 的对象绘制边框。</class-id></td>
<td>R:G:B:A Float, 0≤R,G,B,A≤1</td>
<td>bbox-border-color2= 1;0;0;1 (Red for class-id 2)</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>bbox-bg-color</td>
<td>特定类 ID 的对象上绘制的框的颜色，采用 RGBA 格式。key的格式必须为 bbox-bg-color<class-id>。此属性可以多次用于多个类 ID。如果它不用于类 ID，则不会为该类 ID 的对象绘制框。</class-id></td>
<td>R:G:B:A Float, 0≤R,G,B,A≤1</td>
<td>bbox-bg-color3=-0;1;0;0.3 (Semi-transparent green for class-id 3)</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>operate-on-gie-id</td>
<td>GIE 的唯一 ID，此 GIE 将在其元数据 (NvDsFrameMeta) 上运行</td>
<td>Integer, &gt;0</td>
<td>operate-on-gie-id=1</td>
<td>dGPU, Jetson Secondary GIE</td>
</tr>
<tr>
<td>operate-on-class-ids</td>
<td>此 GIE 必须在其上运行的父 GIE 的类 ID。使用 operation-on-gie-id 指定父 GIE。</td>
<td>Semicolon separated integer array</td>
<td>operate-on-class-ids=1;2 (operate on objects with class IDs 1, 2 generated by parent GIE)</td>
<td>dGPU, Jetson Secondary GIE</td>
</tr>
<tr>
<td>infer-raw-output-dir</td>
<td>Pathname of an existing directory in which to dump the raw inference buffer contents in a file.</td>
<td>String</td>
<td>infer-raw-output-dir=­/home/­ubuntu/­infer_raw_out</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>labelfile-path</td>
<td>Pathname of the labelfile.</td>
<td>String</td>
<td>labelfile-path=…/…/models/Primary_Detector/labels.txt</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>plugin-type</td>
<td>Plugin to use for inference. 0: nvinfer (TensorRT) 1: nvinferserver (Triton inference server)</td>
<td>Integer, 0 or 1</td>
<td>plugin-type=1</td>
<td>dGPU, Jetson Both GIEs</td>
</tr>
<tr>
<td>input-tensor-meta</td>
<td>Use preprocessed input tensors attached as metadata by nvdspreprocess plugin instead of preprocessing inside the nvinfer.</td>
<td>Integer, 0 or 1</td>
<td>input-tensor-meta=1</td>
<td>dGPU, Jetson, Primary GIE</td>
</tr>
</tbody>
</table>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvinfer.html">Gst-nvinfer — DeepStream 6.0 Release documentation (nvidia.com)</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">spaceman</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://nu-ll.github.io/2020/08/20/JetsonNano%E6%8C%87%E5%8D%97/">http://nu-ll.github.io/2020/08/20/JetsonNano指南/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://NU-LL.github.io" target="_blank">spaceman</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/JetsonNano/">JetsonNano</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/08/23/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"><img class="prev-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Linux常用命令汇总</div></div></a></div><div class="next-post pull-right"><a href="/2020/08/19/%E5%A4%A7%E7%96%86%E5%B5%8C%E5%85%A5%E5%BC%8F%E6%8B%9B%E8%81%98%E6%84%9F%E6%82%9F/"><img class="next-cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大疆嵌入式招聘感悟</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/12/JetsonNano%20Multimedia%20API%E5%B7%A5%E7%A8%8B%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%BC%96%E8%AF%91/" title="JetsonNano Multimedia API工程搭建及编译"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2022-05-12</div><div class="title">JetsonNano Multimedia API工程搭建及编译</div></div></a></div><div><a href="/2022/03/15/JetsonNano%E6%91%84%E5%83%8F%E5%A4%B4%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/" title="JetsonNano摄像头驱动开发指南"><img class="cover" src="https://gitee.com/NU-LL/image-host/raw/master/12.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2022-06-20</div><div class="title">JetsonNano摄像头驱动开发指南</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/spaceman.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">spaceman</div><div class="author-info__description">CtrlC CtrlV大师</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">101</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/NU-LL"><i class="fab fa-github"></i><span>Github</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">白嫖一时爽，一直白嫖一直爽</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">JetsonNano指南</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%85%A5%E9%97%A8"><span class="toc-text">一、入门</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%86%E5%A4%87"><span class="toc-text">1.准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%BC%80%E5%A7%8B"><span class="toc-text">2.开始</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-text">二、基本环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85%E6%BA%90"><span class="toc-text">1.更换国内源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85CUDA"><span class="toc-text">2.安装CUDA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%85%8D%E7%BD%AEpython"><span class="toc-text">3.配置python</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%89%E8%A3%85Code-OSS"><span class="toc-text">4.安装Code OSS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%AE%89%E8%A3%85OPENCV"><span class="toc-text">5.安装OPENCV</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1python%E7%8E%AF%E5%A2%83"><span class="toc-text">5.1python环境</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2%E6%91%84%E5%83%8F%E5%A4%B4%E8%AF%BB%E5%8F%96"><span class="toc-text">5.2摄像头读取</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%91%84%E5%83%8F%E5%A4%B4%E5%8F%82%E6%95%B0"><span class="toc-text">读取摄像头参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96CSI%E6%91%84%E5%83%8F%E5%A4%B4%E5%BC%82%E5%B8%B8"><span class="toc-text">读取CSI摄像头异常</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CSI%E6%91%84%E5%83%8F%E5%A4%B4"><span class="toc-text">CSI摄像头</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#USB%E6%91%84%E5%83%8F%E5%A4%B4"><span class="toc-text">USB摄像头</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%AE%89%E8%A3%85VNC%E6%9C%8D%E5%8A%A1"><span class="toc-text">6.安装VNC服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%EF%BC%9A%E6%B0%B4%E6%B5%81%E6%A3%80%E6%B5%8B%E4%BB%A3%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-text">实验：水流检测代码环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E7%BC%96%E8%AF%91%E5%B9%B6%E5%AE%89%E8%A3%85opencv"><span class="toc-text">手动编译并安装opencv</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%96%E8%AF%91-2"><span class="toc-text">编译</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%93%BE%E6%8E%A5%E5%88%B0python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83"><span class="toc-text">链接到python虚拟环境</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pytorch%E5%AE%89%E8%A3%85"><span class="toc-text">pytorch安装</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%96%E8%AF%91-3"><span class="toc-text">编译</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81"><span class="toc-text">验证</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#torchvision%E5%AE%89%E8%A3%85"><span class="toc-text">torchvision安装</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85FCOS%E7%8E%AF%E5%A2%83"><span class="toc-text">安装FCOS环境</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-text">三、深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-jetson-inference%E9%A1%B9%E7%9B%AE"><span class="toc-text">1.jetson-inference项目</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-text">1.1环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#docker%E6%96%B9%E5%BC%8F"><span class="toc-text">docker方式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%BA%90%E7%A0%81%E6%96%B9%E5%BC%8F"><span class="toc-text">源码方式</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2%E6%8E%A8%E7%90%86"><span class="toc-text">1.2推理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-1%E5%88%86%E7%B1%BB%EF%BC%88ImageNet%EF%BC%89"><span class="toc-text">1.2.1分类（ImageNet）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-2%E6%A3%80%E6%B5%8B%EF%BC%88DetectNet%EF%BC%89"><span class="toc-text">1.2.2检测（DetectNet）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-3%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%EF%BC%88SegNet%EF%BC%89"><span class="toc-text">1.2.3语义分割（SegNet）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3%E8%AE%AD%E7%BB%83"><span class="toc-text">1.3训练</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-tensorRT-yolov5"><span class="toc-text">2.tensorRT+yolov5</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-PyCUDA%E5%AE%89%E8%A3%85"><span class="toc-text">2.1 PyCUDA安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-cuDNN%E5%AE%89%E8%A3%85"><span class="toc-text">2.2 cuDNN安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-tensorRT%E5%AE%89%E8%A3%85"><span class="toc-text">2.3 tensorRT安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="toc-text">2.4 模型转换</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-1-%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%88%E6%9A%82%E6%9C%AA%E9%80%9A%E8%BF%87%EF%BC%89"><span class="toc-text">2.4.1 方案一（暂未通过）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-2-%E6%96%B9%E6%A1%88%E4%BA%8C"><span class="toc-text">2.4.2 方案二</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5-DeepStream"><span class="toc-text">2.5 DeepStream</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-5-1-deepstream-app-%E9%85%8D%E7%BD%AE"><span class="toc-text">2.5.1 deepstream-app 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Application-Group"><span class="toc-text">Application Group</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Tiled-display-Group"><span class="toc-text">Tiled-display Group</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Source-Group"><span class="toc-text">Source Group</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Streammux-Group"><span class="toc-text">Streammux Group</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Preprocess-Group"><span class="toc-text">Preprocess Group</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Primary-GIE-and-Secondary-GIE-Group"><span class="toc-text">Primary GIE and Secondary GIE Group</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/10/06/openwrt%E5%AE%89%E8%A3%85transmission/" title="openwrt安装transmission.md">openwrt安装transmission.md</a><time datetime="2022-10-06T15:37:29.000Z" title="发表于 2022-10-06 23:37:29">2022-10-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/08/14/Linux%20perl%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/" title="Linux perl性能分析工具">Linux perl性能分析工具</a><time datetime="2022-08-14T09:17:28.000Z" title="发表于 2022-08-14 17:17:28">2022-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/08/05/C++%20%E8%99%9A%E5%87%BD%E6%95%B0%E3%80%81%E7%BA%AF%E8%99%9A%E5%87%BD%E6%95%B0/" title="C++ 虚函数、纯虚函数">C++ 虚函数、纯虚函数</a><time datetime="2022-08-04T16:05:23.000Z" title="发表于 2022-08-05 00:05:23">2022-08-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/26/VEYE%E6%91%84%E5%83%8F%E5%A4%B4%E8%B0%83%E8%AF%95/" title="VEYE摄像头调试">VEYE摄像头调试</a><time datetime="2022-06-26T08:37:45.000Z" title="发表于 2022-06-26 16:37:45">2022-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/06/%E5%9F%BA%E4%BA%8EVSCode%E6%90%AD%E5%BB%BAESP-IDF%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/" title="基于VSCode搭建ESP-IDF开发环境">基于VSCode搭建ESP-IDF开发环境</a><time datetime="2022-06-06T06:27:54.000Z" title="发表于 2022-06-06 14:27:54">2022-06-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By spaceman</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><script type="text/javascript" src="https://api.uixsj.cn/hitokoto/w.php?code=js"></script><div id="xsjhitokoto"><script>xsjhitokoto()</script></div> <iframe scrolling="no" src="https://tianqiapi.com/api.php?style=tx&color=eee" frameborder="0" allowtransparency="false" align="middle" height="20"></iframe></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>