<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>lidar摄像头融合 | spaceman</title><meta name="keywords" content="传感器融合"><meta name="author" content="spaceman"><meta name="copyright" content="spaceman"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="A novel approach for fusing LIDAR and visual camera images in unstructured environment  B. Yohannan and D. A. Chandy, “A novel approach for fusing LIDAR and visual camera images in unstructured enviro">
<meta property="og:type" content="article">
<meta property="og:title" content="lidar摄像头融合">
<meta property="og:url" content="http://nu-ll.github.io/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/index.html">
<meta property="og:site_name" content="spaceman">
<meta property="og:description" content="A novel approach for fusing LIDAR and visual camera images in unstructured environment  B. Yohannan and D. A. Chandy, “A novel approach for fusing LIDAR and visual camera images in unstructured enviro">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/NU-LL/image-host/raw/master/12.jpg">
<meta property="article:published_time" content="2021-04-02T02:50:34.000Z">
<meta property="article:modified_time" content="2021-04-05T15:26:40.569Z">
<meta property="article:author" content="spaceman">
<meta property="article:tag" content="传感器融合">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/NU-LL/image-host/raw/master/12.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://nu-ll.github.io/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'lidar摄像头融合',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-04-05 23:26:40'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/spaceman.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">92</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fas fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://gitee.com/NU-LL/image-host/raw/master/12.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">spaceman</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/todo/"><i class="fa-fw fas fa-list"></i><span> 清单</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">lidar摄像头融合</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-04-02T02:50:34.000Z" title="发表于 2021-04-02 10:50:34">2021-04-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-04-05T15:26:40.569Z" title="更新于 2021-04-05 23:26:40">2021-04-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="lidar摄像头融合"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8014604/">A novel approach for fusing LIDAR and visual camera images in unstructured environment</a></h1>
<blockquote>
<p>B. Yohannan and D. A. Chandy, “A novel approach for fusing LIDAR and visual camera images in unstructured environment,” 2017 4th International Conference on Advanced Computing and Communication Systems (ICACCS), Coimbatore, India, 2017, pp. 1-5, doi: 10.1109/ICACCS.2017.8014604.</p>
<p>Abstract: Image fusion is the process of merging all similar information from two or more images into a single image. The aim is to provide an image fusion method for fusing the images from the different modalities so that the fusion image will give more information without losing input information and also without any redundancy. This paper gives the efficient method for fusion purpose, by fusing LIDAR and visual camera images. The objective of this proposed method is to develop an image fusion algorithm and its applications in automated navigation in an unstructured environment.</p>
<p>图像融合是将来自两个或更多图像的所有相似信息合并为一个图像的过程。目的是提供一种用于融合来自不同模态的图像的图像融合方法，使得融合图像将给出更多的信息而不会丢失输入信息，并且也没有任何冗余。通过融合激光雷达图像和摄像机图像，给出了一种有效的融合方法。该方法的目的是开发一种图像融合算法及其在非结构化环境中的自动导航中的应用。</p>
<p>keywords: {Cameras;Laser radar;Image fusion;Image edge detection;Visualization;Sensors;Communication systems;Image fusion;Edge detection;Background removal;LIDAR;Ford campus vision}</p>
<p>URL: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8014604&amp;isnumber=8014556">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8014604&amp;isnumber=8014556</a></p>
</blockquote>
<p>主要采用全方位摄像机（5个摄像头）与lidar（该lidar能够直接出图），基本步骤为：</p>
<ol>
<li>图像采集</li>
<li>将两种图片均转为灰度图片</li>
<li>边缘检测</li>
<li>删除背景</li>
<li>调整图像大小并旋转图像</li>
</ol>
<p>融合结果如下：</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/8014604-fig-17-source-small.gif" alt="最终融合图"></p>
<p>对硬件要求比较高，融合简单粗暴，直接通过图像叠加实现，整篇文章的重点在检测出边缘后将天空等无用背景删除，因为lidar成像是不包括天空的</p>
<h1><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8806579">Sensor Fusion of a Camera and 2D LIDAR for Lane Detection</a></h1>
<blockquote>
<p>Y. Yenıaydin and K. W. Schmidt, “Sensor Fusion of a Camera and 2D LIDAR for Lane Detection,” 2019 27th Signal Processing and Communications Applications Conference (SIU), Sivas, Turkey, 2019, pp. 1-4, doi: 10.1109/SIU.2019.8806579.</p>
<p>Abstract: This paper presents a novel lane detection algorithm based on fusion of camera and 2D LIDAR data. On the one hand, objects on the road are detected via 2D LIDAR. On the other hand, binary bird’s eye view (BEV) images are acquired from the camera data and the locations of objects detected by LIDAR are estimated on the BEV image. In order to remove the noise generated by objects on the BEV, a modified BEV image is obtained, where pixels occluded by the detected objects are turned into background pixels. Then, lane detection is performed on the modified BEV image. Computational and experimental evaluations show that the proposed method significantly increases the lane detection accuracy.</p>
<p>本文提出了一种基于摄像机和二维激光雷达数据融合的新型车道检测算法。一方面，通过2D LIDAR检测道路上的物体。另一方面，从照相机数据获取<strong>二元鸟瞰图</strong>（BEV）图像，并在BEV图像上估计由LIDAR检测到的物体的位置。为了消除由BEV上的物体产生的噪声，获得了修改后的BEV图像，在该图像中，被检测到的物体所遮挡的像素被转换为背景像素。然后，对修改后的BEV图像执行车道检测。计算和实验评估表明，该方法大大提高了车道检测的准确性。</p>
<p>keywords: {Laser radar;Cameras;Two dimensional displays;Roads;Image segmentation;Feature extraction;Transforms;2D LIDAR;camera;lane detection;modified bird’s eye view;sensor fusion}</p>
<p>URL: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8806579&amp;isnumber=8806230">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8806579&amp;isnumber=8806230</a></p>
</blockquote>
<p>这篇论文主要是通过lidar排除摄像头在识别车道线时一些外界的干扰，因为在有些时候车道线可能会被前方车辆挡住，此时通过摄像头获取的结果就会有前车的干扰。其基本思路如下：</p>
<ol>
<li>
<p>从摄像头和lidar上获取原始数据，假设摄像头上获取的直接是二元鸟瞰图（BEV）图像</p>
</li>
<li>
<p>将lidar上的点进行聚类，并将lidar上的点通过下式映射到摄像头图像上</p>
\begin{equation*} P^{c}=RP^{l}+t \tag{1} \end{equation*}

\begin{equation*} \gamma\cdot[u\ v\ 1]^{T}=HK(RP^{l}+t) \tag{2} \end{equation*}

</li>
<li>
<p>标出lidar对象的矩形，再通过摄像头和矩形的连线确定背景区域，然后直接删除该部分区域进行后续车道线识别</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/bildiri_27-fig-3-source-small.gif" alt="背景筛选"></p>
</li>
<li>
<p>最终结果：</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/image-20210402182511297.png" alt="结果"></p>
</li>
</ol>
<blockquote>
<p>式子1中旋转矩阵R和变换向量t的获取可以参考以下论文</p>
<ul>
<li>L. Zhou and Z. Deng, “Extrinsic calibration of a camera and a lidar based on decoupling the rotation from translation”, <em>IEEE Intelligent Vehicles Symposium (□)</em>, pp. 642-648, 2012.</li>
<li>Z. Lipu and Z. Deng, “A new algorithm for extrinsic calibration of a 2D LIDAR and a camera”, <em>Measurement Science and Technology</em>, vol. 25, no. 6, 2014.</li>
</ul>
</blockquote>
<p>优点：硬件简单，仅仅利用一个二维lidar+普通摄像头，本文还考虑到了lidar识别的高度在摄像头成像中的偏差，并且最后进行了纠正</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/bildiri_27-fig-7-source-small.gif" alt="纠正lidar高度产生的误差"></p>
<h1><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9008742">An advanced object classification strategy using YOLO through camera and LiDAR sensor fusion</a></h1>
<blockquote>
<p>J. Kim, J. Kim and J. Cho, “An advanced object classification strategy using YOLO through camera and LiDAR sensor fusion,” 2019 13th International Conference on Signal Processing and Communication Systems (ICSPCS), Gold Coast, QLD, Australia, 2019, pp. 1-5, doi: 10.1109/ICSPCS47537.2019.9008742.</p>
<p>Abstract: In this paper, we propose weighted-mean YOLO to improve real-time performance of object detection by fusing information of RGB camera and LIDAR. RGB camera is vulnerable to external environments and therefore strongly affected by illumination. Conversely, LIDAR is robust to external environments, but has low resolution. Since each sensor can complement their disadvantages, we propose a method to improve the performance of object detection through sensor fusion. We design the system using weighted-mean to construct a robust system and compared with other algorithms, it shows performance improvement of missed-detection.</p>
<p>在本文中，我们提出了加权平均YOLO，通过融合RGB摄像机和LIDAR的信息来提高物体检测的实时性能。 RGB相机易受外部环境影响，因此会受到照明的强烈影响。相反，激光雷达对外部环境具有鲁棒性，但分辨率较低。由于每个传感器都可以弥补其缺点，因此我们提出了一种通过传感器融合来提高目标检测性能的方法。我们使用加权均值设计系统，以构建一个健壮的系统，并与其他算法进行比较，它显示出漏检性能的提高。</p>
<p>keywords: {Object detection;Cameras;Laser radar;Feature extraction;Reflectivity;Sensor fusion;Three-dimensional displays;YOLO;real-time;object detection;sensor fusion;LIDAR}</p>
<p>URL: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9008742&amp;isnumber=9008412">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9008742&amp;isnumber=9008412</a></p>
</blockquote>
<p>术语：</p>
<ul>
<li>PCD（Point Cloud Data）：点云数据</li>
</ul>
<p>整篇论文的基本框图如下所示：</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/kim1-d3-p13-kim-small.gif" alt="基本框图"></p>
<p>文章直接使用的Kim数据集，其中用的lidar所采集的数据格式为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y,z,r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>，其中r为信号的反射强度。文章首先将3D点云投射到摄像头采集的图像上，然后将其分离为深度图和反射强度图。再先后将三种图分别通过三个YOLO网络，每个网络得到一个物体边界信息b和种类概率信息c，然后通过加权每个图的概率c，得到：</p>
\begin{align*}b.b_{f}=\left(\displaystyle \frac{\Sigma_{k}x_{k^{C}k}}{\Sigma_{k}c_{k}},\displaystyle \frac{\Sigma_{k}y_{k^{C}k}}{\Sigma_{k}c_{k}},\displaystyle \frac{\Sigma_{k}w_{k^{C}k}}{\Sigma_{k}c_{k}},\displaystyle \frac{\Sigma_{k}h_{k}c_{k}}{\Sigma_{k}c_{k}}\right) \tag{3}\end{align*}

<p>整个模型在PC上跑，平均总共耗时77ms，其他时间如下：</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/kim5-d3-p13-kim-small.gif" alt="平均处理时间"></p>
<p>前三个网络以及加上WM-YOLO网络的精度如下：</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/kim.t1-d3-p13-kim-small.gif" alt="Table I"></p>
<p>整篇论文的核心就是上述WM-YOLO网络，其实就是做了个简单的加权，但是通过最后结果观察效果却好很多</p>
<h1><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/7390258">Robust Vision-Based Relative-Localization Approach Using an RGB-Depth Camera and LiDAR Sensor Fusion</a></h1>
<blockquote>
<p>H. Song, W. Choi and H. Kim, “Robust Vision-Based Relative-Localization Approach Using an RGB-Depth Camera and LiDAR Sensor Fusion,” in IEEE Transactions on Industrial Electronics, vol. 63, no. 6, pp. 3725-3736, June 2016, doi: 10.1109/TIE.2016.2521346.</p>
<p>Abstract: This paper describes a robust vision-based relative-localization approach for a moving target based on an RGB-depth (RGB-D) camera and sensor measurements from two-dimensional (2-D) light detection and ranging (LiDAR). With the proposed approach, a target’s three-dimensional (3-D) and 2-D position information is measured with an RGB-D camera and LiDAR sensor, respectively, to find the location of a target by incorporating visual-tracking algorithms, depth information of the structured light sensor, and a low-level vision-LiDAR fusion algorithm, e.g., extrinsic calibration. To produce 2-D location measurements, both visual- and depth-tracking approaches are introduced, utilizing an adaptive color-based particle filter (ACPF) (for visual tracking) and an interacting multiple-model (IMM) estimator with intermittent observations from depth-image segmentation (for depth image tracking). The 2-D LiDAR data enhance location measurements by replacing results from both visual and depth tracking; through this procedure, multiple LiDAR location measurements for a target are generated. To deal with these multiple-location measurements, we propose a modified track-to-track fusion scheme. The proposed approach shows robust localization results, even when one of the trackers fails. The proposed approach was compared to position data from a Vicon motion-capture system as the ground truth. The results of this evaluation demonstrate the superiority and robustness of the proposed approach.</p>
<p>本文介绍了基于RGB深度（RGB-D）相机和来自二维（2-D）光检测和测距（LiDAR）的传感器测量结果的，基于运动的目标的基于视觉的鲁棒相对定位方法。通过提出的方法，分别使用RGB-D相机和LiDAR传感器测量目标的三维（3-D）和2-D位置信息，以通过结合视觉跟踪算法，深度来找到目标的位置结构化光传感器的信息以及低级视觉-LiDAR融合算法（例如，外部校准）。为了产生二维位置测量，引入了视觉跟踪和深度跟踪方法，利用自适应的基于颜色的粒子滤波（ACPF）（用于视觉跟踪）和交互的多模型（IMM）估计器以及来自深度的间歇性观察-图像分割（用于深度图像跟踪）。二维LiDAR数据通过替换视觉和深度跟踪的结果来增强位置测量；通过此过程，将生成目标的多个LiDAR位置测量值。为了处理这些多位置测量，我们提出了一种改进的轨道间融合方案。所提出的方法显示出鲁棒的定位结果，即使其中一个跟踪器发生故障也是如此。将拟议的方法与来自Vicon运动捕捉系统的位置数据作了比较，作为基本事实。评估结果证明了该方法的优越性和鲁棒性。</p>
<p>keywords: {Laser radar;Cameras;Target tracking;Robustness;Robot sensing systems;Calibration;Localization;RGB-D camera;LiDAR;Visual tracking;Depth segmentation;Intermittent observation;Interacting multiple Model;Modified track to track fusion;Depth segmentation;interacting multiple model (IMM);intermittent observation;light detection and ranging (LiDAR);localization;modified track-to-track fusion;RGB-depth (RGB-D) camera;visual tracking}</p>
<p>URL: <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7390258&amp;isnumber=7467584">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7390258&amp;isnumber=7467584</a></p>
</blockquote>
<p>本文首先通过使用外在校准算法将摄像头和lidar进行低级融合，然后通过一个视觉跟踪器和一个深度跟踪器选择一个ROI，并对此区域进行精确测量，最后提出一种改进的轨道间融合的算法进行本地化的融合</p>
<p>整篇论文首先是通过使用视觉跟踪+lidar，结果发现效果不是很好，进而改用深度跟踪+lidar。其中深度跟踪算法这块是整篇论文的核心。</p>
<h1><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.04554">RoIFusion: 3D Object Detection from LiDAR and Vision</a></h1>
<blockquote>
<p>When localizing and detecting 3D objects for autonomous driving scenes, obtaining information from multiple sensor (e.g. camera, LIDAR) typically increases the robustness of 3D detectors. However, the efficient and effective fusion of different features captured from LIDAR and camera is still challenging, especially due to the sparsity and irregularity of point cloud distributions. This notwithstanding, point clouds offer useful complementary information. In this paper, we would like to leverage the advantages of LIDAR and camera sensors by proposing a deep neural network architecture for the fusion and the efficient detection of 3D objects by identifying their corresponding 3D bounding boxes with orientation. In order to achieve this task, instead of densely combining the point-wise feature of the point cloud and the related pixel features, we propose a novel fusion algorithm by projecting a set of 3D Region of Interests (RoIs) from the point clouds to the 2D RoIs of the corresponding the images. Finally, we demonstrate that our deep fusion approach achieves state-of-the-art performance on the KITTI 3D object detection challenging benchmark.</p>
<p>URL:<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2009.04554">https://arxiv.org/pdf/2009.04554</a></p>
</blockquote>
<p>本文采用KITTI数据集进行测试，通过设计出一个轻量级的RolFusion网络来解决融合问题：其主要由一个关键点生成层提取估计对象上的关键点，再通过一个投票层产生对象的中心点，并根据该中心点生成一个三维ROI，最后通过RolFusion层将生成的三维ROI与对应的二维ROI进行融合</p>
<p><img src="/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/image-20210405221514341.png" alt="RolFusion框图"></p>
<p>该文章通过lidar数据来计算ROI从而达到筛选有用数据的目的，从而避免了大量的冗余计算，和第二篇文章有点异曲同工</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">spaceman</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://nu-ll.github.io/2021/04/02/lidar%E6%91%84%E5%83%8F%E5%A4%B4%E8%9E%8D%E5%90%88/">http://nu-ll.github.io/2021/04/02/lidar摄像头融合/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://NU-LL.github.io" target="_blank">spaceman</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88/">传感器融合</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/NU-LL/image-host/raw/master/12.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/04/12/conda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"><img class="prev-cover" src="https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">conda常用命令</div></div></a></div><div class="next-post pull-right"><a href="/2021/04/01/C++%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><img class="next-cover" src="https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">C++设计模式</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/10/20/%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88/" title="传感器融合"><img class="cover" src="https://gitee.com/NU-LL/image-host/raw/master/139-150515124111.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-04-02</div><div class="title">传感器融合</div></div></a></div><div><a href="/2021/03/12/%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE%E8%9E%8D%E5%90%88%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/" title="毫米波雷达融合相关论文"><img class="cover" src="https://gitee.com/NU-LL/image-host/raw/master/12.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-04-02</div><div class="title">毫米波雷达融合相关论文</div></div></a></div><div><a href="/2021/05/11/%E8%9E%8D%E5%90%88%E6%80%BB%E7%BB%93/" title="融合总结"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2021-05-16</div><div class="title">融合总结</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/spaceman.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">spaceman</div><div class="author-info__description">CtrlC CtrlV大师</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">92</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/NU-LL"><i class="fab fa-github"></i><span>Github</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">白嫖一时爽，一直白嫖一直爽</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">A novel approach for fusing LIDAR and visual camera images in unstructured environment</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">Sensor Fusion of a Camera and 2D LIDAR for Lane Detection</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">An advanced object classification strategy using YOLO through camera and LiDAR sensor fusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">Robust Vision-Based Relative-Localization Approach Using an RGB-Depth Camera and LiDAR Sensor Fusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">RoIFusion: 3D Object Detection from LiDAR and Vision</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/03/15/JetsonNano%E6%91%84%E5%83%8F%E5%A4%B4%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/" title="JetsonNano摄像头驱动开发指南">JetsonNano摄像头驱动开发指南</a><time datetime="2022-03-15T06:07:34.000Z" title="发表于 2022-03-15 14:07:34">2022-03-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/22/JetsonTX2%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/" title="JetsonTX2避坑指南">JetsonTX2避坑指南</a><time datetime="2022-02-21T17:46:24.000Z" title="发表于 2022-02-22 01:46:24">2022-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/13/python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8/" title="python迭代器与生成器">python迭代器与生成器</a><time datetime="2021-12-13T06:28:34.000Z" title="发表于 2021-12-13 14:28:34">2021-12-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/22/Arch%20Linux%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/" title="Arch Linux安装指南">Arch Linux安装指南</a><time datetime="2021-11-22T04:43:24.000Z" title="发表于 2021-11-22 12:43:24">2021-11-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/04/Arduino%E4%B8%AD%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9D%BF%E5%8D%A1/" title="Arduino中添加自定义板卡">Arduino中添加自定义板卡</a><time datetime="2021-11-04T10:37:40.000Z" title="发表于 2021-11-04 18:37:40">2021-11-04</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By spaceman</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><script type="text/javascript" src="https://api.uixsj.cn/hitokoto/w.php?code=js"></script><div id="xsjhitokoto"><script>xsjhitokoto()</script></div> <iframe scrolling="no" src="https://tianqiapi.com/api.php?style=tx&color=eee" frameborder="0" allowtransparency="false" align="middle" height="20"></iframe></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>